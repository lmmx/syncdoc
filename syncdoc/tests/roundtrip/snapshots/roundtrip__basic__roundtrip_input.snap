---
source: syncdoc/tests/roundtrip/basic.rs
expression: result.migrate_stderr
---
[SYNCDOC DEBUG] get_docs_path called:
[SYNCDOC DEBUG]   source_file: src
[SYNCDOC DEBUG]   manifest_dir: /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   docs_path from toml: docs
[SYNCDOC DEBUG]   manifest_path (canonical): /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   source_dir (canonical): /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   relative_path (stripped): 
[SYNCDOC DEBUG]   depth: 0
[SYNCDOC DEBUG]   final result: docs
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(214..217) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: crate, span: bytes(218..223) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(223..224) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(224..225) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: formats, span: bytes(225..232) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(232..233) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(233..234) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: Format, span: bytes(234..240) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(240..241) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(242..245) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: crate, span: bytes(246..251) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(251..252) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(252..253) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: section, span: bytes(253..260) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(260..261) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(261..262) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: Section, span: bytes(262..269) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(269..270) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(271..274) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(275..278) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(278..279) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(279..280) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: fs, span: bytes(280..282) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(282..283) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(284..287) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(288..291) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(291..292) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(292..293) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: io, span: bytes(293..295) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(295..296) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(297..300) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(301..304) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(304..305) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(305..306) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: path, span: bytes(306..310) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(310..311) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(311..312) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: Path, span: bytes(313..317) }, Punct { char: ',', spacing: Alone, span: bytes(317..318) }, Ident { sym: PathBuf, span: bytes(319..326) }], span: bytes(312..327) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(327..328) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(329..332) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: streaming_iterator, span: bytes(333..351) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(351..352) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(352..353) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: StreamingIterator, span: bytes(353..370) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(370..371) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(372..375) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: tree_sitter, span: bytes(376..387) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(387..388) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(388..389) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: Parser, span: bytes(390..396) }, Punct { char: ',', spacing: Alone, span: bytes(396..397) }, Ident { sym: Query, span: bytes(398..403) }, Punct { char: ',', spacing: Alone, span: bytes(403..404) }, Ident { sym: QueryCursor, span: bytes(405..416) }], span: bytes(389..417) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(417..418) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(420..469) }, Punct { char: '=', spacing: Alone, span: bytes(420..469) }, Literal { lit: " Find documents matching the given extensions.", span: bytes(420..469) }], span: bytes(420..469) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(470..473) }, Punct { char: '=', spacing: Alone, span: bytes(470..473) }, Literal { lit: "", span: bytes(470..473) }], span: bytes(470..473) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(474..537) }, Punct { char: '=', spacing: Alone, span: bytes(474..537) }, Literal { lit: " If paths is empty, scans the current directory recursively.", span: bytes(474..537) }], span: bytes(474..537) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(538..584) }, Punct { char: '=', spacing: Alone, span: bytes(538..584) }, Literal { lit: " Skips common build/dependency directories.", span: bytes(538..584) }], span: bytes(538..584) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(585..588) }, Punct { char: '=', spacing: Alone, span: bytes(585..588) }, Literal { lit: "", span: bytes(585..588) }], span: bytes(585..588) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(589..601) }, Punct { char: '=', spacing: Alone, span: bytes(589..601) }, Literal { lit: " # Errors", span: bytes(589..601) }], span: bytes(589..601) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(602..605) }, Punct { char: '=', spacing: Alone, span: bytes(602..605) }, Literal { lit: "", span: bytes(602..605) }], span: bytes(602..605) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(606..656) }, Punct { char: '=', spacing: Alone, span: bytes(606..656) }, Literal { lit: " Returns an error if directory traversal fails.", span: bytes(606..656) }], span: bytes(606..656) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(657..660) }, string: "pub" }))), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(661..663) }, string: "fn" }), name: Ident { sym: find_documents, span: bytes(664..678) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: paths, span: bytes(679..684) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(686..689) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: PathBuf, span: bytes(690..697) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: extensions, span: bytes(700..710) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(712..713) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: String, span: bytes(714..720) }], span: bytes(713..721) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: io, span: bytes(726..728) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(728..729) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(729..730) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Result, span: bytes(730..736) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(737..740) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: PathBuf, span: bytes(741..748) })) }], third: Operator<'>'> })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(757..759) }, Ident { sym: paths, span: bytes(760..765) }, Punct { char: '.', spacing: Alone, span: bytes(765..766) }, Ident { sym: is_empty, span: bytes(766..774) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(774..776) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: find_in_directory, span: bytes(787..804) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Path, span: bytes(805..809) }, Punct { char: ':', spacing: Joint, span: bytes(809..810) }, Punct { char: ':', spacing: Alone, span: bytes(810..811) }, Ident { sym: new, span: bytes(811..814) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ".", span: bytes(815..818) }], span: bytes(814..819) }, Punct { char: ',', spacing: Alone, span: bytes(819..820) }, Ident { sym: extensions, span: bytes(821..831) }], span: bytes(804..832) }], span: bytes(777..838) }, Ident { sym: else, span: bytes(839..843) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(854..857) }, Ident { sym: mut, span: bytes(858..861) }, Ident { sym: results, span: bytes(862..869) }, Punct { char: '=', spacing: Alone, span: bytes(870..871) }, Ident { sym: Vec, span: bytes(872..875) }, Punct { char: ':', spacing: Joint, span: bytes(875..876) }, Punct { char: ':', spacing: Alone, span: bytes(876..877) }, Ident { sym: new, span: bytes(877..880) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(880..882) }, Punct { char: ';', spacing: Alone, span: bytes(882..883) }, Ident { sym: for, span: bytes(892..895) }, Ident { sym: path, span: bytes(896..900) }, Ident { sym: in, span: bytes(901..903) }, Ident { sym: paths, span: bytes(904..909) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(924..926) }, Ident { sym: path, span: bytes(927..931) }, Punct { char: '.', spacing: Alone, span: bytes(931..932) }, Ident { sym: is_file, span: bytes(932..939) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(939..941) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(960..962) }, Ident { sym: let, span: bytes(963..966) }, Ident { sym: Some, span: bytes(967..971) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: ext, span: bytes(972..975) }], span: bytes(971..976) }, Punct { char: '=', spacing: Alone, span: bytes(977..978) }, Ident { sym: path, span: bytes(979..983) }, Punct { char: '.', spacing: Alone, span: bytes(983..984) }, Ident { sym: extension, span: bytes(984..993) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(993..995) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(1018..1020) }, Ident { sym: extensions, span: bytes(1021..1031) }, Punct { char: '.', spacing: Alone, span: bytes(1056..1057) }, Ident { sym: iter, span: bytes(1057..1061) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1061..1063) }, Punct { char: '.', spacing: Alone, span: bytes(1088..1089) }, Ident { sym: any, span: bytes(1089..1092) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(1093..1094) }, Ident { sym: e, span: bytes(1094..1095) }, Punct { char: '|', spacing: Alone, span: bytes(1095..1096) }, Ident { sym: e, span: bytes(1097..1098) }, Punct { char: '=', spacing: Joint, span: bytes(1099..1100) }, Punct { char: '=', spacing: Alone, span: bytes(1100..1101) }, Ident { sym: ext, span: bytes(1102..1105) }, Punct { char: '.', spacing: Alone, span: bytes(1105..1106) }, Ident { sym: to_string_lossy, span: bytes(1106..1121) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1121..1123) }, Punct { char: '.', spacing: Alone, span: bytes(1123..1124) }, Ident { sym: as_ref, span: bytes(1124..1130) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1130..1132) }], span: bytes(1092..1133) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: results, span: bytes(1180..1187) }, Punct { char: '.', spacing: Alone, span: bytes(1187..1188) }, Ident { sym: push, span: bytes(1188..1192) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: path, span: bytes(1193..1197) }], span: bytes(1192..1198) }, Punct { char: ';', spacing: Alone, span: bytes(1198..1199) }], span: bytes(1154..1221) }], span: bytes(996..1239) }], span: bytes(942..1253) }, Ident { sym: else, span: bytes(1254..1258) }, Ident { sym: if, span: bytes(1259..1261) }, Ident { sym: path, span: bytes(1262..1266) }, Punct { char: '.', spacing: Alone, span: bytes(1266..1267) }, Ident { sym: is_dir, span: bytes(1267..1273) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1273..1275) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: results, span: bytes(1294..1301) }, Punct { char: '.', spacing: Alone, span: bytes(1301..1302) }, Ident { sym: extend, span: bytes(1302..1308) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: find_in_directory, span: bytes(1309..1326) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(1327..1328) }, Ident { sym: path, span: bytes(1328..1332) }, Punct { char: ',', spacing: Alone, span: bytes(1332..1333) }, Ident { sym: extensions, span: bytes(1334..1344) }], span: bytes(1326..1345) }, Punct { char: '?', spacing: Alone, span: bytes(1345..1346) }], span: bytes(1308..1347) }, Punct { char: ';', spacing: Alone, span: bytes(1347..1348) }], span: bytes(1276..1362) }], span: bytes(910..1372) }, Ident { sym: Ok, span: bytes(1381..1383) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: results, span: bytes(1384..1391) }], span: bytes(1383..1392) }], span: bytes(844..1398) }], span: bytes(751..1400) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(1402..1404) }, string: "fn" }), name: Ident { sym: find_in_directory, span: bytes(1405..1422) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: dir, span: bytes(1423..1426) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(1428..1429) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Path, span: bytes(1429..1433) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: extensions, span: bytes(1435..1445) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(1447..1448) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: String, span: bytes(1449..1455) }], span: bytes(1448..1456) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: io, span: bytes(1461..1463) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(1463..1464) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(1464..1465) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Result, span: bytes(1465..1471) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(1472..1475) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: PathBuf, span: bytes(1476..1483) })) }], third: Operator<'>'> })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(1492..1495) }, Ident { sym: mut, span: bytes(1496..1499) }, Ident { sym: results, span: bytes(1500..1507) }, Punct { char: '=', spacing: Alone, span: bytes(1508..1509) }, Ident { sym: Vec, span: bytes(1510..1513) }, Punct { char: ':', spacing: Joint, span: bytes(1513..1514) }, Punct { char: ':', spacing: Alone, span: bytes(1514..1515) }, Ident { sym: new, span: bytes(1515..1518) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1518..1520) }, Punct { char: ';', spacing: Alone, span: bytes(1520..1521) }, Ident { sym: if, span: bytes(1527..1529) }, Ident { sym: let, span: bytes(1530..1533) }, Ident { sym: Ok, span: bytes(1534..1536) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: entries, span: bytes(1537..1544) }], span: bytes(1536..1545) }, Punct { char: '=', spacing: Alone, span: bytes(1546..1547) }, Ident { sym: fs, span: bytes(1548..1550) }, Punct { char: ':', spacing: Joint, span: bytes(1550..1551) }, Punct { char: ':', spacing: Alone, span: bytes(1551..1552) }, Ident { sym: read_dir, span: bytes(1552..1560) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: dir, span: bytes(1561..1564) }], span: bytes(1560..1565) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: for, span: bytes(1576..1579) }, Ident { sym: entry, span: bytes(1580..1585) }, Ident { sym: in, span: bytes(1586..1588) }, Ident { sym: entries, span: bytes(1589..1596) }, Punct { char: '.', spacing: Alone, span: bytes(1596..1597) }, Ident { sym: flatten, span: bytes(1597..1604) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1604..1606) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(1621..1624) }, Ident { sym: path, span: bytes(1625..1629) }, Punct { char: '=', spacing: Alone, span: bytes(1630..1631) }, Ident { sym: entry, span: bytes(1632..1637) }, Punct { char: '.', spacing: Alone, span: bytes(1637..1638) }, Ident { sym: path, span: bytes(1638..1642) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1642..1644) }, Punct { char: ';', spacing: Alone, span: bytes(1644..1645) }, Ident { sym: if, span: bytes(1659..1661) }, Ident { sym: path, span: bytes(1662..1666) }, Punct { char: '.', spacing: Alone, span: bytes(1666..1667) }, Ident { sym: is_dir, span: bytes(1667..1673) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1673..1675) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(1694..1696) }, Ident { sym: let, span: bytes(1697..1700) }, Ident { sym: Some, span: bytes(1701..1705) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: name, span: bytes(1706..1710) }], span: bytes(1705..1711) }, Punct { char: '=', spacing: Alone, span: bytes(1712..1713) }, Ident { sym: path, span: bytes(1714..1718) }, Punct { char: '.', spacing: Alone, span: bytes(1718..1719) }, Ident { sym: file_name, span: bytes(1719..1728) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1728..1730) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(1753..1756) }, Ident { sym: name_str, span: bytes(1757..1765) }, Punct { char: '=', spacing: Alone, span: bytes(1766..1767) }, Ident { sym: name, span: bytes(1768..1772) }, Punct { char: '.', spacing: Alone, span: bytes(1772..1773) }, Ident { sym: to_string_lossy, span: bytes(1773..1788) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1788..1790) }, Punct { char: ';', spacing: Alone, span: bytes(1790..1791) }, Ident { sym: if, span: bytes(1812..1814) }, Group { delimiter: Bracket, stream: TokenStream [Literal { lit: "target", span: bytes(1816..1824) }, Punct { char: ',', spacing: Alone, span: bytes(1824..1825) }, Literal { lit: "dist", span: bytes(1826..1832) }, Punct { char: ',', spacing: Alone, span: bytes(1832..1833) }, Literal { lit: ".git", span: bytes(1834..1840) }, Punct { char: ',', spacing: Alone, span: bytes(1840..1841) }, Literal { lit: "node_modules", span: bytes(1842..1856) }], span: bytes(1815..1857) }, Punct { char: '.', spacing: Alone, span: bytes(1857..1858) }, Ident { sym: contains, span: bytes(1858..1866) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(1867..1868) }, Ident { sym: name_str, span: bytes(1868..1876) }, Punct { char: '.', spacing: Alone, span: bytes(1876..1877) }, Ident { sym: as_ref, span: bytes(1877..1883) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1883..1885) }], span: bytes(1866..1886) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: continue, span: bytes(1913..1921) }, Punct { char: ';', spacing: Alone, span: bytes(1921..1922) }], span: bytes(1887..1944) }], span: bytes(1731..1962) }, Ident { sym: results, span: bytes(1979..1986) }, Punct { char: '.', spacing: Alone, span: bytes(1986..1987) }, Ident { sym: extend, span: bytes(1987..1993) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: find_in_directory, span: bytes(1994..2011) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(2012..2013) }, Ident { sym: path, span: bytes(2013..2017) }, Punct { char: ',', spacing: Alone, span: bytes(2017..2018) }, Ident { sym: extensions, span: bytes(2019..2029) }], span: bytes(2011..2030) }, Punct { char: '?', spacing: Alone, span: bytes(2030..2031) }], span: bytes(1993..2032) }, Punct { char: ';', spacing: Alone, span: bytes(2032..2033) }], span: bytes(1676..2047) }, Ident { sym: else, span: bytes(2048..2052) }, Ident { sym: if, span: bytes(2053..2055) }, Ident { sym: path, span: bytes(2056..2060) }, Punct { char: '.', spacing: Alone, span: bytes(2060..2061) }, Ident { sym: is_file, span: bytes(2061..2068) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2068..2070) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(2089..2091) }, Ident { sym: let, span: bytes(2092..2095) }, Ident { sym: Some, span: bytes(2096..2100) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: ext, span: bytes(2101..2104) }], span: bytes(2100..2105) }, Punct { char: '=', spacing: Alone, span: bytes(2106..2107) }, Ident { sym: path, span: bytes(2108..2112) }, Punct { char: '.', spacing: Alone, span: bytes(2112..2113) }, Ident { sym: extension, span: bytes(2113..2122) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2122..2124) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(2147..2149) }, Ident { sym: extensions, span: bytes(2150..2160) }, Punct { char: '.', spacing: Alone, span: bytes(2185..2186) }, Ident { sym: iter, span: bytes(2186..2190) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2190..2192) }, Punct { char: '.', spacing: Alone, span: bytes(2217..2218) }, Ident { sym: any, span: bytes(2218..2221) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(2222..2223) }, Ident { sym: e, span: bytes(2223..2224) }, Punct { char: '|', spacing: Alone, span: bytes(2224..2225) }, Ident { sym: e, span: bytes(2226..2227) }, Punct { char: '=', spacing: Joint, span: bytes(2228..2229) }, Punct { char: '=', spacing: Alone, span: bytes(2229..2230) }, Ident { sym: ext, span: bytes(2231..2234) }, Punct { char: '.', spacing: Alone, span: bytes(2234..2235) }, Ident { sym: to_string_lossy, span: bytes(2235..2250) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2250..2252) }, Punct { char: '.', spacing: Alone, span: bytes(2252..2253) }, Ident { sym: as_ref, span: bytes(2253..2259) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2259..2261) }], span: bytes(2221..2262) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: results, span: bytes(2309..2316) }, Punct { char: '.', spacing: Alone, span: bytes(2316..2317) }, Ident { sym: push, span: bytes(2317..2321) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: path, span: bytes(2322..2326) }], span: bytes(2321..2327) }, Punct { char: ';', spacing: Alone, span: bytes(2327..2328) }], span: bytes(2283..2350) }], span: bytes(2125..2368) }], span: bytes(2071..2382) }], span: bytes(1607..2392) }], span: bytes(1566..2398) }, Ident { sym: Ok, span: bytes(2404..2406) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: results, span: bytes(2407..2414) }], span: bytes(2406..2415) }], span: bytes(1486..2417) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2419..2474) }, Punct { char: '=', spacing: Alone, span: bytes(2419..2474) }, Literal { lit: " Extract sections from a document using tree-sitter.", span: bytes(2419..2474) }], span: bytes(2419..2474) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2475..2478) }, Punct { char: '=', spacing: Alone, span: bytes(2475..2478) }, Literal { lit: "", span: bytes(2475..2478) }], span: bytes(2475..2478) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2479..2547) }, Punct { char: '=', spacing: Alone, span: bytes(2479..2547) }, Literal { lit: " Parses the file with the given format and extracts all sections,", span: bytes(2479..2547) }], span: bytes(2479..2547) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2548..2612) }, Punct { char: '=', spacing: Alone, span: bytes(2548..2612) }, Literal { lit: " building parent/child relationships based on heading levels.", span: bytes(2548..2612) }], span: bytes(2548..2612) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2613..2616) }, Punct { char: '=', spacing: Alone, span: bytes(2613..2616) }, Literal { lit: "", span: bytes(2613..2616) }], span: bytes(2613..2616) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2617..2629) }, Punct { char: '=', spacing: Alone, span: bytes(2617..2629) }, Literal { lit: " # Errors", span: bytes(2617..2629) }], span: bytes(2617..2629) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2630..2633) }, Punct { char: '=', spacing: Alone, span: bytes(2630..2633) }, Literal { lit: "", span: bytes(2630..2633) }], span: bytes(2630..2633) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2634..2688) }, Punct { char: '=', spacing: Alone, span: bytes(2634..2688) }, Literal { lit: " Returns an error if file reading or parsing fails.", span: bytes(2634..2688) }], span: bytes(2634..2688) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(2689..2692) }, string: "pub" }))), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2693..2695) }, string: "fn" }), name: Ident { sym: extract_sections, span: bytes(2696..2712) }, generics: Some(Generics { _lt: Operator<'<'>, content: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: Ident { sym: F, span: bytes(2713..2714) } }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: Punct { char: ':', spacing: Alone, span: bytes(2714..2715) } }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: Ident { sym: Format, span: bytes(2716..2722) } }, delimiter: Some(Nothing) }]), _gt: Operator<'>'> }), params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: file_path, span: bytes(2724..2733) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(2735..2736) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Path, span: bytes(2736..2740) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: format, span: bytes(2742..2748) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(2750..2751) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: F, span: bytes(2751..2752) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: io, span: bytes(2757..2759) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(2759..2760) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(2760..2761) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Result, span: bytes(2761..2767) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(2768..2771) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Section, span: bytes(2772..2779) })) }], third: Operator<'>'> })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(2788..2791) }, Ident { sym: content, span: bytes(2792..2799) }, Punct { char: '=', spacing: Alone, span: bytes(2800..2801) }, Ident { sym: fs, span: bytes(2802..2804) }, Punct { char: ':', spacing: Joint, span: bytes(2804..2805) }, Punct { char: ':', spacing: Alone, span: bytes(2805..2806) }, Ident { sym: read_to_string, span: bytes(2806..2820) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: file_path, span: bytes(2821..2830) }], span: bytes(2820..2831) }, Punct { char: '?', spacing: Joint, span: bytes(2831..2832) }, Punct { char: ';', spacing: Alone, span: bytes(2832..2833) }, Ident { sym: let, span: bytes(2839..2842) }, Ident { sym: mut, span: bytes(2843..2846) }, Ident { sym: parser, span: bytes(2847..2853) }, Punct { char: '=', spacing: Alone, span: bytes(2854..2855) }, Ident { sym: Parser, span: bytes(2856..2862) }, Punct { char: ':', spacing: Joint, span: bytes(2862..2863) }, Punct { char: ':', spacing: Alone, span: bytes(2863..2864) }, Ident { sym: new, span: bytes(2864..2867) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2867..2869) }, Punct { char: ';', spacing: Alone, span: bytes(2869..2870) }, Ident { sym: parser, span: bytes(2875..2881) }, Punct { char: '.', spacing: Alone, span: bytes(2890..2891) }, Ident { sym: set_language, span: bytes(2891..2903) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(2904..2905) }, Ident { sym: format, span: bytes(2905..2911) }, Punct { char: '.', spacing: Alone, span: bytes(2911..2912) }, Ident { sym: language, span: bytes(2912..2920) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2920..2922) }], span: bytes(2903..2923) }, Punct { char: '.', spacing: Alone, span: bytes(2932..2933) }, Ident { sym: map_err, span: bytes(2933..2940) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(2941..2942) }, Ident { sym: e, span: bytes(2942..2943) }, Punct { char: '|', spacing: Alone, span: bytes(2943..2944) }, Ident { sym: io, span: bytes(2945..2947) }, Punct { char: ':', spacing: Joint, span: bytes(2947..2948) }, Punct { char: ':', spacing: Alone, span: bytes(2948..2949) }, Ident { sym: Error, span: bytes(2949..2954) }, Punct { char: ':', spacing: Joint, span: bytes(2954..2955) }, Punct { char: ':', spacing: Alone, span: bytes(2955..2956) }, Ident { sym: other, span: bytes(2956..2961) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: format, span: bytes(2962..2968) }, Punct { char: '!', spacing: Alone, span: bytes(2968..2969) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Language error: {e}", span: bytes(2970..2991) }], span: bytes(2969..2992) }], span: bytes(2961..2993) }], span: bytes(2940..2994) }, Punct { char: '?', spacing: Joint, span: bytes(2994..2995) }, Punct { char: ';', spacing: Alone, span: bytes(2995..2996) }, Ident { sym: let, span: bytes(3002..3005) }, Ident { sym: tree, span: bytes(3006..3010) }, Punct { char: '=', spacing: Alone, span: bytes(3011..3012) }, Ident { sym: parser, span: bytes(3013..3019) }, Punct { char: '.', spacing: Alone, span: bytes(3028..3029) }, Ident { sym: parse, span: bytes(3029..3034) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3035..3036) }, Ident { sym: content, span: bytes(3036..3043) }, Punct { char: ',', spacing: Alone, span: bytes(3043..3044) }, Ident { sym: None, span: bytes(3045..3049) }], span: bytes(3034..3050) }, Punct { char: '.', spacing: Alone, span: bytes(3059..3060) }, Ident { sym: ok_or_else, span: bytes(3060..3070) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Joint, span: bytes(3071..3072) }, Punct { char: '|', spacing: Alone, span: bytes(3072..3073) }, Ident { sym: io, span: bytes(3074..3076) }, Punct { char: ':', spacing: Joint, span: bytes(3076..3077) }, Punct { char: ':', spacing: Alone, span: bytes(3077..3078) }, Ident { sym: Error, span: bytes(3078..3083) }, Punct { char: ':', spacing: Joint, span: bytes(3083..3084) }, Punct { char: ':', spacing: Alone, span: bytes(3084..3085) }, Ident { sym: other, span: bytes(3085..3090) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Parse failed", span: bytes(3091..3105) }], span: bytes(3090..3106) }], span: bytes(3070..3107) }, Punct { char: '?', spacing: Joint, span: bytes(3107..3108) }, Punct { char: ';', spacing: Alone, span: bytes(3108..3109) }, Ident { sym: let, span: bytes(3115..3118) }, Ident { sym: section_query, span: bytes(3119..3132) }, Punct { char: '=', spacing: Alone, span: bytes(3133..3134) }, Ident { sym: Query, span: bytes(3135..3140) }, Punct { char: ':', spacing: Joint, span: bytes(3140..3141) }, Punct { char: ':', spacing: Alone, span: bytes(3141..3142) }, Ident { sym: new, span: bytes(3142..3145) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3146..3147) }, Ident { sym: format, span: bytes(3147..3153) }, Punct { char: '.', spacing: Alone, span: bytes(3153..3154) }, Ident { sym: language, span: bytes(3154..3162) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3162..3164) }, Punct { char: ',', spacing: Alone, span: bytes(3164..3165) }, Ident { sym: format, span: bytes(3166..3172) }, Punct { char: '.', spacing: Alone, span: bytes(3172..3173) }, Ident { sym: section_query, span: bytes(3173..3186) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3186..3188) }], span: bytes(3145..3189) }, Punct { char: '.', spacing: Alone, span: bytes(3198..3199) }, Ident { sym: map_err, span: bytes(3199..3206) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(3207..3208) }, Ident { sym: e, span: bytes(3208..3209) }, Punct { char: '|', spacing: Alone, span: bytes(3209..3210) }, Ident { sym: io, span: bytes(3211..3213) }, Punct { char: ':', spacing: Joint, span: bytes(3213..3214) }, Punct { char: ':', spacing: Alone, span: bytes(3214..3215) }, Ident { sym: Error, span: bytes(3215..3220) }, Punct { char: ':', spacing: Joint, span: bytes(3220..3221) }, Punct { char: ':', spacing: Alone, span: bytes(3221..3222) }, Ident { sym: other, span: bytes(3222..3227) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: format, span: bytes(3228..3234) }, Punct { char: '!', spacing: Alone, span: bytes(3234..3235) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Query error: {e}", span: bytes(3236..3254) }], span: bytes(3235..3255) }], span: bytes(3227..3256) }], span: bytes(3206..3257) }, Punct { char: '?', spacing: Joint, span: bytes(3257..3258) }, Punct { char: ';', spacing: Alone, span: bytes(3258..3259) }, Ident { sym: let, span: bytes(3265..3268) }, Ident { sym: title_query, span: bytes(3269..3280) }, Punct { char: '=', spacing: Alone, span: bytes(3281..3282) }, Ident { sym: Query, span: bytes(3283..3288) }, Punct { char: ':', spacing: Joint, span: bytes(3288..3289) }, Punct { char: ':', spacing: Alone, span: bytes(3289..3290) }, Ident { sym: new, span: bytes(3290..3293) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3294..3295) }, Ident { sym: format, span: bytes(3295..3301) }, Punct { char: '.', spacing: Alone, span: bytes(3301..3302) }, Ident { sym: language, span: bytes(3302..3310) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3310..3312) }, Punct { char: ',', spacing: Alone, span: bytes(3312..3313) }, Ident { sym: format, span: bytes(3314..3320) }, Punct { char: '.', spacing: Alone, span: bytes(3320..3321) }, Ident { sym: title_query, span: bytes(3321..3332) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3332..3334) }], span: bytes(3293..3335) }, Punct { char: '.', spacing: Alone, span: bytes(3344..3345) }, Ident { sym: map_err, span: bytes(3345..3352) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(3353..3354) }, Ident { sym: e, span: bytes(3354..3355) }, Punct { char: '|', spacing: Alone, span: bytes(3355..3356) }, Ident { sym: io, span: bytes(3357..3359) }, Punct { char: ':', spacing: Joint, span: bytes(3359..3360) }, Punct { char: ':', spacing: Alone, span: bytes(3360..3361) }, Ident { sym: Error, span: bytes(3361..3366) }, Punct { char: ':', spacing: Joint, span: bytes(3366..3367) }, Punct { char: ':', spacing: Alone, span: bytes(3367..3368) }, Ident { sym: other, span: bytes(3368..3373) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: format, span: bytes(3374..3380) }, Punct { char: '!', spacing: Alone, span: bytes(3380..3381) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Query error: {e}", span: bytes(3382..3400) }], span: bytes(3381..3401) }], span: bytes(3373..3402) }], span: bytes(3352..3403) }, Punct { char: '?', spacing: Joint, span: bytes(3403..3404) }, Punct { char: ';', spacing: Alone, span: bytes(3404..3405) }, Ident { sym: let, span: bytes(3474..3477) }, Ident { sym: mut, span: bytes(3478..3481) }, Ident { sym: headings, span: bytes(3482..3490) }, Punct { char: ':', spacing: Alone, span: bytes(3490..3491) }, Ident { sym: Vec, span: bytes(3492..3495) }, Punct { char: '<', spacing: Alone, span: bytes(3495..3496) }, Ident { sym: tree_sitter, span: bytes(3496..3507) }, Punct { char: ':', spacing: Joint, span: bytes(3507..3508) }, Punct { char: ':', spacing: Alone, span: bytes(3508..3509) }, Ident { sym: Node, span: bytes(3509..3513) }, Punct { char: '>', spacing: Alone, span: bytes(3513..3514) }, Punct { char: '=', spacing: Alone, span: bytes(3515..3516) }, Ident { sym: Vec, span: bytes(3517..3520) }, Punct { char: ':', spacing: Joint, span: bytes(3520..3521) }, Punct { char: ':', spacing: Alone, span: bytes(3521..3522) }, Ident { sym: new, span: bytes(3522..3525) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3525..3527) }, Punct { char: ';', spacing: Alone, span: bytes(3527..3528) }, Ident { sym: let, span: bytes(3533..3536) }, Ident { sym: mut, span: bytes(3537..3540) }, Ident { sym: cursor, span: bytes(3541..3547) }, Punct { char: '=', spacing: Alone, span: bytes(3548..3549) }, Ident { sym: QueryCursor, span: bytes(3550..3561) }, Punct { char: ':', spacing: Joint, span: bytes(3561..3562) }, Punct { char: ':', spacing: Alone, span: bytes(3562..3563) }, Ident { sym: new, span: bytes(3563..3566) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3566..3568) }, Punct { char: ';', spacing: Alone, span: bytes(3568..3569) }, Ident { sym: let, span: bytes(3574..3577) }, Ident { sym: mut, span: bytes(3578..3581) }, Ident { sym: matches, span: bytes(3582..3589) }, Punct { char: '=', spacing: Alone, span: bytes(3590..3591) }, Ident { sym: cursor, span: bytes(3592..3598) }, Punct { char: '.', spacing: Alone, span: bytes(3598..3599) }, Ident { sym: matches, span: bytes(3599..3606) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3607..3608) }, Ident { sym: section_query, span: bytes(3608..3621) }, Punct { char: ',', spacing: Alone, span: bytes(3621..3622) }, Ident { sym: tree, span: bytes(3623..3627) }, Punct { char: '.', spacing: Alone, span: bytes(3627..3628) }, Ident { sym: root_node, span: bytes(3628..3637) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3637..3639) }, Punct { char: ',', spacing: Alone, span: bytes(3639..3640) }, Ident { sym: content, span: bytes(3641..3648) }, Punct { char: '.', spacing: Alone, span: bytes(3648..3649) }, Ident { sym: as_bytes, span: bytes(3649..3657) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3657..3659) }], span: bytes(3606..3660) }, Punct { char: ';', spacing: Alone, span: bytes(3660..3661) }, Ident { sym: while, span: bytes(3667..3672) }, Ident { sym: let, span: bytes(3673..3676) }, Ident { sym: Some, span: bytes(3677..3681) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: m, span: bytes(3682..3683) }], span: bytes(3681..3684) }, Punct { char: '=', spacing: Alone, span: bytes(3685..3686) }, Ident { sym: matches, span: bytes(3687..3694) }, Punct { char: '.', spacing: Alone, span: bytes(3694..3695) }, Ident { sym: next, span: bytes(3695..3699) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3699..3701) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(3712..3714) }, Ident { sym: let, span: bytes(3715..3718) }, Ident { sym: Some, span: bytes(3719..3723) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: c, span: bytes(3724..3725) }], span: bytes(3723..3726) }, Punct { char: '=', spacing: Alone, span: bytes(3727..3728) }, Ident { sym: m, span: bytes(3729..3730) }, Punct { char: '.', spacing: Alone, span: bytes(3730..3731) }, Ident { sym: captures, span: bytes(3731..3739) }, Punct { char: '.', spacing: Alone, span: bytes(3739..3740) }, Ident { sym: first, span: bytes(3740..3745) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3745..3747) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: headings, span: bytes(3762..3770) }, Punct { char: '.', spacing: Alone, span: bytes(3770..3771) }, Ident { sym: push, span: bytes(3771..3775) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: c, span: bytes(3776..3777) }, Punct { char: '.', spacing: Alone, span: bytes(3777..3778) }, Ident { sym: node, span: bytes(3778..3782) }], span: bytes(3775..3783) }, Punct { char: ';', spacing: Alone, span: bytes(3783..3784) }], span: bytes(3748..3794) }], span: bytes(3702..3800) }, Ident { sym: let, span: bytes(3806..3809) }, Ident { sym: mut, span: bytes(3810..3813) }, Ident { sym: sections, span: bytes(3814..3822) }, Punct { char: '=', spacing: Alone, span: bytes(3823..3824) }, Ident { sym: Vec, span: bytes(3825..3828) }, Punct { char: ':', spacing: Joint, span: bytes(3828..3829) }, Punct { char: ':', spacing: Alone, span: bytes(3829..3830) }, Ident { sym: new, span: bytes(3830..3833) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3833..3835) }, Punct { char: ';', spacing: Alone, span: bytes(3835..3836) }, Ident { sym: for, span: bytes(3842..3845) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: i, span: bytes(3847..3848) }, Punct { char: ',', spacing: Alone, span: bytes(3848..3849) }, Ident { sym: heading, span: bytes(3850..3857) }], span: bytes(3846..3858) }, Ident { sym: in, span: bytes(3859..3861) }, Ident { sym: headings, span: bytes(3862..3870) }, Punct { char: '.', spacing: Alone, span: bytes(3870..3871) }, Ident { sym: iter, span: bytes(3871..3875) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3875..3877) }, Punct { char: '.', spacing: Alone, span: bytes(3877..3878) }, Ident { sym: enumerate, span: bytes(3878..3887) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3887..3889) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(3962..3965) }, Ident { sym: mut, span: bytes(3966..3969) }, Ident { sym: level, span: bytes(3970..3975) }, Punct { char: '=', spacing: Alone, span: bytes(3976..3977) }, Literal { lit: 1, span: bytes(3978..3979) }, Punct { char: ';', spacing: Alone, span: bytes(3979..3980) }, Ident { sym: let, span: bytes(3989..3992) }, Ident { sym: mut, span: bytes(3993..3996) }, Ident { sym: heading_cursor, span: bytes(3997..4011) }, Punct { char: '=', spacing: Alone, span: bytes(4012..4013) }, Ident { sym: heading, span: bytes(4014..4021) }, Punct { char: '.', spacing: Alone, span: bytes(4021..4022) }, Ident { sym: walk, span: bytes(4022..4026) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4026..4028) }, Punct { char: ';', spacing: Alone, span: bytes(4028..4029) }, Ident { sym: if, span: bytes(4038..4040) }, Ident { sym: heading_cursor, span: bytes(4041..4055) }, Punct { char: '.', spacing: Alone, span: bytes(4055..4056) }, Ident { sym: goto_first_child, span: bytes(4056..4072) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4072..4074) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: loop, span: bytes(4089..4093) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(4112..4115) }, Ident { sym: node, span: bytes(4116..4120) }, Punct { char: '=', spacing: Alone, span: bytes(4121..4122) }, Ident { sym: heading_cursor, span: bytes(4123..4137) }, Punct { char: '.', spacing: Alone, span: bytes(4137..4138) }, Ident { sym: node, span: bytes(4138..4142) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4142..4144) }, Punct { char: ';', spacing: Alone, span: bytes(4144..4145) }, Ident { sym: let, span: bytes(4162..4165) }, Ident { sym: kind, span: bytes(4166..4170) }, Punct { char: '=', spacing: Alone, span: bytes(4171..4172) }, Ident { sym: node, span: bytes(4173..4177) }, Punct { char: '.', spacing: Alone, span: bytes(4177..4178) }, Ident { sym: kind, span: bytes(4178..4182) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4182..4184) }, Punct { char: ';', spacing: Alone, span: bytes(4184..4185) }, Ident { sym: if, span: bytes(4262..4264) }, Ident { sym: kind, span: bytes(4265..4269) }, Punct { char: '.', spacing: Alone, span: bytes(4269..4270) }, Ident { sym: starts_with, span: bytes(4270..4281) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "atx_h", span: bytes(4282..4289) }], span: bytes(4281..4290) }, Punct { char: '&', spacing: Joint, span: bytes(4291..4292) }, Punct { char: '&', spacing: Alone, span: bytes(4292..4293) }, Ident { sym: kind, span: bytes(4294..4298) }, Punct { char: '.', spacing: Alone, span: bytes(4298..4299) }, Ident { sym: ends_with, span: bytes(4299..4308) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "_marker", span: bytes(4309..4318) }], span: bytes(4308..4319) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(4342..4344) }, Ident { sym: let, span: bytes(4345..4348) }, Ident { sym: Some, span: bytes(4349..4353) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: level_char, span: bytes(4354..4364) }], span: bytes(4353..4365) }, Punct { char: '=', spacing: Alone, span: bytes(4366..4367) }, Ident { sym: kind, span: bytes(4368..4372) }, Punct { char: '.', spacing: Alone, span: bytes(4372..4373) }, Ident { sym: chars, span: bytes(4373..4378) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4378..4380) }, Punct { char: '.', spacing: Alone, span: bytes(4380..4381) }, Ident { sym: nth, span: bytes(4381..4384) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 5, span: bytes(4385..4386) }], span: bytes(4384..4387) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: level, span: bytes(4414..4419) }, Punct { char: '=', spacing: Alone, span: bytes(4420..4421) }, Ident { sym: level_char, span: bytes(4422..4432) }, Punct { char: '.', spacing: Alone, span: bytes(4432..4433) }, Ident { sym: to_digit, span: bytes(4433..4441) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 10, span: bytes(4442..4444) }], span: bytes(4441..4445) }, Punct { char: '.', spacing: Alone, span: bytes(4445..4446) }, Ident { sym: unwrap_or, span: bytes(4446..4455) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4456..4457) }], span: bytes(4455..4458) }, Ident { sym: as, span: bytes(4459..4461) }, Ident { sym: usize, span: bytes(4462..4467) }, Punct { char: ';', spacing: Alone, span: bytes(4467..4468) }], span: bytes(4388..4490) }, Ident { sym: break, span: bytes(4511..4516) }, Punct { char: ';', spacing: Alone, span: bytes(4516..4517) }], span: bytes(4320..4535) }, Ident { sym: if, span: bytes(4552..4554) }, Punct { char: '!', spacing: Alone, span: bytes(4555..4556) }, Ident { sym: heading_cursor, span: bytes(4556..4570) }, Punct { char: '.', spacing: Alone, span: bytes(4570..4571) }, Ident { sym: goto_next_sibling, span: bytes(4571..4588) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4588..4590) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: break, span: bytes(4613..4618) }, Punct { char: ';', spacing: Alone, span: bytes(4618..4619) }], span: bytes(4591..4637) }], span: bytes(4094..4651) }], span: bytes(4075..4661) }, Ident { sym: let, span: bytes(4708..4711) }, Ident { sym: mut, span: bytes(4712..4715) }, Ident { sym: title_cursor, span: bytes(4716..4728) }, Punct { char: '=', spacing: Alone, span: bytes(4729..4730) }, Ident { sym: QueryCursor, span: bytes(4731..4742) }, Punct { char: ':', spacing: Joint, span: bytes(4742..4743) }, Punct { char: ':', spacing: Alone, span: bytes(4743..4744) }, Ident { sym: new, span: bytes(4744..4747) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4747..4749) }, Punct { char: ';', spacing: Alone, span: bytes(4749..4750) }, Ident { sym: let, span: bytes(4759..4762) }, Ident { sym: mut, span: bytes(4763..4766) }, Ident { sym: title, span: bytes(4767..4772) }, Punct { char: '=', spacing: Alone, span: bytes(4773..4774) }, Ident { sym: String, span: bytes(4775..4781) }, Punct { char: ':', spacing: Joint, span: bytes(4781..4782) }, Punct { char: ':', spacing: Alone, span: bytes(4782..4783) }, Ident { sym: from, span: bytes(4783..4787) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Untitled", span: bytes(4788..4798) }], span: bytes(4787..4799) }, Punct { char: ';', spacing: Alone, span: bytes(4799..4800) }, Ident { sym: let, span: bytes(4809..4812) }, Ident { sym: mut, span: bytes(4813..4816) }, Ident { sym: title_matches, span: bytes(4817..4830) }, Punct { char: '=', spacing: Alone, span: bytes(4831..4832) }, Ident { sym: title_cursor, span: bytes(4833..4845) }, Punct { char: '.', spacing: Alone, span: bytes(4845..4846) }, Ident { sym: matches, span: bytes(4846..4853) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(4854..4855) }, Ident { sym: title_query, span: bytes(4855..4866) }, Punct { char: ',', spacing: Alone, span: bytes(4866..4867) }, Punct { char: '*', spacing: Alone, span: bytes(4868..4869) }, Ident { sym: heading, span: bytes(4869..4876) }, Punct { char: ',', spacing: Alone, span: bytes(4876..4877) }, Ident { sym: content, span: bytes(4878..4885) }, Punct { char: '.', spacing: Alone, span: bytes(4885..4886) }, Ident { sym: as_bytes, span: bytes(4886..4894) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4894..4896) }], span: bytes(4853..4897) }, Punct { char: ';', spacing: Alone, span: bytes(4897..4898) }, Ident { sym: while, span: bytes(4907..4912) }, Ident { sym: let, span: bytes(4913..4916) }, Ident { sym: Some, span: bytes(4917..4921) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: m, span: bytes(4922..4923) }], span: bytes(4921..4924) }, Punct { char: '=', spacing: Alone, span: bytes(4925..4926) }, Ident { sym: title_matches, span: bytes(4927..4940) }, Punct { char: '.', spacing: Alone, span: bytes(4940..4941) }, Ident { sym: next, span: bytes(4941..4945) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4945..4947) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(4962..4964) }, Ident { sym: let, span: bytes(4965..4968) }, Ident { sym: Some, span: bytes(4969..4973) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: c, span: bytes(4974..4975) }], span: bytes(4973..4976) }, Punct { char: '=', spacing: Alone, span: bytes(4977..4978) }, Ident { sym: m, span: bytes(4979..4980) }, Punct { char: '.', spacing: Alone, span: bytes(4997..4998) }, Ident { sym: captures, span: bytes(4998..5006) }, Punct { char: '.', spacing: Alone, span: bytes(5023..5024) }, Ident { sym: iter, span: bytes(5024..5028) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5028..5030) }, Punct { char: '.', spacing: Alone, span: bytes(5047..5048) }, Ident { sym: find, span: bytes(5048..5052) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(5053..5054) }, Ident { sym: c, span: bytes(5054..5055) }, Punct { char: '|', spacing: Alone, span: bytes(5055..5056) }, Ident { sym: title_query, span: bytes(5057..5068) }, Punct { char: '.', spacing: Alone, span: bytes(5068..5069) }, Ident { sym: capture_names, span: bytes(5069..5082) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5082..5084) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: c, span: bytes(5085..5086) }, Punct { char: '.', spacing: Alone, span: bytes(5086..5087) }, Ident { sym: index, span: bytes(5087..5092) }, Ident { sym: as, span: bytes(5093..5095) }, Ident { sym: usize, span: bytes(5096..5101) }], span: bytes(5084..5102) }, Punct { char: '=', spacing: Joint, span: bytes(5103..5104) }, Punct { char: '=', spacing: Alone, span: bytes(5104..5105) }, Literal { lit: "title", span: bytes(5106..5113) }], span: bytes(5052..5114) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: title, span: bytes(5145..5150) }, Punct { char: '=', spacing: Alone, span: bytes(5151..5152) }, Ident { sym: content, span: bytes(5153..5160) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: c, span: bytes(5161..5162) }, Punct { char: '.', spacing: Alone, span: bytes(5162..5163) }, Ident { sym: node, span: bytes(5163..5167) }, Punct { char: '.', spacing: Alone, span: bytes(5167..5168) }, Ident { sym: byte_range, span: bytes(5168..5178) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5178..5180) }], span: bytes(5160..5181) }, Punct { char: '.', spacing: Alone, span: bytes(5181..5182) }, Ident { sym: trim, span: bytes(5182..5186) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5186..5188) }, Punct { char: '.', spacing: Alone, span: bytes(5188..5189) }, Ident { sym: to_string, span: bytes(5189..5198) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5198..5200) }, Punct { char: ';', spacing: Alone, span: bytes(5200..5201) }, Ident { sym: break, span: bytes(5218..5223) }, Punct { char: ';', spacing: Alone, span: bytes(5223..5224) }], span: bytes(5127..5238) }], span: bytes(4948..5248) }, Ident { sym: let, span: bytes(5325..5328) }, Ident { sym: byte_start, span: bytes(5329..5339) }, Punct { char: '=', spacing: Alone, span: bytes(5340..5341) }, Ident { sym: heading, span: bytes(5342..5349) }, Punct { char: '.', spacing: Alone, span: bytes(5349..5350) }, Ident { sym: end_byte, span: bytes(5350..5358) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5358..5360) }, Punct { char: ';', spacing: Alone, span: bytes(5360..5361) }, Ident { sym: let, span: bytes(5370..5373) }, Ident { sym: byte_end, span: bytes(5374..5382) }, Punct { char: '=', spacing: Alone, span: bytes(5383..5384) }, Ident { sym: headings, span: bytes(5385..5393) }, Punct { char: '.', spacing: Alone, span: bytes(5406..5407) }, Ident { sym: get, span: bytes(5407..5410) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: i, span: bytes(5411..5412) }, Punct { char: '+', spacing: Alone, span: bytes(5413..5414) }, Literal { lit: 1, span: bytes(5415..5416) }], span: bytes(5410..5417) }, Punct { char: '.', spacing: Alone, span: bytes(5430..5431) }, Ident { sym: map_or, span: bytes(5431..5437) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: content, span: bytes(5438..5445) }, Punct { char: '.', spacing: Alone, span: bytes(5445..5446) }, Ident { sym: len, span: bytes(5446..5449) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5449..5451) }, Punct { char: ',', spacing: Alone, span: bytes(5451..5452) }, Ident { sym: tree_sitter, span: bytes(5453..5464) }, Punct { char: ':', spacing: Joint, span: bytes(5464..5465) }, Punct { char: ':', spacing: Alone, span: bytes(5465..5466) }, Ident { sym: Node, span: bytes(5466..5470) }, Punct { char: ':', spacing: Joint, span: bytes(5470..5471) }, Punct { char: ':', spacing: Alone, span: bytes(5471..5472) }, Ident { sym: start_byte, span: bytes(5472..5482) }], span: bytes(5437..5483) }, Punct { char: ';', spacing: Alone, span: bytes(5483..5484) }, Ident { sym: let, span: bytes(5583..5586) }, Ident { sym: line_start, span: bytes(5587..5597) }, Punct { char: '=', spacing: Alone, span: bytes(5598..5599) }, Ident { sym: i64, span: bytes(5600..5603) }, Punct { char: ':', spacing: Joint, span: bytes(5603..5604) }, Punct { char: ':', spacing: Alone, span: bytes(5604..5605) }, Ident { sym: try_from, span: bytes(5605..5613) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: heading, span: bytes(5614..5621) }, Punct { char: '.', spacing: Alone, span: bytes(5621..5622) }, Ident { sym: end_position, span: bytes(5622..5634) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5634..5636) }, Punct { char: '.', spacing: Alone, span: bytes(5636..5637) }, Ident { sym: row, span: bytes(5637..5640) }], span: bytes(5613..5641) }, Punct { char: '.', spacing: Alone, span: bytes(5641..5642) }, Ident { sym: unwrap_or, span: bytes(5642..5651) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(5652..5653) }], span: bytes(5651..5654) }, Punct { char: ';', spacing: Alone, span: bytes(5654..5655) }, Ident { sym: let, span: bytes(5664..5667) }, Ident { sym: line_end, span: bytes(5668..5676) }, Punct { char: '=', spacing: Alone, span: bytes(5677..5678) }, Ident { sym: headings, span: bytes(5679..5687) }, Punct { char: '.', spacing: Alone, span: bytes(5687..5688) }, Ident { sym: get, span: bytes(5688..5691) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: i, span: bytes(5692..5693) }, Punct { char: '+', spacing: Alone, span: bytes(5694..5695) }, Literal { lit: 1, span: bytes(5696..5697) }], span: bytes(5691..5698) }, Punct { char: '.', spacing: Alone, span: bytes(5698..5699) }, Ident { sym: map_or, span: bytes(5699..5705) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: i64, span: bytes(5719..5722) }, Punct { char: ':', spacing: Joint, span: bytes(5722..5723) }, Punct { char: ':', spacing: Alone, span: bytes(5723..5724) }, Ident { sym: try_from, span: bytes(5724..5732) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: content, span: bytes(5733..5740) }, Punct { char: '.', spacing: Alone, span: bytes(5740..5741) }, Ident { sym: lines, span: bytes(5741..5746) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5746..5748) }, Punct { char: '.', spacing: Alone, span: bytes(5748..5749) }, Ident { sym: count, span: bytes(5749..5754) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5754..5756) }], span: bytes(5732..5757) }, Punct { char: '.', spacing: Alone, span: bytes(5757..5758) }, Ident { sym: unwrap_or, span: bytes(5758..5767) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(5768..5769) }], span: bytes(5767..5770) }, Punct { char: ',', spacing: Alone, span: bytes(5770..5771) }, Punct { char: '|', spacing: Alone, span: bytes(5784..5785) }, Ident { sym: next, span: bytes(5785..5789) }, Punct { char: '|', spacing: Alone, span: bytes(5789..5790) }, Ident { sym: i64, span: bytes(5791..5794) }, Punct { char: ':', spacing: Joint, span: bytes(5794..5795) }, Punct { char: ':', spacing: Alone, span: bytes(5795..5796) }, Ident { sym: try_from, span: bytes(5796..5804) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: next, span: bytes(5805..5809) }, Punct { char: '.', spacing: Alone, span: bytes(5809..5810) }, Ident { sym: start_position, span: bytes(5810..5824) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5824..5826) }, Punct { char: '.', spacing: Alone, span: bytes(5826..5827) }, Ident { sym: row, span: bytes(5827..5830) }], span: bytes(5804..5831) }, Punct { char: '.', spacing: Alone, span: bytes(5831..5832) }, Ident { sym: unwrap_or, span: bytes(5832..5841) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(5842..5843) }], span: bytes(5841..5844) }, Punct { char: ',', spacing: Alone, span: bytes(5844..5845) }], span: bytes(5705..5855) }, Punct { char: ';', spacing: Alone, span: bytes(5855..5856) }, Ident { sym: let, span: bytes(5866..5869) }, Ident { sym: column_start, span: bytes(5870..5882) }, Punct { char: '=', spacing: Alone, span: bytes(5883..5884) }, Ident { sym: i64, span: bytes(5885..5888) }, Punct { char: ':', spacing: Joint, span: bytes(5888..5889) }, Punct { char: ':', spacing: Alone, span: bytes(5889..5890) }, Ident { sym: try_from, span: bytes(5890..5898) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: heading, span: bytes(5899..5906) }, Punct { char: '.', spacing: Alone, span: bytes(5906..5907) }, Ident { sym: start_position, span: bytes(5907..5921) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(5921..5923) }, Punct { char: '.', spacing: Alone, span: bytes(5923..5924) }, Ident { sym: column, span: bytes(5924..5930) }], span: bytes(5898..5931) }, Punct { char: '.', spacing: Alone, span: bytes(5931..5932) }, Ident { sym: unwrap_or, span: bytes(5932..5941) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(5942..5943) }], span: bytes(5941..5944) }, Punct { char: ';', spacing: Alone, span: bytes(5944..5945) }, Ident { sym: let, span: bytes(5954..5957) }, Ident { sym: column_end, span: bytes(5958..5968) }, Punct { char: '=', spacing: Alone, span: bytes(5969..5970) }, Ident { sym: i64, span: bytes(5971..5974) }, Punct { char: ':', spacing: Joint, span: bytes(5974..5975) }, Punct { char: ':', spacing: Alone, span: bytes(5975..5976) }, Ident { sym: try_from, span: bytes(5976..5984) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: heading, span: bytes(5985..5992) }, Punct { char: '.', spacing: Alone, span: bytes(5992..5993) }, Ident { sym: end_position, span: bytes(5993..6005) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6005..6007) }, Punct { char: '.', spacing: Alone, span: bytes(6007..6008) }, Ident { sym: column, span: bytes(6008..6014) }], span: bytes(5984..6015) }, Punct { char: '.', spacing: Alone, span: bytes(6015..6016) }, Ident { sym: unwrap_or, span: bytes(6016..6025) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(6026..6027) }], span: bytes(6025..6028) }, Punct { char: ';', spacing: Alone, span: bytes(6028..6029) }, Ident { sym: sections, span: bytes(6039..6047) }, Punct { char: '.', spacing: Alone, span: bytes(6047..6048) }, Ident { sym: push, span: bytes(6048..6052) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Section, span: bytes(6053..6060) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: title, span: bytes(6075..6080) }, Punct { char: ',', spacing: Alone, span: bytes(6080..6081) }, Ident { sym: level, span: bytes(6094..6099) }, Punct { char: ',', spacing: Alone, span: bytes(6099..6100) }, Ident { sym: line_start, span: bytes(6113..6123) }, Punct { char: ',', spacing: Alone, span: bytes(6123..6124) }, Ident { sym: line_end, span: bytes(6137..6145) }, Punct { char: ',', spacing: Alone, span: bytes(6145..6146) }, Ident { sym: column_start, span: bytes(6159..6171) }, Punct { char: ',', spacing: Alone, span: bytes(6171..6172) }, Ident { sym: column_end, span: bytes(6185..6195) }, Punct { char: ',', spacing: Alone, span: bytes(6195..6196) }, Ident { sym: byte_start, span: bytes(6209..6219) }, Punct { char: ',', spacing: Alone, span: bytes(6219..6220) }, Ident { sym: byte_end, span: bytes(6233..6241) }, Punct { char: ',', spacing: Alone, span: bytes(6241..6242) }, Ident { sym: file_path, span: bytes(6255..6264) }, Punct { char: ':', spacing: Alone, span: bytes(6264..6265) }, Ident { sym: file_path, span: bytes(6266..6275) }, Punct { char: '.', spacing: Alone, span: bytes(6275..6276) }, Ident { sym: to_string_lossy, span: bytes(6276..6291) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6291..6293) }, Punct { char: '.', spacing: Alone, span: bytes(6293..6294) }, Ident { sym: to_string, span: bytes(6294..6303) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6303..6305) }, Punct { char: ',', spacing: Alone, span: bytes(6305..6306) }, Ident { sym: parent_index, span: bytes(6319..6331) }, Punct { char: ':', spacing: Alone, span: bytes(6331..6332) }, Ident { sym: None, span: bytes(6333..6337) }, Punct { char: ',', spacing: Alone, span: bytes(6337..6338) }, Ident { sym: children_indices, span: bytes(6351..6367) }, Punct { char: ':', spacing: Alone, span: bytes(6367..6368) }, Ident { sym: Vec, span: bytes(6369..6372) }, Punct { char: ':', spacing: Joint, span: bytes(6372..6373) }, Punct { char: ':', spacing: Alone, span: bytes(6373..6374) }, Ident { sym: new, span: bytes(6374..6377) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6377..6379) }, Punct { char: ',', spacing: Alone, span: bytes(6379..6380) }, Ident { sym: section_content, span: bytes(6393..6408) }, Punct { char: ':', spacing: Alone, span: bytes(6408..6409) }, Ident { sym: None, span: bytes(6410..6414) }, Punct { char: ',', spacing: Alone, span: bytes(6414..6415) }, Ident { sym: chunk_type, span: bytes(6428..6438) }, Punct { char: ':', spacing: Alone, span: bytes(6438..6439) }, Ident { sym: None, span: bytes(6440..6444) }, Punct { char: ',', spacing: Alone, span: bytes(6444..6445) }, Ident { sym: lhs_content, span: bytes(6458..6469) }, Punct { char: ':', spacing: Alone, span: bytes(6469..6470) }, Ident { sym: None, span: bytes(6471..6475) }, Punct { char: ',', spacing: Alone, span: bytes(6475..6476) }, Ident { sym: rhs_content, span: bytes(6489..6500) }, Punct { char: ':', spacing: Alone, span: bytes(6500..6501) }, Ident { sym: None, span: bytes(6502..6506) }, Punct { char: ',', spacing: Alone, span: bytes(6506..6507) }], span: bytes(6061..6517) }], span: bytes(6052..6518) }, Punct { char: ';', spacing: Alone, span: bytes(6518..6519) }], span: bytes(3890..6525) }, Ident { sym: build_hierarchy, span: bytes(6571..6586) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(6587..6588) }, Ident { sym: mut, span: bytes(6588..6591) }, Ident { sym: sections, span: bytes(6592..6600) }], span: bytes(6586..6601) }, Punct { char: ';', spacing: Alone, span: bytes(6601..6602) }, Ident { sym: Ok, span: bytes(6608..6610) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: sections, span: bytes(6611..6619) }], span: bytes(6610..6620) }], span: bytes(2782..6622) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(6624..6626) }, string: "fn" }), name: Ident { sym: build_hierarchy, span: bytes(6627..6642) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: sections, span: bytes(6643..6651) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(6653..6654) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: mut, span: bytes(6654..6657) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: Section, span: bytes(6659..6666) }], span: bytes(6658..6667) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: None, where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(6675..6678) }, Ident { sym: mut, span: bytes(6679..6682) }, Ident { sym: stack, span: bytes(6683..6688) }, Punct { char: ':', spacing: Alone, span: bytes(6688..6689) }, Ident { sym: Vec, span: bytes(6690..6693) }, Punct { char: '<', spacing: Alone, span: bytes(6693..6694) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: usize, span: bytes(6695..6700) }, Punct { char: ',', spacing: Alone, span: bytes(6700..6701) }, Ident { sym: usize, span: bytes(6702..6707) }], span: bytes(6694..6708) }, Punct { char: '>', spacing: Alone, span: bytes(6708..6709) }, Punct { char: '=', spacing: Alone, span: bytes(6710..6711) }, Ident { sym: Vec, span: bytes(6712..6715) }, Punct { char: ':', spacing: Joint, span: bytes(6715..6716) }, Punct { char: ':', spacing: Alone, span: bytes(6716..6717) }, Ident { sym: new, span: bytes(6717..6720) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6720..6722) }, Punct { char: ';', spacing: Alone, span: bytes(6722..6723) }, Ident { sym: for, span: bytes(6747..6750) }, Ident { sym: i, span: bytes(6751..6752) }, Ident { sym: in, span: bytes(6753..6755) }, Literal { lit: 0, span: bytes(6756..6757) }, Punct { char: '.', spacing: Joint, span: bytes(6757..6758) }, Punct { char: '.', spacing: Alone, span: bytes(6758..6759) }, Ident { sym: sections, span: bytes(6759..6767) }, Punct { char: '.', spacing: Alone, span: bytes(6767..6768) }, Ident { sym: len, span: bytes(6768..6771) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6771..6773) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(6784..6787) }, Ident { sym: current_level, span: bytes(6788..6801) }, Punct { char: '=', spacing: Alone, span: bytes(6802..6803) }, Ident { sym: sections, span: bytes(6804..6812) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: i, span: bytes(6813..6814) }], span: bytes(6812..6815) }, Punct { char: '.', spacing: Alone, span: bytes(6815..6816) }, Ident { sym: level, span: bytes(6816..6821) }, Punct { char: ';', spacing: Alone, span: bytes(6821..6822) }, Ident { sym: while, span: bytes(6880..6885) }, Ident { sym: let, span: bytes(6886..6889) }, Ident { sym: Some, span: bytes(6890..6894) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(6895..6896) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: _, span: bytes(6897..6898) }, Punct { char: ',', spacing: Alone, span: bytes(6898..6899) }, Ident { sym: parent_level, span: bytes(6900..6912) }], span: bytes(6896..6913) }], span: bytes(6894..6914) }, Punct { char: '=', spacing: Alone, span: bytes(6915..6916) }, Ident { sym: stack, span: bytes(6917..6922) }, Punct { char: '.', spacing: Alone, span: bytes(6922..6923) }, Ident { sym: last, span: bytes(6923..6927) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6927..6929) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(6944..6946) }, Ident { sym: parent_level, span: bytes(6947..6959) }, Punct { char: '<', spacing: Alone, span: bytes(6960..6961) }, Ident { sym: current_level, span: bytes(6962..6975) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: break, span: bytes(6994..6999) }, Punct { char: ';', spacing: Alone, span: bytes(6999..7000) }], span: bytes(6976..7014) }, Ident { sym: stack, span: bytes(7027..7032) }, Punct { char: '.', spacing: Alone, span: bytes(7032..7033) }, Ident { sym: pop, span: bytes(7033..7036) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(7036..7038) }, Punct { char: ';', spacing: Alone, span: bytes(7038..7039) }], span: bytes(6930..7049) }, Ident { sym: if, span: bytes(7094..7096) }, Ident { sym: let, span: bytes(7097..7100) }, Ident { sym: Some, span: bytes(7101..7105) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(7106..7107) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: parent_idx, span: bytes(7108..7118) }, Punct { char: ',', spacing: Alone, span: bytes(7118..7119) }, Ident { sym: _, span: bytes(7120..7121) }], span: bytes(7107..7122) }], span: bytes(7105..7123) }, Punct { char: '=', spacing: Alone, span: bytes(7124..7125) }, Ident { sym: stack, span: bytes(7126..7131) }, Punct { char: '.', spacing: Alone, span: bytes(7131..7132) }, Ident { sym: last, span: bytes(7132..7136) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(7136..7138) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: sections, span: bytes(7153..7161) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: i, span: bytes(7162..7163) }], span: bytes(7161..7164) }, Punct { char: '.', spacing: Alone, span: bytes(7164..7165) }, Ident { sym: parent_index, span: bytes(7165..7177) }, Punct { char: '=', spacing: Alone, span: bytes(7178..7179) }, Ident { sym: Some, span: bytes(7180..7184) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: parent_idx, span: bytes(7185..7195) }], span: bytes(7184..7196) }, Punct { char: ';', spacing: Alone, span: bytes(7196..7197) }, Ident { sym: sections, span: bytes(7210..7218) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: parent_idx, span: bytes(7219..7229) }], span: bytes(7218..7230) }, Punct { char: '.', spacing: Alone, span: bytes(7230..7231) }, Ident { sym: children_indices, span: bytes(7231..7247) }, Punct { char: '.', spacing: Alone, span: bytes(7247..7248) }, Ident { sym: push, span: bytes(7248..7252) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: i, span: bytes(7253..7254) }], span: bytes(7252..7255) }, Punct { char: ';', spacing: Alone, span: bytes(7255..7256) }], span: bytes(7139..7266) }, Ident { sym: stack, span: bytes(7276..7281) }, Punct { char: '.', spacing: Alone, span: bytes(7281..7282) }, Ident { sym: push, span: bytes(7282..7286) }, Group { delimiter: Parenthesis, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: i, span: bytes(7288..7289) }, Punct { char: ',', spacing: Alone, span: bytes(7289..7290) }, Ident { sym: current_level, span: bytes(7291..7304) }], span: bytes(7287..7305) }], span: bytes(7286..7306) }, Punct { char: ';', spacing: Alone, span: bytes(7306..7307) }], span: bytes(6774..7313) }], span: bytes(6669..7315) }) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: '#', spacing: Alone, span: bytes(7317..7318) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: cfg, span: bytes(7319..7322) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: test, span: bytes(7323..7327) }], span: bytes(7322..7328) }], span: bytes(7318..7329) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: '#', spacing: Alone, span: bytes(7330..7331) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: path, span: bytes(7332..7336) }, Punct { char: '=', spacing: Alone, span: bytes(7337..7338) }, Literal { lit: "tests/input.rs", span: bytes(7339..7355) }], span: bytes(7331..7356) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(7357..7360) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: tests, span: bytes(7361..7366) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(7366..7367) })
[SYNCDOC DEBUG] 
=== REFORMAT START ===
[SYNCDOC DEBUG] Original length: 7367
[SYNCDOC DEBUG] Transformed length: 5211
[SYNCDOC DEBUG] Formatted original length: 7367
[SYNCDOC DEBUG] Formatted transformed length: 6220
[SYNCDOC DEBUG] 
--- Formatted Original ---
[SYNCDOC DEBUG] //! Document discovery and section extraction using tree-sitter.
//!
//! This module handles finding markdown files in the filesystem and parsing
//! them with tree-sitter queries to extract section hierarchies.

use crate::formats::Format;
use crate::section::Section;
use std::fs;
use std::io;
use std::path::{Path, PathBuf};
use streaming_iterator::StreamingIterator;
use tree_sitter::{Parser, Query, QueryCursor};

/// Find documents matching the given extensions.
///
/// If paths is empty, scans the current directory recursively.
/// Skips common build/dependency directories.
///
/// # Errors
///
/// Returns an error if directory traversal fails.
pub fn find_documents(paths: Vec<PathBuf>, extensions: &[String]) -> io::Result<Vec<PathBuf>> {
    if paths.is_empty() {
        find_in_directory(Path::new("."), extensions)
    } else {
        let mut results = Vec::new();
        for path in paths {
            if path.is_file() {
                if let Some(ext) = path.extension() {
                    if extensions
                        .iter()
                        .any(|e| e == ext.to_string_lossy().as_ref())
                    {
                        results.push(path);
                    }
                }
            } else if path.is_dir() {
                results.extend(find_in_directory(&path, extensions)?);
            }
        }
        Ok(results)
    }
}

fn find_in_directory(dir: &Path, extensions: &[String]) -> io::Result<Vec<PathBuf>> {
    let mut results = Vec::new();

    if let Ok(entries) = fs::read_dir(dir) {
        for entry in entries.flatten() {
            let path = entry.path();

            if path.is_dir() {
                if let Some(name) = path.file_name() {
                    let name_str = name.to_string_lossy();
                    if ["target", "dist", ".git", "node_modules"].contains(&name_str.as_ref()) {
                        continue;
                    }
                }
                results.extend(find_in_directory(&path, extensions)?);
            } else if path.is_file() {
                if let Some(ext) = path.extension() {
                    if extensions
                        .iter()
                        .any(|e| e == ext.to_string_lossy().as_ref())
                    {
                        results.push(path);
                    }
                }
            }
        }
    }

    Ok(results)
}

/// Extract sections from a document using tree-sitter.
///
/// Parses the file with the given format and extracts all sections,
/// building parent/child relationships based on heading levels.
///
/// # Errors
///
/// Returns an error if file reading or parsing fails.
pub fn extract_sections<F: Format>(file_path: &Path, format: &F) -> io::Result<Vec<Section>> {
    let content = fs::read_to_string(file_path)?;

    let mut parser = Parser::new();
    parser
        .set_language(&format.language())
        .map_err(|e| io::Error::other(format!("Language error: {e}")))?;

    let tree = parser
        .parse(&content, None)
        .ok_or_else(|| io::Error::other("Parse failed"))?;

    let section_query = Query::new(&format.language(), format.section_query())
        .map_err(|e| io::Error::other(format!("Query error: {e}")))?;

    let title_query = Query::new(&format.language(), format.title_query())
        .map_err(|e| io::Error::other(format!("Query error: {e}")))?;

    // Collect all heading nodes by traversing the entire tree
    let mut headings: Vec<tree_sitter::Node> = Vec::new();
    let mut cursor = QueryCursor::new();
    let mut matches = cursor.matches(&section_query, tree.root_node(), content.as_bytes());

    while let Some(m) = matches.next() {
        if let Some(c) = m.captures.first() {
            headings.push(c.node);
        }
    }

    let mut sections = Vec::new();

    for (i, heading) in headings.iter().enumerate() {
        // Determine level from the heading marker child node
        let mut level = 1;
        let mut heading_cursor = heading.walk();
        if heading_cursor.goto_first_child() {
            loop {
                let node = heading_cursor.node();
                let kind = node.kind();
                // Match atx_h1_marker, atx_h2_marker, etc.
                if kind.starts_with("atx_h") && kind.ends_with("_marker") {
                    if let Some(level_char) = kind.chars().nth(5) {
                        level = level_char.to_digit(10).unwrap_or(1) as usize;
                    }
                    break;
                }
                if !heading_cursor.goto_next_sibling() {
                    break;
                }
            }
        }

        // Extract title using query
        let mut title_cursor = QueryCursor::new();
        let mut title = String::from("Untitled");
        let mut title_matches = title_cursor.matches(&title_query, *heading, content.as_bytes());
        while let Some(m) = title_matches.next() {
            if let Some(c) = m
                .captures
                .iter()
                .find(|c| title_query.capture_names()[c.index as usize] == "title")
            {
                title = content[c.node.byte_range()].trim().to_string();
                break;
            }
        }

        // Calculate byte range (content only, after heading line)
        let byte_start = heading.end_byte();
        let byte_end = headings
            .get(i + 1)
            .map_or(content.len(), tree_sitter::Node::start_byte);

        // Calculate line coordinates
        // Around line 100-110 in extract_sections
        let line_start = i64::try_from(heading.end_position().row).unwrap_or(0);
        let line_end = headings.get(i + 1).map_or(
            i64::try_from(content.lines().count()).unwrap_or(0),
            |next| i64::try_from(next.start_position().row).unwrap_or(0),
        );

        let column_start = i64::try_from(heading.start_position().column).unwrap_or(0);
        let column_end = i64::try_from(heading.end_position().column).unwrap_or(0);

        sections.push(Section {
            title,
            level,
            line_start,
            line_end,
            column_start,
            column_end,
            byte_start,
            byte_end,
            file_path: file_path.to_string_lossy().to_string(),
            parent_index: None,
            children_indices: Vec::new(),
            section_content: None,
            chunk_type: None,
            lhs_content: None,
            rhs_content: None,
        });
    }

    // Build parent/child relationships
    build_hierarchy(&mut sections);

    Ok(sections)
}

fn build_hierarchy(sections: &mut [Section]) {
    let mut stack: Vec<(usize, usize)> = Vec::new(); // (index, level)

    for i in 0..sections.len() {
        let current_level = sections[i].level;

        // Pop stack until we find parent level
        while let Some(&(_, parent_level)) = stack.last() {
            if parent_level < current_level {
                break;
            }
            stack.pop();
        }

        // Set parent relationship
        if let Some(&(parent_idx, _)) = stack.last() {
            sections[i].parent_index = Some(parent_idx);
            sections[parent_idx].children_indices.push(i);
        }

        stack.push((i, current_level));
    }
}

#[cfg(test)]
#[path = "tests/input.rs"]
mod tests;

[SYNCDOC DEBUG] 
--- Formatted Transformed ---
[SYNCDOC DEBUG] # ! [doc = syncdoc :: module_doc ! ()]
use crate::formats::Format;
use crate::section::Section;
use std::fs;
use std::io;
use std::path::{Path, PathBuf};
use streaming_iterator::StreamingIterator;
use tree_sitter::{Parser, Query, QueryCursor};
#[syncdoc::omnidoc]
pub fn find_documents(paths: Vec<PathBuf>, extensions: &[String]) -> io::Result<Vec<PathBuf>> {
    if paths.is_empty() {
        find_in_directory(Path::new("."), extensions)
    } else {
        let mut results = Vec::new();
        for path in paths {
            if path.is_file() {
                if let Some(ext) = path.extension() {
                    if extensions
                        .iter()
                        .any(|e| e == ext.to_string_lossy().as_ref())
                    {
                        results.push(path);
                    }
                }
            } else if path.is_dir() {
                results.extend(find_in_directory(&path, extensions)?);
            }
        }
        Ok(results)
    }
}
#[syncdoc::omnidoc]
fn find_in_directory(dir: &Path, extensions: &[String]) -> io::Result<Vec<PathBuf>> {
    let mut results = Vec::new();
    if let Ok(entries) = fs::read_dir(dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            if path.is_dir() {
                if let Some(name) = path.file_name() {
                    let name_str = name.to_string_lossy();
                    if ["target", "dist", ".git", "node_modules"].contains(&name_str.as_ref()) {
                        continue;
                    }
                }
                results.extend(find_in_directory(&path, extensions)?);
            } else if path.is_file() {
                if let Some(ext) = path.extension() {
                    if extensions
                        .iter()
                        .any(|e| e == ext.to_string_lossy().as_ref())
                    {
                        results.push(path);
                    }
                }
            }
        }
    }
    Ok(results)
}
#[syncdoc::omnidoc]
pub fn extract_sections<F: Format>(file_path: &Path, format: &F) -> io::Result<Vec<Section>> {
    let content = fs::read_to_string(file_path)?;
    let mut parser = Parser::new();
    parser
        .set_language(&format.language())
        .map_err(|e| io::Error::other(format!("Language error: {e}")))?;
    let tree = parser
        .parse(&content, None)
        .ok_or_else(|| io::Error::other("Parse failed"))?;
    let section_query = Query::new(&format.language(), format.section_query())
        .map_err(|e| io::Error::other(format!("Query error: {e}")))?;
    let title_query = Query::new(&format.language(), format.title_query())
        .map_err(|e| io::Error::other(format!("Query error: {e}")))?;
    let mut headings: Vec<tree_sitter::Node> = Vec::new();
    let mut cursor = QueryCursor::new();
    let mut matches = cursor.matches(&section_query, tree.root_node(), content.as_bytes());
    while let Some(m) = matches.next() {
        if let Some(c) = m.captures.first() {
            headings.push(c.node);
        }
    }
    let mut sections = Vec::new();
    for (i, heading) in headings.iter().enumerate() {
        let mut level = 1;
        let mut heading_cursor = heading.walk();
        if heading_cursor.goto_first_child() {
            loop {
                let node = heading_cursor.node();
                let kind = node.kind();
                if kind.starts_with("atx_h") && kind.ends_with("_marker") {
                    if let Some(level_char) = kind.chars().nth(5) {
                        level = level_char.to_digit(10).unwrap_or(1) as usize;
                    }
                    break;
                }
                if !heading_cursor.goto_next_sibling() {
                    break;
                }
            }
        }
        let mut title_cursor = QueryCursor::new();
        let mut title = String::from("Untitled");
        let mut title_matches = title_cursor.matches(&title_query, *heading, content.as_bytes());
        while let Some(m) = title_matches.next() {
            if let Some(c) = m
                .captures
                .iter()
                .find(|c| title_query.capture_names()[c.index as usize] == "title")
            {
                title = content[c.node.byte_range()].trim().to_string();
                break;
            }
        }
        let byte_start = heading.end_byte();
        let byte_end = headings
            .get(i + 1)
            .map_or(content.len(), tree_sitter::Node::start_byte);
        let line_start = i64::try_from(heading.end_position().row).unwrap_or(0);
        let line_end = headings.get(i + 1).map_or(
            i64::try_from(content.lines().count()).unwrap_or(0),
            |next| i64::try_from(next.start_position().row).unwrap_or(0),
        );
        let column_start = i64::try_from(heading.start_position().column).unwrap_or(0);
        let column_end = i64::try_from(heading.end_position().column).unwrap_or(0);
        sections.push(Section {
            title,
            level,
            line_start,
            line_end,
            column_start,
            column_end,
            byte_start,
            byte_end,
            file_path: file_path.to_string_lossy().to_string(),
            parent_index: None,
            children_indices: Vec::new(),
            section_content: None,
            chunk_type: None,
            lhs_content: None,
            rhs_content: None,
        });
    }
    build_hierarchy(&mut sections);
    Ok(sections)
}
#[syncdoc::omnidoc]
fn build_hierarchy(sections: &mut [Section]) {
    let mut stack: Vec<(usize, usize)> = Vec::new();
    for i in 0..sections.len() {
        let current_level = sections[i].level;
        while let Some(&(_, parent_level)) = stack.last() {
            if parent_level < current_level {
                break;
            }
            stack.pop();
        }
        if let Some(&(parent_idx, _)) = stack.last() {
            sections[i].parent_index = Some(parent_idx);
            sections[parent_idx].children_indices.push(i);
        }
        stack.push((i, current_level));
    }
}
#[cfg(test)]
#[path = "tests/input.rs"]
mod tests;

[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 219
[SYNCDOC DEBUG] After lines: 166
[SYNCDOC DEBUG] Hunks: 30
[SYNCDOC DEBUG] Hunk 0: before[0..5] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! Document discovery and section extraction using tree-sitter."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module handles finding markdown files in the filesystem and parsing"
[SYNCDOC DEBUG]     [3]: "//! them with tree-sitter queries to extract section hierarchies."
[SYNCDOC DEBUG]     [4]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[12..21] -> after[8..9]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [12]: ""
[SYNCDOC DEBUG]     [13]: "/// Find documents matching the given extensions."
[SYNCDOC DEBUG]     [14]: "///"
[SYNCDOC DEBUG]     [15]: "/// If paths is empty, scans the current directory recursively."
[SYNCDOC DEBUG]     [16]: "/// Skips common build/dependency directories."
[SYNCDOC DEBUG]     [17]: "///"
[SYNCDOC DEBUG]     [18]: "/// # Errors"
[SYNCDOC DEBUG]     [19]: "///"
[SYNCDOC DEBUG]     [20]: "/// Returns an error if directory traversal fails."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [8]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[43..44] -> after[31..32]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [43]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [31]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 3: before[46..47] -> after[34..34]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [46]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 4: before[50..51] -> after[37..37]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [50]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[71..72] -> after[57..57]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [71]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[74..83] -> after[59..60]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [74]: ""
[SYNCDOC DEBUG]     [75]: "/// Extract sections from a document using tree-sitter."
[SYNCDOC DEBUG]     [76]: "///"
[SYNCDOC DEBUG]     [77]: "/// Parses the file with the given format and extracts all sections,"
[SYNCDOC DEBUG]     [78]: "/// building parent/child relationships based on heading levels."
[SYNCDOC DEBUG]     [79]: "///"
[SYNCDOC DEBUG]     [80]: "/// # Errors"
[SYNCDOC DEBUG]     [81]: "///"
[SYNCDOC DEBUG]     [82]: "/// Returns an error if file reading or parsing fails."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [59]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 7: before[85..86] -> after[62..62]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [85]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 8: before[90..91] -> after[66..66]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [90]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 9: before[94..95] -> after[69..69]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [94]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 10: before[97..98] -> after[71..71]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [97]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 11: before[100..102] -> after[73..73]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [100]: ""
[SYNCDOC DEBUG]     [101]: "    // Collect all heading nodes by traversing the entire tree"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 12: before[105..106] -> after[76..76]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [105]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 13: before[111..112] -> after[81..81]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [111]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 14: before[113..114] -> after[82..82]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [113]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 15: before[115..116] -> after[83..83]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [115]: "        // Determine level from the heading marker child node"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 16: before[122..123] -> after[89..89]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [122]: "                // Match atx_h1_marker, atx_h2_marker, etc."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 17: before[134..136] -> after[100..100]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [134]: ""
[SYNCDOC DEBUG]     [135]: "        // Extract title using query"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 18: before[149..151] -> after[113..113]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [149]: ""
[SYNCDOC DEBUG]     [150]: "        // Calculate byte range (content only, after heading line)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 19: before[155..158] -> after[117..117]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [155]: ""
[SYNCDOC DEBUG]     [156]: "        // Calculate line coordinates"
[SYNCDOC DEBUG]     [157]: "        // Around line 100-110 in extract_sections"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 20: before[163..164] -> after[122..122]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [163]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 21: before[166..167] -> after[124..124]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [166]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 22: before[185..187] -> after[142..142]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [185]: ""
[SYNCDOC DEBUG]     [186]: "    // Build parent/child relationships"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 23: before[188..189] -> after[143..143]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [188]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 24: before[191..192] -> after[145..146]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [191]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [145]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 25: before[193..195] -> after[147..148]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [193]: "    let mut stack: Vec<(usize, usize)> = Vec::new(); // (index, level)"
[SYNCDOC DEBUG]     [194]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [147]: "    let mut stack: Vec<(usize, usize)> = Vec::new();"
[SYNCDOC DEBUG] Hunk 26: before[197..199] -> after[150..150]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [197]: ""
[SYNCDOC DEBUG]     [198]: "        // Pop stack until we find parent level"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 27: before[205..207] -> after[156..156]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [205]: ""
[SYNCDOC DEBUG]     [206]: "        // Set parent relationship"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 28: before[211..212] -> after[160..160]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [211]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 29: before[215..216] -> after[163..163]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [215]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] DEBUG restore: Found 30 hunks
[SYNCDOC DEBUG]   Hunk 0: before[0..5] after[0..1]
[SYNCDOC DEBUG]   Hunk 1: before[12..21] after[8..9]
[SYNCDOC DEBUG]   Hunk 2: before[43..44] after[31..32]
[SYNCDOC DEBUG]   Hunk 3: before[46..47] after[34..34]
[SYNCDOC DEBUG]   Hunk 4: before[50..51] after[37..37]
[SYNCDOC DEBUG]   Hunk 5: before[71..72] after[57..57]
[SYNCDOC DEBUG]   Hunk 6: before[74..83] after[59..60]
[SYNCDOC DEBUG]   Hunk 7: before[85..86] after[62..62]
[SYNCDOC DEBUG]   Hunk 8: before[90..91] after[66..66]
[SYNCDOC DEBUG]   Hunk 9: before[94..95] after[69..69]
[SYNCDOC DEBUG]   Hunk 10: before[97..98] after[71..71]
[SYNCDOC DEBUG]   Hunk 11: before[100..102] after[73..73]
[SYNCDOC DEBUG]   Hunk 12: before[105..106] after[76..76]
[SYNCDOC DEBUG]   Hunk 13: before[111..112] after[81..81]
[SYNCDOC DEBUG]   Hunk 14: before[113..114] after[82..82]
[SYNCDOC DEBUG]   Hunk 15: before[115..116] after[83..83]
[SYNCDOC DEBUG]   Hunk 16: before[122..123] after[89..89]
[SYNCDOC DEBUG]   Hunk 17: before[134..136] after[100..100]
[SYNCDOC DEBUG]   Hunk 18: before[149..151] after[113..113]
[SYNCDOC DEBUG]   Hunk 19: before[155..158] after[117..117]
[SYNCDOC DEBUG]   Hunk 20: before[163..164] after[122..122]
[SYNCDOC DEBUG]   Hunk 21: before[166..167] after[124..124]
[SYNCDOC DEBUG]   Hunk 22: before[185..187] after[142..142]
[SYNCDOC DEBUG]   Hunk 23: before[188..189] after[143..143]
[SYNCDOC DEBUG]   Hunk 24: before[191..192] after[145..146]
[SYNCDOC DEBUG]   Hunk 25: before[193..195] after[147..148]
[SYNCDOC DEBUG]   Hunk 26: before[197..199] after[150..150]
[SYNCDOC DEBUG]   Hunk 27: before[205..207] after[156..156]
[SYNCDOC DEBUG]   Hunk 28: before[211..212] after[160..160]
[SYNCDOC DEBUG]   Hunk 29: before[215..216] after[163..163]
[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 219
[SYNCDOC DEBUG] After lines: 166
[SYNCDOC DEBUG] Hunks: 30
[SYNCDOC DEBUG] Hunk 0: before[0..5] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! Document discovery and section extraction using tree-sitter."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module handles finding markdown files in the filesystem and parsing"
[SYNCDOC DEBUG]     [3]: "//! them with tree-sitter queries to extract section hierarchies."
[SYNCDOC DEBUG]     [4]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[12..21] -> after[8..9]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [12]: ""
[SYNCDOC DEBUG]     [13]: "/// Find documents matching the given extensions."
[SYNCDOC DEBUG]     [14]: "///"
[SYNCDOC DEBUG]     [15]: "/// If paths is empty, scans the current directory recursively."
[SYNCDOC DEBUG]     [16]: "/// Skips common build/dependency directories."
[SYNCDOC DEBUG]     [17]: "///"
[SYNCDOC DEBUG]     [18]: "/// # Errors"
[SYNCDOC DEBUG]     [19]: "///"
[SYNCDOC DEBUG]     [20]: "/// Returns an error if directory traversal fails."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [8]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[43..44] -> after[31..32]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [43]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [31]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 3: before[46..47] -> after[34..34]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [46]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 4: before[50..51] -> after[37..37]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [50]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[71..72] -> after[57..57]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [71]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[74..83] -> after[59..60]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [74]: ""
[SYNCDOC DEBUG]     [75]: "/// Extract sections from a document using tree-sitter."
[SYNCDOC DEBUG]     [76]: "///"
[SYNCDOC DEBUG]     [77]: "/// Parses the file with the given format and extracts all sections,"
[SYNCDOC DEBUG]     [78]: "/// building parent/child relationships based on heading levels."
[SYNCDOC DEBUG]     [79]: "///"
[SYNCDOC DEBUG]     [80]: "/// # Errors"
[SYNCDOC DEBUG]     [81]: "///"
[SYNCDOC DEBUG]     [82]: "/// Returns an error if file reading or parsing fails."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [59]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 7: before[85..86] -> after[62..62]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [85]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 8: before[90..91] -> after[66..66]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [90]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 9: before[94..95] -> after[69..69]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [94]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 10: before[97..98] -> after[71..71]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [97]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 11: before[100..102] -> after[73..73]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [100]: ""
[SYNCDOC DEBUG]     [101]: "    // Collect all heading nodes by traversing the entire tree"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 12: before[105..106] -> after[76..76]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [105]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 13: before[111..112] -> after[81..81]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [111]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 14: before[113..114] -> after[82..82]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [113]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 15: before[115..116] -> after[83..83]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [115]: "        // Determine level from the heading marker child node"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 16: before[122..123] -> after[89..89]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [122]: "                // Match atx_h1_marker, atx_h2_marker, etc."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 17: before[134..136] -> after[100..100]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [134]: ""
[SYNCDOC DEBUG]     [135]: "        // Extract title using query"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 18: before[149..151] -> after[113..113]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [149]: ""
[SYNCDOC DEBUG]     [150]: "        // Calculate byte range (content only, after heading line)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 19: before[155..158] -> after[117..117]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [155]: ""
[SYNCDOC DEBUG]     [156]: "        // Calculate line coordinates"
[SYNCDOC DEBUG]     [157]: "        // Around line 100-110 in extract_sections"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 20: before[163..164] -> after[122..122]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [163]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 21: before[166..167] -> after[124..124]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [166]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 22: before[185..187] -> after[142..142]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [185]: ""
[SYNCDOC DEBUG]     [186]: "    // Build parent/child relationships"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 23: before[188..189] -> after[143..143]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [188]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 24: before[191..192] -> after[145..146]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [191]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [145]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 25: before[193..195] -> after[147..148]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [193]: "    let mut stack: Vec<(usize, usize)> = Vec::new(); // (index, level)"
[SYNCDOC DEBUG]     [194]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [147]: "    let mut stack: Vec<(usize, usize)> = Vec::new();"
[SYNCDOC DEBUG] Hunk 26: before[197..199] -> after[150..150]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [197]: ""
[SYNCDOC DEBUG]     [198]: "        // Pop stack until we find parent level"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 27: before[205..207] -> after[156..156]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [205]: ""
[SYNCDOC DEBUG]     [206]: "        // Set parent relationship"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 28: before[211..212] -> after[160..160]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [211]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 29: before[215..216] -> after[163..163]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [215]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 0..5 (adds 1 lines, removes 5 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 12..21 (adds 1 lines, removes 9 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 43..44 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 46..47
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 50..51
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 71..72
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 74..83 (adds 1 lines, removes 9 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 85..86
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 90..91
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 94..95
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 97..98
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 100..102
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 105..106
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 111..112
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 113..114
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 115..116
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 122..123
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 134..136
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 149..151
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 155..158
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 163..164
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 166..167
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 185..187
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 188..189
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 191..192 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 193..195
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 197..199
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 205..207
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 211..212
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 215..216
[SYNCDOC DEBUG] Original != Result: true
[SYNCDOC DEBUG] 
=== BOOKEND DEBUG START ===
[SYNCDOC DEBUG] Input code length: 6766
[SYNCDOC DEBUG] 
Line 0: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       -> Starts with #!
[SYNCDOC DEBUG]       -> Checking trigger "syncdoc::module_doc!": true
[SYNCDOC DEBUG]       -> Has trigger: true
[SYNCDOC DEBUG]   -> NEEDS BOOKENDING
[SYNCDOC DEBUG]     reformat_line for: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     extract_bookend_content:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       Found #![ at position: 0
[SYNCDOC DEBUG]       Found ] at position: 29
[SYNCDOC DEBUG]       Extracted content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Got content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Created bookended expr: "const _: i32 = { doc=syncdoc::module_doc!() };"
[SYNCDOC DEBUG]     Rustfmt output: "const _: i32 = { doc = syncdoc::module_doc!() };\n"
[SYNCDOC DEBUG]     Stripped bookends: "doc = syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Final result: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG]   -> Reformatted to: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG] 
Line 1: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 2: "use crate::formats::Format;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use crate::formats::Format;"
[SYNCDOC DEBUG]       no_spaces: "usecrate::formats::Format;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 3: "use crate::section::Section;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use crate::section::Section;"
[SYNCDOC DEBUG]       no_spaces: "usecrate::section::Section;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 4: "use std::fs;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::fs;"
[SYNCDOC DEBUG]       no_spaces: "usestd::fs;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 5: "use std::io;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::io;"
[SYNCDOC DEBUG]       no_spaces: "usestd::io;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 6: "use std::path::{Path, PathBuf};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::path::{Path, PathBuf};"
[SYNCDOC DEBUG]       no_spaces: "usestd::path::{Path,PathBuf};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 7: "use streaming_iterator::StreamingIterator;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use streaming_iterator::StreamingIterator;"
[SYNCDOC DEBUG]       no_spaces: "usestreaming_iterator::StreamingIterator;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 8: "use tree_sitter::{Parser, Query, QueryCursor};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use tree_sitter::{Parser, Query, QueryCursor};"
[SYNCDOC DEBUG]       no_spaces: "usetree_sitter::{Parser,Query,QueryCursor};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 9: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 10: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 11: "pub fn find_documents(paths: Vec<PathBuf>, extensions: &[String]) -> io::Result<Vec<PathBuf>> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub fn find_documents(paths: Vec<PathBuf>, extensions: &[String]) -> io::Result<Vec<PathBuf>> {"
[SYNCDOC DEBUG]       no_spaces: "pubfnfind_documents(paths:Vec<PathBuf>,extensions:&[String])->io::Result<Vec<PathBuf>>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 12: "    if paths.is_empty() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if paths.is_empty() {"
[SYNCDOC DEBUG]       no_spaces: "ifpaths.is_empty(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 13: "        find_in_directory(Path::new(\".\"), extensions)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "find_in_directory(Path::new(\".\"), extensions)"
[SYNCDOC DEBUG]       no_spaces: "find_in_directory(Path::new(\".\"),extensions)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 14: "    } else {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else {"
[SYNCDOC DEBUG]       no_spaces: "}else{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 15: "        let mut results = Vec::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut results = Vec::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutresults=Vec::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 16: "        for path in paths {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for path in paths {"
[SYNCDOC DEBUG]       no_spaces: "forpathinpaths{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 17: "            if path.is_file() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if path.is_file() {"
[SYNCDOC DEBUG]       no_spaces: "ifpath.is_file(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 18: "                if let Some(ext) = path.extension() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(ext) = path.extension() {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(ext)=path.extension(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 19: "                    if extensions"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if extensions"
[SYNCDOC DEBUG]       no_spaces: "ifextensions"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 20: "                        .iter()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".iter()"
[SYNCDOC DEBUG]       no_spaces: ".iter()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 21: "                        .any(|e| e == ext.to_string_lossy().as_ref())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".any(|e| e == ext.to_string_lossy().as_ref())"
[SYNCDOC DEBUG]       no_spaces: ".any(|e|e==ext.to_string_lossy().as_ref())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 22: "                    {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "{"
[SYNCDOC DEBUG]       no_spaces: "{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 23: "                        results.push(path);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "results.push(path);"
[SYNCDOC DEBUG]       no_spaces: "results.push(path);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 24: "                    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 25: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 26: "            } else if path.is_dir() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else if path.is_dir() {"
[SYNCDOC DEBUG]       no_spaces: "}elseifpath.is_dir(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 27: "                results.extend(find_in_directory(&path, extensions)?);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "results.extend(find_in_directory(&path, extensions)?);"
[SYNCDOC DEBUG]       no_spaces: "results.extend(find_in_directory(&path,extensions)?);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 28: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 29: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 30: "        Ok(results)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Ok(results)"
[SYNCDOC DEBUG]       no_spaces: "Ok(results)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 31: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 32: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 33: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 34: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 35: "fn find_in_directory(dir: &Path, extensions: &[String]) -> io::Result<Vec<PathBuf>> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn find_in_directory(dir: &Path, extensions: &[String]) -> io::Result<Vec<PathBuf>> {"
[SYNCDOC DEBUG]       no_spaces: "fnfind_in_directory(dir:&Path,extensions:&[String])->io::Result<Vec<PathBuf>>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 36: "    let mut results = Vec::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut results = Vec::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutresults=Vec::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 37: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 38: "    if let Ok(entries) = fs::read_dir(dir) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Ok(entries) = fs::read_dir(dir) {"
[SYNCDOC DEBUG]       no_spaces: "ifletOk(entries)=fs::read_dir(dir){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 39: "        for entry in entries.flatten() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for entry in entries.flatten() {"
[SYNCDOC DEBUG]       no_spaces: "forentryinentries.flatten(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 40: "            let path = entry.path();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let path = entry.path();"
[SYNCDOC DEBUG]       no_spaces: "letpath=entry.path();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 41: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 42: "            if path.is_dir() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if path.is_dir() {"
[SYNCDOC DEBUG]       no_spaces: "ifpath.is_dir(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 43: "                if let Some(name) = path.file_name() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(name) = path.file_name() {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(name)=path.file_name(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 44: "                    let name_str = name.to_string_lossy();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let name_str = name.to_string_lossy();"
[SYNCDOC DEBUG]       no_spaces: "letname_str=name.to_string_lossy();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 45: "                    if [\"target\", \"dist\", \".git\", \"node_modules\"].contains(&name_str.as_ref()) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if [\"target\", \"dist\", \".git\", \"node_modules\"].contains(&name_str.as_ref()) {"
[SYNCDOC DEBUG]       no_spaces: "if[\"target\",\"dist\",\".git\",\"node_modules\"].contains(&name_str.as_ref()){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 46: "                        continue;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "continue;"
[SYNCDOC DEBUG]       no_spaces: "continue;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 47: "                    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 48: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 49: "                results.extend(find_in_directory(&path, extensions)?);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "results.extend(find_in_directory(&path, extensions)?);"
[SYNCDOC DEBUG]       no_spaces: "results.extend(find_in_directory(&path,extensions)?);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 50: "            } else if path.is_file() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else if path.is_file() {"
[SYNCDOC DEBUG]       no_spaces: "}elseifpath.is_file(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 51: "                if let Some(ext) = path.extension() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(ext) = path.extension() {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(ext)=path.extension(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 52: "                    if extensions"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if extensions"
[SYNCDOC DEBUG]       no_spaces: "ifextensions"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 53: "                        .iter()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".iter()"
[SYNCDOC DEBUG]       no_spaces: ".iter()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 54: "                        .any(|e| e == ext.to_string_lossy().as_ref())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".any(|e| e == ext.to_string_lossy().as_ref())"
[SYNCDOC DEBUG]       no_spaces: ".any(|e|e==ext.to_string_lossy().as_ref())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 55: "                    {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "{"
[SYNCDOC DEBUG]       no_spaces: "{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 56: "                        results.push(path);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "results.push(path);"
[SYNCDOC DEBUG]       no_spaces: "results.push(path);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 57: "                    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 58: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 59: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 60: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 61: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 62: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 63: "    Ok(results)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Ok(results)"
[SYNCDOC DEBUG]       no_spaces: "Ok(results)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 64: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 65: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 66: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 67: "pub fn extract_sections<F: Format>(file_path: &Path, format: &F) -> io::Result<Vec<Section>> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub fn extract_sections<F: Format>(file_path: &Path, format: &F) -> io::Result<Vec<Section>> {"
[SYNCDOC DEBUG]       no_spaces: "pubfnextract_sections<F:Format>(file_path:&Path,format:&F)->io::Result<Vec<Section>>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 68: "    let content = fs::read_to_string(file_path)?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let content = fs::read_to_string(file_path)?;"
[SYNCDOC DEBUG]       no_spaces: "letcontent=fs::read_to_string(file_path)?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 69: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 70: "    let mut parser = Parser::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut parser = Parser::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutparser=Parser::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 71: "    parser"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "parser"
[SYNCDOC DEBUG]       no_spaces: "parser"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 72: "        .set_language(&format.language())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".set_language(&format.language())"
[SYNCDOC DEBUG]       no_spaces: ".set_language(&format.language())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 73: "        .map_err(|e| io::Error::other(format!(\"Language error: {e}\")))?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map_err(|e| io::Error::other(format!(\"Language error: {e}\")))?;"
[SYNCDOC DEBUG]       no_spaces: ".map_err(|e|io::Error::other(format!(\"Languageerror:{e}\")))?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 74: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 75: "    let tree = parser"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let tree = parser"
[SYNCDOC DEBUG]       no_spaces: "lettree=parser"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 76: "        .parse(&content, None)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".parse(&content, None)"
[SYNCDOC DEBUG]       no_spaces: ".parse(&content,None)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 77: "        .ok_or_else(|| io::Error::other(\"Parse failed\"))?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".ok_or_else(|| io::Error::other(\"Parse failed\"))?;"
[SYNCDOC DEBUG]       no_spaces: ".ok_or_else(||io::Error::other(\"Parsefailed\"))?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 78: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 79: "    let section_query = Query::new(&format.language(), format.section_query())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let section_query = Query::new(&format.language(), format.section_query())"
[SYNCDOC DEBUG]       no_spaces: "letsection_query=Query::new(&format.language(),format.section_query())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 80: "        .map_err(|e| io::Error::other(format!(\"Query error: {e}\")))?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map_err(|e| io::Error::other(format!(\"Query error: {e}\")))?;"
[SYNCDOC DEBUG]       no_spaces: ".map_err(|e|io::Error::other(format!(\"Queryerror:{e}\")))?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 81: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 82: "    let title_query = Query::new(&format.language(), format.title_query())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let title_query = Query::new(&format.language(), format.title_query())"
[SYNCDOC DEBUG]       no_spaces: "lettitle_query=Query::new(&format.language(),format.title_query())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 83: "        .map_err(|e| io::Error::other(format!(\"Query error: {e}\")))?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map_err(|e| io::Error::other(format!(\"Query error: {e}\")))?;"
[SYNCDOC DEBUG]       no_spaces: ".map_err(|e|io::Error::other(format!(\"Queryerror:{e}\")))?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 84: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 85: "    // Collect all heading nodes by traversing the entire tree"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Collect all heading nodes by traversing the entire tree"
[SYNCDOC DEBUG]       no_spaces: "//Collectallheadingnodesbytraversingtheentiretree"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 86: "    let mut headings: Vec<tree_sitter::Node> = Vec::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut headings: Vec<tree_sitter::Node> = Vec::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutheadings:Vec<tree_sitter::Node>=Vec::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 87: "    let mut cursor = QueryCursor::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut cursor = QueryCursor::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutcursor=QueryCursor::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 88: "    let mut matches = cursor.matches(&section_query, tree.root_node(), content.as_bytes());"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut matches = cursor.matches(&section_query, tree.root_node(), content.as_bytes());"
[SYNCDOC DEBUG]       no_spaces: "letmutmatches=cursor.matches(&section_query,tree.root_node(),content.as_bytes());"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 89: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 90: "    while let Some(m) = matches.next() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "while let Some(m) = matches.next() {"
[SYNCDOC DEBUG]       no_spaces: "whileletSome(m)=matches.next(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 91: "        if let Some(c) = m.captures.first() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(c) = m.captures.first() {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(c)=m.captures.first(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 92: "            headings.push(c.node);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "headings.push(c.node);"
[SYNCDOC DEBUG]       no_spaces: "headings.push(c.node);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 93: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 94: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 95: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 96: "    let mut sections = Vec::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut sections = Vec::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutsections=Vec::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 97: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 98: "    for (i, heading) in headings.iter().enumerate() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for (i, heading) in headings.iter().enumerate() {"
[SYNCDOC DEBUG]       no_spaces: "for(i,heading)inheadings.iter().enumerate(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 99: "        // Determine level from the heading marker child node"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Determine level from the heading marker child node"
[SYNCDOC DEBUG]       no_spaces: "//Determinelevelfromtheheadingmarkerchildnode"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 100: "        let mut level = 1;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut level = 1;"
[SYNCDOC DEBUG]       no_spaces: "letmutlevel=1;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 101: "        let mut heading_cursor = heading.walk();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut heading_cursor = heading.walk();"
[SYNCDOC DEBUG]       no_spaces: "letmutheading_cursor=heading.walk();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 102: "        if heading_cursor.goto_first_child() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if heading_cursor.goto_first_child() {"
[SYNCDOC DEBUG]       no_spaces: "ifheading_cursor.goto_first_child(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 103: "            loop {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "loop {"
[SYNCDOC DEBUG]       no_spaces: "loop{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 104: "                let node = heading_cursor.node();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let node = heading_cursor.node();"
[SYNCDOC DEBUG]       no_spaces: "letnode=heading_cursor.node();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 105: "                let kind = node.kind();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let kind = node.kind();"
[SYNCDOC DEBUG]       no_spaces: "letkind=node.kind();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 106: "                // Match atx_h1_marker, atx_h2_marker, etc."
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Match atx_h1_marker, atx_h2_marker, etc."
[SYNCDOC DEBUG]       no_spaces: "//Matchatx_h1_marker,atx_h2_marker,etc."
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 107: "                if kind.starts_with(\"atx_h\") && kind.ends_with(\"_marker\") {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if kind.starts_with(\"atx_h\") && kind.ends_with(\"_marker\") {"
[SYNCDOC DEBUG]       no_spaces: "ifkind.starts_with(\"atx_h\")&&kind.ends_with(\"_marker\"){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 108: "                    if let Some(level_char) = kind.chars().nth(5) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(level_char) = kind.chars().nth(5) {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(level_char)=kind.chars().nth(5){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 109: "                        level = level_char.to_digit(10).unwrap_or(1) as usize;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "level = level_char.to_digit(10).unwrap_or(1) as usize;"
[SYNCDOC DEBUG]       no_spaces: "level=level_char.to_digit(10).unwrap_or(1)asusize;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 110: "                    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 111: "                    break;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "break;"
[SYNCDOC DEBUG]       no_spaces: "break;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 112: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 113: "                if !heading_cursor.goto_next_sibling() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if !heading_cursor.goto_next_sibling() {"
[SYNCDOC DEBUG]       no_spaces: "if!heading_cursor.goto_next_sibling(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 114: "                    break;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "break;"
[SYNCDOC DEBUG]       no_spaces: "break;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 115: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 116: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 117: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 118: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 119: "        // Extract title using query"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Extract title using query"
[SYNCDOC DEBUG]       no_spaces: "//Extracttitleusingquery"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 120: "        let mut title_cursor = QueryCursor::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut title_cursor = QueryCursor::new();"
[SYNCDOC DEBUG]       no_spaces: "letmuttitle_cursor=QueryCursor::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 121: "        let mut title = String::from(\"Untitled\");"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut title = String::from(\"Untitled\");"
[SYNCDOC DEBUG]       no_spaces: "letmuttitle=String::from(\"Untitled\");"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 122: "        let mut title_matches = title_cursor.matches(&title_query, *heading, content.as_bytes());"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut title_matches = title_cursor.matches(&title_query, *heading, content.as_bytes());"
[SYNCDOC DEBUG]       no_spaces: "letmuttitle_matches=title_cursor.matches(&title_query,*heading,content.as_bytes());"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 123: "        while let Some(m) = title_matches.next() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "while let Some(m) = title_matches.next() {"
[SYNCDOC DEBUG]       no_spaces: "whileletSome(m)=title_matches.next(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 124: "            if let Some(c) = m"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(c) = m"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(c)=m"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 125: "                .captures"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".captures"
[SYNCDOC DEBUG]       no_spaces: ".captures"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 126: "                .iter()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".iter()"
[SYNCDOC DEBUG]       no_spaces: ".iter()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 127: "                .find(|c| title_query.capture_names()[c.index as usize] == \"title\")"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".find(|c| title_query.capture_names()[c.index as usize] == \"title\")"
[SYNCDOC DEBUG]       no_spaces: ".find(|c|title_query.capture_names()[c.indexasusize]==\"title\")"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 128: "            {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "{"
[SYNCDOC DEBUG]       no_spaces: "{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 129: "                title = content[c.node.byte_range()].trim().to_string();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "title = content[c.node.byte_range()].trim().to_string();"
[SYNCDOC DEBUG]       no_spaces: "title=content[c.node.byte_range()].trim().to_string();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 130: "                break;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "break;"
[SYNCDOC DEBUG]       no_spaces: "break;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 131: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 132: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 133: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 134: "        // Calculate byte range (content only, after heading line)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Calculate byte range (content only, after heading line)"
[SYNCDOC DEBUG]       no_spaces: "//Calculatebyterange(contentonly,afterheadingline)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 135: "        let byte_start = heading.end_byte();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let byte_start = heading.end_byte();"
[SYNCDOC DEBUG]       no_spaces: "letbyte_start=heading.end_byte();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 136: "        let byte_end = headings"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let byte_end = headings"
[SYNCDOC DEBUG]       no_spaces: "letbyte_end=headings"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 137: "            .get(i + 1)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".get(i + 1)"
[SYNCDOC DEBUG]       no_spaces: ".get(i+1)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 138: "            .map_or(content.len(), tree_sitter::Node::start_byte);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map_or(content.len(), tree_sitter::Node::start_byte);"
[SYNCDOC DEBUG]       no_spaces: ".map_or(content.len(),tree_sitter::Node::start_byte);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 139: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 140: "        // Calculate line coordinates"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Calculate line coordinates"
[SYNCDOC DEBUG]       no_spaces: "//Calculatelinecoordinates"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 141: "        // Around line 100-110 in extract_sections"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Around line 100-110 in extract_sections"
[SYNCDOC DEBUG]       no_spaces: "//Aroundline100-110inextract_sections"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 142: "        let line_start = i64::try_from(heading.end_position().row).unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let line_start = i64::try_from(heading.end_position().row).unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: "letline_start=i64::try_from(heading.end_position().row).unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 143: "        let line_end = headings.get(i + 1).map_or("
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let line_end = headings.get(i + 1).map_or("
[SYNCDOC DEBUG]       no_spaces: "letline_end=headings.get(i+1).map_or("
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 144: "            i64::try_from(content.lines().count()).unwrap_or(0),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "i64::try_from(content.lines().count()).unwrap_or(0),"
[SYNCDOC DEBUG]       no_spaces: "i64::try_from(content.lines().count()).unwrap_or(0),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 145: "            |next| i64::try_from(next.start_position().row).unwrap_or(0),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "|next| i64::try_from(next.start_position().row).unwrap_or(0),"
[SYNCDOC DEBUG]       no_spaces: "|next|i64::try_from(next.start_position().row).unwrap_or(0),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 146: "        );"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ");"
[SYNCDOC DEBUG]       no_spaces: ");"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 147: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 148: "        let column_start = i64::try_from(heading.start_position().column).unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let column_start = i64::try_from(heading.start_position().column).unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: "letcolumn_start=i64::try_from(heading.start_position().column).unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 149: "        let column_end = i64::try_from(heading.end_position().column).unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let column_end = i64::try_from(heading.end_position().column).unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: "letcolumn_end=i64::try_from(heading.end_position().column).unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 150: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 151: "        sections.push(Section {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "sections.push(Section {"
[SYNCDOC DEBUG]       no_spaces: "sections.push(Section{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 152: "            title,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "title,"
[SYNCDOC DEBUG]       no_spaces: "title,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 153: "            level,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "level,"
[SYNCDOC DEBUG]       no_spaces: "level,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 154: "            line_start,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_start,"
[SYNCDOC DEBUG]       no_spaces: "line_start,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 155: "            line_end,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_end,"
[SYNCDOC DEBUG]       no_spaces: "line_end,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 156: "            column_start,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_start,"
[SYNCDOC DEBUG]       no_spaces: "column_start,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 157: "            column_end,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_end,"
[SYNCDOC DEBUG]       no_spaces: "column_end,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 158: "            byte_start,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_start,"
[SYNCDOC DEBUG]       no_spaces: "byte_start,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 159: "            byte_end,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_end,"
[SYNCDOC DEBUG]       no_spaces: "byte_end,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 160: "            file_path: file_path.to_string_lossy().to_string(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file_path: file_path.to_string_lossy().to_string(),"
[SYNCDOC DEBUG]       no_spaces: "file_path:file_path.to_string_lossy().to_string(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 161: "            parent_index: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "parent_index: None,"
[SYNCDOC DEBUG]       no_spaces: "parent_index:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 162: "            children_indices: Vec::new(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "children_indices: Vec::new(),"
[SYNCDOC DEBUG]       no_spaces: "children_indices:Vec::new(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 163: "            section_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "section_content: None,"
[SYNCDOC DEBUG]       no_spaces: "section_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 164: "            chunk_type: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "chunk_type: None,"
[SYNCDOC DEBUG]       no_spaces: "chunk_type:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 165: "            lhs_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "lhs_content: None,"
[SYNCDOC DEBUG]       no_spaces: "lhs_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 166: "            rhs_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "rhs_content: None,"
[SYNCDOC DEBUG]       no_spaces: "rhs_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 167: "        });"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "});"
[SYNCDOC DEBUG]       no_spaces: "});"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 168: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 169: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 170: "    // Build parent/child relationships"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Build parent/child relationships"
[SYNCDOC DEBUG]       no_spaces: "//Buildparent/childrelationships"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 171: "    build_hierarchy(&mut sections);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "build_hierarchy(&mut sections);"
[SYNCDOC DEBUG]       no_spaces: "build_hierarchy(&mutsections);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 172: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 173: "    Ok(sections)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Ok(sections)"
[SYNCDOC DEBUG]       no_spaces: "Ok(sections)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 174: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 175: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 176: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 177: "fn build_hierarchy(sections: &mut [Section]) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn build_hierarchy(sections: &mut [Section]) {"
[SYNCDOC DEBUG]       no_spaces: "fnbuild_hierarchy(sections:&mut[Section]){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 178: "    let mut stack: Vec<(usize, usize)> = Vec::new(); // (index, level)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut stack: Vec<(usize, usize)> = Vec::new(); // (index, level)"
[SYNCDOC DEBUG]       no_spaces: "letmutstack:Vec<(usize,usize)>=Vec::new();//(index,level)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 179: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 180: "    for i in 0..sections.len() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for i in 0..sections.len() {"
[SYNCDOC DEBUG]       no_spaces: "foriin0..sections.len(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 181: "        let current_level = sections[i].level;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let current_level = sections[i].level;"
[SYNCDOC DEBUG]       no_spaces: "letcurrent_level=sections[i].level;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 182: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 183: "        // Pop stack until we find parent level"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Pop stack until we find parent level"
[SYNCDOC DEBUG]       no_spaces: "//Popstackuntilwefindparentlevel"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 184: "        while let Some(&(_, parent_level)) = stack.last() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "while let Some(&(_, parent_level)) = stack.last() {"
[SYNCDOC DEBUG]       no_spaces: "whileletSome(&(_,parent_level))=stack.last(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 185: "            if parent_level < current_level {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if parent_level < current_level {"
[SYNCDOC DEBUG]       no_spaces: "ifparent_level<current_level{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 186: "                break;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "break;"
[SYNCDOC DEBUG]       no_spaces: "break;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 187: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 188: "            stack.pop();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "stack.pop();"
[SYNCDOC DEBUG]       no_spaces: "stack.pop();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 189: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 190: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 191: "        // Set parent relationship"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Set parent relationship"
[SYNCDOC DEBUG]       no_spaces: "//Setparentrelationship"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 192: "        if let Some(&(parent_idx, _)) = stack.last() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(&(parent_idx, _)) = stack.last() {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(&(parent_idx,_))=stack.last(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 193: "            sections[i].parent_index = Some(parent_idx);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "sections[i].parent_index = Some(parent_idx);"
[SYNCDOC DEBUG]       no_spaces: "sections[i].parent_index=Some(parent_idx);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 194: "            sections[parent_idx].children_indices.push(i);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "sections[parent_idx].children_indices.push(i);"
[SYNCDOC DEBUG]       no_spaces: "sections[parent_idx].children_indices.push(i);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 195: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 196: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 197: "        stack.push((i, current_level));"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "stack.push((i, current_level));"
[SYNCDOC DEBUG]       no_spaces: "stack.push((i,current_level));"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 198: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 199: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 200: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 201: "#[cfg(test)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[cfg(test)]"
[SYNCDOC DEBUG]       no_spaces: "#[cfg(test)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 202: "#[path = \"tests/input.rs\"]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[path = \"tests/input.rs\"]"
[SYNCDOC DEBUG]       no_spaces: "#[path=\"tests/input.rs\"]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 203: "mod tests;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "mod tests;"
[SYNCDOC DEBUG]       no_spaces: "modtests;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Final result length: 6760
[SYNCDOC DEBUG] === BOOKEND DEBUG END ===

[SYNCDOC DEBUG] After bookending: 5211
[SYNCDOC DEBUG] 
--- Final Result ---
[SYNCDOC DEBUG] #![doc = syncdoc::module_doc!()]

use crate::formats::Format;
use crate::section::Section;
use std::fs;
use std::io;
use std::path::{Path, PathBuf};
use streaming_iterator::StreamingIterator;
use tree_sitter::{Parser, Query, QueryCursor};

#[syncdoc::omnidoc]
pub fn find_documents(paths: Vec<PathBuf>, extensions: &[String]) -> io::Result<Vec<PathBuf>> {
    if paths.is_empty() {
        find_in_directory(Path::new("."), extensions)
    } else {
        let mut results = Vec::new();
        for path in paths {
            if path.is_file() {
                if let Some(ext) = path.extension() {
                    if extensions
                        .iter()
                        .any(|e| e == ext.to_string_lossy().as_ref())
                    {
                        results.push(path);
                    }
                }
            } else if path.is_dir() {
                results.extend(find_in_directory(&path, extensions)?);
            }
        }
        Ok(results)
    }
}

#[syncdoc::omnidoc]
fn find_in_directory(dir: &Path, extensions: &[String]) -> io::Result<Vec<PathBuf>> {
    let mut results = Vec::new();

    if let Ok(entries) = fs::read_dir(dir) {
        for entry in entries.flatten() {
            let path = entry.path();

            if path.is_dir() {
                if let Some(name) = path.file_name() {
                    let name_str = name.to_string_lossy();
                    if ["target", "dist", ".git", "node_modules"].contains(&name_str.as_ref()) {
                        continue;
                    }
                }
                results.extend(find_in_directory(&path, extensions)?);
            } else if path.is_file() {
                if let Some(ext) = path.extension() {
                    if extensions
                        .iter()
                        .any(|e| e == ext.to_string_lossy().as_ref())
                    {
                        results.push(path);
                    }
                }
            }
        }
    }

    Ok(results)
}

#[syncdoc::omnidoc]
pub fn extract_sections<F: Format>(file_path: &Path, format: &F) -> io::Result<Vec<Section>> {
    let content = fs::read_to_string(file_path)?;

    let mut parser = Parser::new();
    parser
        .set_language(&format.language())
        .map_err(|e| io::Error::other(format!("Language error: {e}")))?;

    let tree = parser
        .parse(&content, None)
        .ok_or_else(|| io::Error::other("Parse failed"))?;

    let section_query = Query::new(&format.language(), format.section_query())
        .map_err(|e| io::Error::other(format!("Query error: {e}")))?;

    let title_query = Query::new(&format.language(), format.title_query())
        .map_err(|e| io::Error::other(format!("Query error: {e}")))?;

    // Collect all heading nodes by traversing the entire tree
    let mut headings: Vec<tree_sitter::Node> = Vec::new();
    let mut cursor = QueryCursor::new();
    let mut matches = cursor.matches(&section_query, tree.root_node(), content.as_bytes());

    while let Some(m) = matches.next() {
        if let Some(c) = m.captures.first() {
            headings.push(c.node);
        }
    }

    let mut sections = Vec::new();

    for (i, heading) in headings.iter().enumerate() {
        // Determine level from the heading marker child node
        let mut level = 1;
        let mut heading_cursor = heading.walk();
        if heading_cursor.goto_first_child() {
            loop {
                let node = heading_cursor.node();
                let kind = node.kind();
                // Match atx_h1_marker, atx_h2_marker, etc.
                if kind.starts_with("atx_h") && kind.ends_with("_marker") {
                    if let Some(level_char) = kind.chars().nth(5) {
                        level = level_char.to_digit(10).unwrap_or(1) as usize;
                    }
                    break;
                }
                if !heading_cursor.goto_next_sibling() {
                    break;
                }
            }
        }

        // Extract title using query
        let mut title_cursor = QueryCursor::new();
        let mut title = String::from("Untitled");
        let mut title_matches = title_cursor.matches(&title_query, *heading, content.as_bytes());
        while let Some(m) = title_matches.next() {
            if let Some(c) = m
                .captures
                .iter()
                .find(|c| title_query.capture_names()[c.index as usize] == "title")
            {
                title = content[c.node.byte_range()].trim().to_string();
                break;
            }
        }

        // Calculate byte range (content only, after heading line)
        let byte_start = heading.end_byte();
        let byte_end = headings
            .get(i + 1)
            .map_or(content.len(), tree_sitter::Node::start_byte);

        // Calculate line coordinates
        // Around line 100-110 in extract_sections
        let line_start = i64::try_from(heading.end_position().row).unwrap_or(0);
        let line_end = headings.get(i + 1).map_or(
            i64::try_from(content.lines().count()).unwrap_or(0),
            |next| i64::try_from(next.start_position().row).unwrap_or(0),
        );

        let column_start = i64::try_from(heading.start_position().column).unwrap_or(0);
        let column_end = i64::try_from(heading.end_position().column).unwrap_or(0);

        sections.push(Section {
            title,
            level,
            line_start,
            line_end,
            column_start,
            column_end,
            byte_start,
            byte_end,
            file_path: file_path.to_string_lossy().to_string(),
            parent_index: None,
            children_indices: Vec::new(),
            section_content: None,
            chunk_type: None,
            lhs_content: None,
            rhs_content: None,
        });
    }

    // Build parent/child relationships
    build_hierarchy(&mut sections);

    Ok(sections)
}

#[syncdoc::omnidoc]
fn build_hierarchy(sections: &mut [Section]) {
    let mut stack: Vec<(usize, usize)> = Vec::new(); // (index, level)

    for i in 0..sections.len() {
        let current_level = sections[i].level;

        // Pop stack until we find parent level
        while let Some(&(_, parent_level)) = stack.last() {
            if parent_level < current_level {
                break;
            }
            stack.pop();
        }

        // Set parent relationship
        if let Some(&(parent_idx, _)) = stack.last() {
            sections[i].parent_index = Some(parent_idx);
            sections[parent_idx].children_indices.push(i);
        }

        stack.push((i, current_level));
    }
}

#[cfg(test)]
#[path = "tests/input.rs"]
mod tests;

[SYNCDOC DEBUG] === REFORMAT END ===

[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: pub, span: bytes(7450..7453) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(7454..7457) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: input, span: bytes(7458..7463) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(7463..7464) })
[SYNCDOC DEBUG] 
=== REFORMAT START ===
[SYNCDOC DEBUG] Original length: 15
[SYNCDOC DEBUG] Transformed length: 15
[SYNCDOC DEBUG] Formatted original length: 15
[SYNCDOC DEBUG] Formatted transformed length: 15
[SYNCDOC DEBUG] 
--- Formatted Original ---
[SYNCDOC DEBUG] pub mod input;

[SYNCDOC DEBUG] 
--- Formatted Transformed ---
[SYNCDOC DEBUG] pub mod input;

[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 1
[SYNCDOC DEBUG] After lines: 1
[SYNCDOC DEBUG] Hunks: 0
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] DEBUG restore: Found 0 hunks
[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 1
[SYNCDOC DEBUG] After lines: 1
[SYNCDOC DEBUG] Hunks: 0
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] Original != Result: true
[SYNCDOC DEBUG] 
=== BOOKEND DEBUG START ===
[SYNCDOC DEBUG] Input code length: 14
[SYNCDOC DEBUG] 
Line 0: "pub mod input;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub mod input;"
[SYNCDOC DEBUG]       no_spaces: "pubmodinput;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Final result length: 14
[SYNCDOC DEBUG] === BOOKEND DEBUG END ===

[SYNCDOC DEBUG] After bookending: 15
[SYNCDOC DEBUG] 
--- Final Result ---
[SYNCDOC DEBUG] pub mod input;

[SYNCDOC DEBUG] === REFORMAT END ===


=== Migration Summary ===
Processed 2 file(s)
Extracted 3 documentation(s)
Touched 3 missing file(s)
Rewrote 2 file(s)
