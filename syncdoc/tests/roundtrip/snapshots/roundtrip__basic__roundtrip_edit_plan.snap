---
source: syncdoc/tests/roundtrip/basic.rs
expression: result.migrate_stderr
---
[SYNCDOC DEBUG] get_docs_path called:
[SYNCDOC DEBUG]   source_file: src
[SYNCDOC DEBUG]   manifest_dir: /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   docs_path from toml: docs
[SYNCDOC DEBUG]   manifest_path (canonical): /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   source_dir (canonical): /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   relative_path (stripped): 
[SYNCDOC DEBUG]   depth: 0
[SYNCDOC DEBUG]   final result: docs
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(266..269) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: serde, span: bytes(270..275) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(275..276) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(276..277) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: Deserialize, span: bytes(278..289) }, Punct { char: ',', spacing: Alone, span: bytes(289..290) }, Ident { sym: Serialize, span: bytes(291..300) }], span: bytes(277..301) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(301..302) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(303..306) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(307..310) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(310..311) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(311..312) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: collections, span: bytes(312..323) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(323..324) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(324..325) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: HashMap, span: bytes(325..332) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(332..333) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(334..337) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(338..341) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(341..342) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(342..343) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: io, span: bytes(343..345) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(345..346) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(347..350) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: textum, span: bytes(351..357) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(357..358) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(358..359) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: Boundary, span: bytes(360..368) }, Punct { char: ',', spacing: Alone, span: bytes(368..369) }, Ident { sym: BoundaryMode, span: bytes(370..382) }, Punct { char: ',', spacing: Alone, span: bytes(382..383) }, Ident { sym: Patch, span: bytes(384..389) }, Punct { char: ',', spacing: Alone, span: bytes(389..390) }, Ident { sym: PatchSet, span: bytes(391..399) }, Punct { char: ',', spacing: Alone, span: bytes(399..400) }, Ident { sym: Snippet, span: bytes(401..408) }, Punct { char: ',', spacing: Alone, span: bytes(408..409) }, Ident { sym: Target, span: bytes(410..416) }], span: bytes(359..417) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(417..418) })
[SYNCDOC DEBUG] Processing item type: Struct
[SYNCDOC DEBUG] Processing item: Struct(StructSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(420..493) }, Punct { char: '=', spacing: Alone, span: bytes(420..493) }, Literal { lit: " Serialisable collection of file modifications for atomic application.", span: bytes(420..493) }], span: bytes(420..493) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: derive, span: bytes(496..502) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Serialize, span: bytes(503..512) }, Punct { char: ',', spacing: Alone, span: bytes(512..513) }, Ident { sym: Deserialize, span: bytes(514..525) }, Punct { char: ',', spacing: Alone, span: bytes(525..526) }, Ident { sym: Clone, span: bytes(527..532) }], span: bytes(502..533) }], span: bytes(495..534) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(535..538) }, string: "pub" }))), _struct: KStruct(Cached<proc_macro2::Ident> { value: Ident { sym: struct, span: bytes(539..545) }, string: "struct" }), name: Ident { sym: EditPlan, span: bytes(546..554) }, generics: None, where_clause: None, body: Named(BraceGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(561..626) }, Punct { char: '=', spacing: Alone, span: bytes(561..626) }, Literal { lit: " Individual section replacements grouped for batch processing.", span: bytes(561..626) }], span: bytes(561..626) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(631..634) }, string: "pub" }))), name: Ident { sym: edits, span: bytes(635..640) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(642..645) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Edit, span: bytes(646..650) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }])))) })
[SYNCDOC DEBUG] Processing item type: Struct
[SYNCDOC DEBUG] Processing item: Struct(StructSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(656..726) }, Punct { char: '=', spacing: Alone, span: bytes(656..726) }, Literal { lit: " Precise coordinates and content for replacing a section in a file.", span: bytes(656..726) }], span: bytes(656..726) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: derive, span: bytes(729..735) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Serialize, span: bytes(736..745) }, Punct { char: ',', spacing: Alone, span: bytes(745..746) }, Ident { sym: Deserialize, span: bytes(747..758) }, Punct { char: ',', spacing: Alone, span: bytes(758..759) }, Ident { sym: Clone, span: bytes(760..765) }], span: bytes(735..766) }], span: bytes(728..767) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(768..771) }, string: "pub" }))), _struct: KStruct(Cached<proc_macro2::Ident> { value: Ident { sym: struct, span: bytes(772..778) }, string: "struct" }), name: Ident { sym: Edit, span: bytes(779..783) }, generics: None, where_clause: None, body: Named(BraceGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(790..833) }, Punct { char: '=', spacing: Alone, span: bytes(790..833) }, Literal { lit: " Target file path for this modification.", span: bytes(790..833) }], span: bytes(790..833) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(838..841) }, string: "pub" }))), name: Ident { sym: file_name, span: bytes(842..851) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(853..859) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(865..918) }, Punct { char: '=', spacing: Alone, span: bytes(865..918) }, Literal { lit: " First line of the section to replace (inclusive).", span: bytes(865..918) }], span: bytes(865..918) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(923..926) }, string: "pub" }))), name: Ident { sym: line_start, span: bytes(927..937) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: i64, span: bytes(939..942) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(948..1001) }, Punct { char: '=', spacing: Alone, span: bytes(948..1001) }, Literal { lit: " Final line of the section to replace (exclusive).", span: bytes(948..1001) }], span: bytes(948..1001) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1006..1009) }, string: "pub" }))), name: Ident { sym: line_end, span: bytes(1010..1018) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: i64, span: bytes(1020..1023) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1029..1071) }, Punct { char: '=', spacing: Alone, span: bytes(1029..1071) }, Literal { lit: " Starting column of the section header.", span: bytes(1029..1071) }], span: bytes(1029..1071) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1076..1079) }, string: "pub" }))), name: Ident { sym: column_start, span: bytes(1080..1092) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: i64, span: bytes(1094..1097) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1103..1143) }, Punct { char: '=', spacing: Alone, span: bytes(1103..1143) }, Literal { lit: " Ending column of the section header.", span: bytes(1103..1143) }], span: bytes(1103..1143) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1148..1151) }, string: "pub" }))), name: Ident { sym: column_end, span: bytes(1152..1162) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: i64, span: bytes(1164..1167) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1173..1216) }, Punct { char: '=', spacing: Alone, span: bytes(1173..1216) }, Literal { lit: " New content replacing the section body.", span: bytes(1173..1216) }], span: bytes(1173..1216) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1221..1224) }, string: "pub" }))), name: Ident { sym: section_content, span: bytes(1225..1240) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(1242..1248) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1254..1305) }, Punct { char: '=', spacing: Alone, span: bytes(1254..1305) }, Literal { lit: " Section title for tracking and debugging edits.", span: bytes(1254..1305) }], span: bytes(1254..1305) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1310..1313) }, string: "pub" }))), name: Ident { sym: item_name, span: bytes(1314..1323) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(1325..1331) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }])))) })
[SYNCDOC DEBUG] Processing item type: ImplBlock
[SYNCDOC DEBUG] Processing item: ImplBlock(ImplBlockSig { attributes: None, _impl: KImpl(Cached<proc_macro2::Ident> { value: Ident { sym: impl, span: bytes(1336..1340) }, string: "impl" }), generics: None, target_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree> { first: Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, second: Ident { sym: EditPlan, span: bytes(1341..1349) } }, delimiter: Some(Nothing) }]), for_trait: None, where_clause: None, items: BraceGroupContaining < syncdoc_core::parse::ModuleContent>(ModuleContent { inner_attrs: None, items: Repeats<1, 18446744073709551615, syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1356..1409) }, Punct { char: '=', spacing: Alone, span: bytes(1356..1409) }, Literal { lit: " Apply all edits in the plan using textum patches.", span: bytes(1356..1409) }], span: bytes(1356..1409) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1414..1417) }, Punct { char: '=', spacing: Alone, span: bytes(1414..1417) }, Literal { lit: "", span: bytes(1414..1417) }], span: bytes(1414..1417) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1422..1496) }, Punct { char: '=', spacing: Alone, span: bytes(1422..1496) }, Literal { lit: " Groups edits by file and uses textum's `PatchSet` to apply all changes", span: bytes(1422..1496) }], span: bytes(1422..1496) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1501..1573) }, Punct { char: '=', spacing: Alone, span: bytes(1501..1573) }, Literal { lit: " atomically per file. Each edit targets a line range and replaces the", span: bytes(1501..1573) }], span: bytes(1501..1573) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1578..1639) }, Punct { char: '=', spacing: Alone, span: bytes(1578..1639) }, Literal { lit: " content between those lines with the new section content.", span: bytes(1578..1639) }], span: bytes(1578..1639) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1644..1647) }, Punct { char: '=', spacing: Alone, span: bytes(1644..1647) }, Literal { lit: "", span: bytes(1644..1647) }], span: bytes(1644..1647) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1652..1664) }, Punct { char: '=', spacing: Alone, span: bytes(1652..1664) }, Literal { lit: " # Errors", span: bytes(1652..1664) }], span: bytes(1652..1664) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1669..1672) }, Punct { char: '=', spacing: Alone, span: bytes(1669..1672) }, Literal { lit: "", span: bytes(1669..1672) }], span: bytes(1669..1672) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1677..1760) }, Punct { char: '=', spacing: Alone, span: bytes(1677..1760) }, Literal { lit: " Returns an error if file operations, patching, or line number conversion fails.", span: bytes(1677..1760) }], span: bytes(1677..1760) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1765..1768) }, string: "pub" }))), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(1769..1771) }, string: "fn" }), name: Ident { sym: apply, span: bytes(1772..1777) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(RefMut(Cons<unsynn::operator::Operator<'&'>, unsynn::combinator::Cons<syncdoc_core::parse::KMut, syncdoc_core::parse::KSelf>> { first: Operator<'&'>, second: Cons<syncdoc_core::parse::KMut, syncdoc_core::parse::KSelf> { first: KMut(Cached<proc_macro2::Ident> { value: Ident { sym: mut, span: bytes(1779..1782) }, string: "mut" }), second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(1783..1787) }, string: "self" }) } })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: io, span: bytes(1792..1794) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(1794..1795) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(1795..1796) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Result, span: bytes(1796..1802) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1803..1805) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(1817..1820) }, Ident { sym: mut, span: bytes(1821..1824) }, Ident { sym: file_groups, span: bytes(1825..1836) }, Punct { char: ':', spacing: Alone, span: bytes(1836..1837) }, Ident { sym: HashMap, span: bytes(1838..1845) }, Punct { char: '<', spacing: Alone, span: bytes(1845..1846) }, Ident { sym: String, span: bytes(1846..1852) }, Punct { char: ',', spacing: Alone, span: bytes(1852..1853) }, Ident { sym: Vec, span: bytes(1854..1857) }, Punct { char: '<', spacing: Joint, span: bytes(1857..1858) }, Punct { char: '&', spacing: Alone, span: bytes(1858..1859) }, Ident { sym: Edit, span: bytes(1859..1863) }, Punct { char: '>', spacing: Joint, span: bytes(1863..1864) }, Punct { char: '>', spacing: Alone, span: bytes(1864..1865) }, Punct { char: '=', spacing: Alone, span: bytes(1866..1867) }, Ident { sym: HashMap, span: bytes(1868..1875) }, Punct { char: ':', spacing: Joint, span: bytes(1875..1876) }, Punct { char: ':', spacing: Alone, span: bytes(1876..1877) }, Ident { sym: new, span: bytes(1877..1880) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1880..1882) }, Punct { char: ';', spacing: Alone, span: bytes(1882..1883) }, Ident { sym: for, span: bytes(1893..1896) }, Ident { sym: edit, span: bytes(1897..1901) }, Ident { sym: in, span: bytes(1902..1904) }, Punct { char: '&', spacing: Alone, span: bytes(1905..1906) }, Ident { sym: self, span: bytes(1906..1910) }, Punct { char: '.', spacing: Alone, span: bytes(1910..1911) }, Ident { sym: edits, span: bytes(1911..1916) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: file_groups, span: bytes(1931..1942) }, Punct { char: '.', spacing: Alone, span: bytes(1959..1960) }, Ident { sym: entry, span: bytes(1960..1965) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: edit, span: bytes(1966..1970) }, Punct { char: '.', spacing: Alone, span: bytes(1970..1971) }, Ident { sym: file_name, span: bytes(1971..1980) }, Punct { char: '.', spacing: Alone, span: bytes(1980..1981) }, Ident { sym: clone, span: bytes(1981..1986) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1986..1988) }], span: bytes(1965..1989) }, Punct { char: '.', spacing: Alone, span: bytes(2006..2007) }, Ident { sym: or_default, span: bytes(2007..2017) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2017..2019) }, Punct { char: '.', spacing: Alone, span: bytes(2036..2037) }, Ident { sym: push, span: bytes(2037..2041) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: edit, span: bytes(2042..2046) }], span: bytes(2041..2047) }, Punct { char: ';', spacing: Alone, span: bytes(2047..2048) }], span: bytes(1917..2058) }, Ident { sym: for, span: bytes(2068..2071) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: file_name, span: bytes(2073..2082) }, Punct { char: ',', spacing: Alone, span: bytes(2082..2083) }, Ident { sym: edits, span: bytes(2084..2089) }], span: bytes(2072..2090) }, Ident { sym: in, span: bytes(2091..2093) }, Ident { sym: file_groups, span: bytes(2094..2105) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(2120..2123) }, Ident { sym: mut, span: bytes(2124..2127) }, Ident { sym: patchset, span: bytes(2128..2136) }, Punct { char: '=', spacing: Alone, span: bytes(2137..2138) }, Ident { sym: PatchSet, span: bytes(2139..2147) }, Punct { char: ':', spacing: Joint, span: bytes(2147..2148) }, Punct { char: ':', spacing: Alone, span: bytes(2148..2149) }, Ident { sym: new, span: bytes(2149..2152) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2152..2154) }, Punct { char: ';', spacing: Alone, span: bytes(2154..2155) }, Ident { sym: for, span: bytes(2169..2172) }, Ident { sym: edit, span: bytes(2173..2177) }, Ident { sym: in, span: bytes(2178..2180) }, Ident { sym: edits, span: bytes(2181..2186) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(2205..2208) }, Ident { sym: line_start, span: bytes(2209..2219) }, Punct { char: ':', spacing: Alone, span: bytes(2219..2220) }, Ident { sym: usize, span: bytes(2221..2226) }, Punct { char: '=', spacing: Alone, span: bytes(2227..2228) }, Ident { sym: edit, span: bytes(2229..2233) }, Punct { char: '.', spacing: Alone, span: bytes(2233..2234) }, Ident { sym: line_start, span: bytes(2234..2244) }, Punct { char: '.', spacing: Alone, span: bytes(2244..2245) }, Ident { sym: try_into, span: bytes(2245..2253) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2253..2255) }, Punct { char: '.', spacing: Alone, span: bytes(2255..2256) }, Ident { sym: map_err, span: bytes(2256..2263) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(2264..2265) }, Ident { sym: _, span: bytes(2265..2266) }, Punct { char: '|', spacing: Alone, span: bytes(2266..2267) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: io, span: bytes(2290..2292) }, Punct { char: ':', spacing: Joint, span: bytes(2292..2293) }, Punct { char: ':', spacing: Alone, span: bytes(2293..2294) }, Ident { sym: Error, span: bytes(2294..2299) }, Punct { char: ':', spacing: Joint, span: bytes(2299..2300) }, Punct { char: ':', spacing: Alone, span: bytes(2300..2301) }, Ident { sym: other, span: bytes(2301..2306) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: format, span: bytes(2307..2313) }, Punct { char: '!', spacing: Alone, span: bytes(2313..2314) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Invalid line_start: {}", span: bytes(2315..2339) }, Punct { char: ',', spacing: Alone, span: bytes(2339..2340) }, Ident { sym: edit, span: bytes(2341..2345) }, Punct { char: '.', spacing: Alone, span: bytes(2345..2346) }, Ident { sym: line_start, span: bytes(2346..2356) }], span: bytes(2314..2357) }], span: bytes(2306..2358) }], span: bytes(2268..2376) }], span: bytes(2263..2377) }, Punct { char: '?', spacing: Joint, span: bytes(2377..2378) }, Punct { char: ';', spacing: Alone, span: bytes(2378..2379) }, Ident { sym: let, span: bytes(2396..2399) }, Ident { sym: line_end, span: bytes(2400..2408) }, Punct { char: ':', spacing: Alone, span: bytes(2408..2409) }, Ident { sym: usize, span: bytes(2410..2415) }, Punct { char: '=', spacing: Alone, span: bytes(2416..2417) }, Ident { sym: edit, span: bytes(2418..2422) }, Punct { char: '.', spacing: Alone, span: bytes(2422..2423) }, Ident { sym: line_end, span: bytes(2423..2431) }, Punct { char: '.', spacing: Alone, span: bytes(2431..2432) }, Ident { sym: try_into, span: bytes(2432..2440) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2440..2442) }, Punct { char: '.', spacing: Alone, span: bytes(2442..2443) }, Ident { sym: map_err, span: bytes(2443..2450) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(2451..2452) }, Ident { sym: _, span: bytes(2452..2453) }, Punct { char: '|', spacing: Alone, span: bytes(2453..2454) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: io, span: bytes(2477..2479) }, Punct { char: ':', spacing: Joint, span: bytes(2479..2480) }, Punct { char: ':', spacing: Alone, span: bytes(2480..2481) }, Ident { sym: Error, span: bytes(2481..2486) }, Punct { char: ':', spacing: Joint, span: bytes(2486..2487) }, Punct { char: ':', spacing: Alone, span: bytes(2487..2488) }, Ident { sym: other, span: bytes(2488..2493) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: format, span: bytes(2494..2500) }, Punct { char: '!', spacing: Alone, span: bytes(2500..2501) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Invalid line_end: {}", span: bytes(2502..2524) }, Punct { char: ',', spacing: Alone, span: bytes(2524..2525) }, Ident { sym: edit, span: bytes(2526..2530) }, Punct { char: '.', spacing: Alone, span: bytes(2530..2531) }, Ident { sym: line_end, span: bytes(2531..2539) }], span: bytes(2501..2540) }], span: bytes(2493..2541) }], span: bytes(2455..2559) }], span: bytes(2450..2560) }, Punct { char: '?', spacing: Joint, span: bytes(2560..2561) }, Punct { char: ';', spacing: Alone, span: bytes(2561..2562) }, Ident { sym: let, span: bytes(2580..2583) }, Ident { sym: start, span: bytes(2584..2589) }, Punct { char: '=', spacing: Alone, span: bytes(2590..2591) }, Ident { sym: Boundary, span: bytes(2592..2600) }, Punct { char: ':', spacing: Joint, span: bytes(2600..2601) }, Punct { char: ':', spacing: Alone, span: bytes(2601..2602) }, Ident { sym: new, span: bytes(2602..2605) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Target, span: bytes(2606..2612) }, Punct { char: ':', spacing: Joint, span: bytes(2612..2613) }, Punct { char: ':', spacing: Alone, span: bytes(2613..2614) }, Ident { sym: Line, span: bytes(2614..2618) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line_start, span: bytes(2619..2629) }], span: bytes(2618..2630) }, Punct { char: ',', spacing: Alone, span: bytes(2630..2631) }, Ident { sym: BoundaryMode, span: bytes(2632..2644) }, Punct { char: ':', spacing: Joint, span: bytes(2644..2645) }, Punct { char: ':', spacing: Alone, span: bytes(2645..2646) }, Ident { sym: Include, span: bytes(2646..2653) }], span: bytes(2605..2654) }, Punct { char: ';', spacing: Alone, span: bytes(2654..2655) }, Ident { sym: let, span: bytes(2672..2675) }, Ident { sym: end, span: bytes(2676..2679) }, Punct { char: '=', spacing: Alone, span: bytes(2680..2681) }, Ident { sym: Boundary, span: bytes(2682..2690) }, Punct { char: ':', spacing: Joint, span: bytes(2690..2691) }, Punct { char: ':', spacing: Alone, span: bytes(2691..2692) }, Ident { sym: new, span: bytes(2692..2695) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Target, span: bytes(2696..2702) }, Punct { char: ':', spacing: Joint, span: bytes(2702..2703) }, Punct { char: ':', spacing: Alone, span: bytes(2703..2704) }, Ident { sym: Line, span: bytes(2704..2708) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line_end, span: bytes(2709..2717) }], span: bytes(2708..2718) }, Punct { char: ',', spacing: Alone, span: bytes(2718..2719) }, Ident { sym: BoundaryMode, span: bytes(2720..2732) }, Punct { char: ':', spacing: Joint, span: bytes(2732..2733) }, Punct { char: ':', spacing: Alone, span: bytes(2733..2734) }, Ident { sym: Exclude, span: bytes(2734..2741) }], span: bytes(2695..2742) }, Punct { char: ';', spacing: Alone, span: bytes(2742..2743) }, Ident { sym: let, span: bytes(2760..2763) }, Ident { sym: snippet, span: bytes(2764..2771) }, Punct { char: '=', spacing: Alone, span: bytes(2772..2773) }, Ident { sym: Snippet, span: bytes(2774..2781) }, Punct { char: ':', spacing: Joint, span: bytes(2781..2782) }, Punct { char: ':', spacing: Alone, span: bytes(2782..2783) }, Ident { sym: Between, span: bytes(2783..2790) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: start, span: bytes(2793..2798) }, Punct { char: ',', spacing: Alone, span: bytes(2798..2799) }, Ident { sym: end, span: bytes(2800..2803) }], span: bytes(2791..2805) }, Punct { char: ';', spacing: Alone, span: bytes(2805..2806) }, Ident { sym: let, span: bytes(2824..2827) }, Ident { sym: replacement, span: bytes(2828..2839) }, Punct { char: '=', spacing: Alone, span: bytes(2840..2841) }, Ident { sym: format, span: bytes(2842..2848) }, Punct { char: '!', spacing: Alone, span: bytes(2848..2849) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "\n{}\n\n", span: bytes(2850..2860) }, Punct { char: ',', spacing: Alone, span: bytes(2860..2861) }, Ident { sym: edit, span: bytes(2862..2866) }, Punct { char: '.', spacing: Alone, span: bytes(2866..2867) }, Ident { sym: section_content, span: bytes(2867..2882) }, Punct { char: '.', spacing: Alone, span: bytes(2882..2883) }, Ident { sym: trim, span: bytes(2883..2887) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2887..2889) }], span: bytes(2849..2890) }, Punct { char: ';', spacing: Alone, span: bytes(2890..2891) }, Ident { sym: let, span: bytes(2909..2912) }, Ident { sym: patch, span: bytes(2913..2918) }, Punct { char: '=', spacing: Alone, span: bytes(2919..2920) }, Ident { sym: Patch, span: bytes(2921..2926) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: file, span: bytes(2949..2953) }, Punct { char: ':', spacing: Alone, span: bytes(2953..2954) }, Ident { sym: file_name, span: bytes(2955..2964) }, Punct { char: '.', spacing: Alone, span: bytes(2964..2965) }, Ident { sym: clone, span: bytes(2965..2970) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2970..2972) }, Punct { char: ',', spacing: Alone, span: bytes(2972..2973) }, Ident { sym: snippet, span: bytes(2994..3001) }, Punct { char: ',', spacing: Alone, span: bytes(3001..3002) }, Ident { sym: replacement, span: bytes(3023..3034) }, Punct { char: ',', spacing: Alone, span: bytes(3034..3035) }], span: bytes(2927..3053) }, Punct { char: ';', spacing: Alone, span: bytes(3053..3054) }, Ident { sym: patchset, span: bytes(3072..3080) }, Punct { char: '.', spacing: Alone, span: bytes(3080..3081) }, Ident { sym: add, span: bytes(3081..3084) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: patch, span: bytes(3085..3090) }], span: bytes(3084..3091) }, Punct { char: ';', spacing: Alone, span: bytes(3091..3092) }], span: bytes(2187..3106) }, Ident { sym: let, span: bytes(3120..3123) }, Ident { sym: results, span: bytes(3124..3131) }, Punct { char: '=', spacing: Alone, span: bytes(3132..3133) }, Ident { sym: patchset, span: bytes(3134..3142) }, Punct { char: '.', spacing: Alone, span: bytes(3159..3160) }, Ident { sym: apply_to_files, span: bytes(3160..3174) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3174..3176) }, Punct { char: '.', spacing: Alone, span: bytes(3193..3194) }, Ident { sym: map_err, span: bytes(3194..3201) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(3202..3203) }, Ident { sym: e, span: bytes(3203..3204) }, Punct { char: '|', spacing: Alone, span: bytes(3204..3205) }, Ident { sym: io, span: bytes(3206..3208) }, Punct { char: ':', spacing: Joint, span: bytes(3208..3209) }, Punct { char: ':', spacing: Alone, span: bytes(3209..3210) }, Ident { sym: Error, span: bytes(3210..3215) }, Punct { char: ':', spacing: Joint, span: bytes(3215..3216) }, Punct { char: ':', spacing: Alone, span: bytes(3216..3217) }, Ident { sym: other, span: bytes(3217..3222) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: e, span: bytes(3223..3224) }, Punct { char: '.', spacing: Alone, span: bytes(3224..3225) }, Ident { sym: to_string, span: bytes(3225..3234) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3234..3236) }], span: bytes(3222..3237) }], span: bytes(3201..3238) }, Punct { char: '?', spacing: Joint, span: bytes(3238..3239) }, Punct { char: ';', spacing: Alone, span: bytes(3239..3240) }, Ident { sym: if, span: bytes(3254..3256) }, Ident { sym: let, span: bytes(3257..3260) }, Ident { sym: Some, span: bytes(3261..3265) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: new_content, span: bytes(3266..3277) }], span: bytes(3265..3278) }, Punct { char: '=', spacing: Alone, span: bytes(3279..3280) }, Ident { sym: results, span: bytes(3281..3288) }, Punct { char: '.', spacing: Alone, span: bytes(3288..3289) }, Ident { sym: get, span: bytes(3289..3292) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3293..3294) }, Ident { sym: file_name, span: bytes(3294..3303) }], span: bytes(3292..3304) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: std, span: bytes(3323..3326) }, Punct { char: ':', spacing: Joint, span: bytes(3326..3327) }, Punct { char: ':', spacing: Alone, span: bytes(3327..3328) }, Ident { sym: fs, span: bytes(3328..3330) }, Punct { char: ':', spacing: Joint, span: bytes(3330..3331) }, Punct { char: ':', spacing: Alone, span: bytes(3331..3332) }, Ident { sym: write, span: bytes(3332..3337) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3338..3339) }, Ident { sym: file_name, span: bytes(3339..3348) }, Punct { char: ',', spacing: Alone, span: bytes(3348..3349) }, Ident { sym: new_content, span: bytes(3350..3361) }], span: bytes(3337..3362) }, Punct { char: '?', spacing: Joint, span: bytes(3362..3363) }, Punct { char: ';', spacing: Alone, span: bytes(3363..3364) }], span: bytes(3305..3378) }], span: bytes(2106..3388) }, Ident { sym: Ok, span: bytes(3398..3400) }, Group { delimiter: Parenthesis, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3401..3403) }], span: bytes(3400..3404) }], span: bytes(1807..3410) }) }), delimiter: Some(Nothing) }]) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1356..1409) }, Punct { char: '=', spacing: Alone, span: bytes(1356..1409) }, Literal { lit: " Apply all edits in the plan using textum patches.", span: bytes(1356..1409) }], span: bytes(1356..1409) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1414..1417) }, Punct { char: '=', spacing: Alone, span: bytes(1414..1417) }, Literal { lit: "", span: bytes(1414..1417) }], span: bytes(1414..1417) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1422..1496) }, Punct { char: '=', spacing: Alone, span: bytes(1422..1496) }, Literal { lit: " Groups edits by file and uses textum's `PatchSet` to apply all changes", span: bytes(1422..1496) }], span: bytes(1422..1496) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1501..1573) }, Punct { char: '=', spacing: Alone, span: bytes(1501..1573) }, Literal { lit: " atomically per file. Each edit targets a line range and replaces the", span: bytes(1501..1573) }], span: bytes(1501..1573) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1578..1639) }, Punct { char: '=', spacing: Alone, span: bytes(1578..1639) }, Literal { lit: " content between those lines with the new section content.", span: bytes(1578..1639) }], span: bytes(1578..1639) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1644..1647) }, Punct { char: '=', spacing: Alone, span: bytes(1644..1647) }, Literal { lit: "", span: bytes(1644..1647) }], span: bytes(1644..1647) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1652..1664) }, Punct { char: '=', spacing: Alone, span: bytes(1652..1664) }, Literal { lit: " # Errors", span: bytes(1652..1664) }], span: bytes(1652..1664) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1669..1672) }, Punct { char: '=', spacing: Alone, span: bytes(1669..1672) }, Literal { lit: "", span: bytes(1669..1672) }], span: bytes(1669..1672) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1677..1760) }, Punct { char: '=', spacing: Alone, span: bytes(1677..1760) }, Literal { lit: " Returns an error if file operations, patching, or line number conversion fails.", span: bytes(1677..1760) }], span: bytes(1677..1760) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1765..1768) }, string: "pub" }))), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(1769..1771) }, string: "fn" }), name: Ident { sym: apply, span: bytes(1772..1777) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(RefMut(Cons<unsynn::operator::Operator<'&'>, unsynn::combinator::Cons<syncdoc_core::parse::KMut, syncdoc_core::parse::KSelf>> { first: Operator<'&'>, second: Cons<syncdoc_core::parse::KMut, syncdoc_core::parse::KSelf> { first: KMut(Cached<proc_macro2::Ident> { value: Ident { sym: mut, span: bytes(1779..1782) }, string: "mut" }), second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(1783..1787) }, string: "self" }) } })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: io, span: bytes(1792..1794) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(1794..1795) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(1795..1796) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Result, span: bytes(1796..1802) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1803..1805) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(1817..1820) }, Ident { sym: mut, span: bytes(1821..1824) }, Ident { sym: file_groups, span: bytes(1825..1836) }, Punct { char: ':', spacing: Alone, span: bytes(1836..1837) }, Ident { sym: HashMap, span: bytes(1838..1845) }, Punct { char: '<', spacing: Alone, span: bytes(1845..1846) }, Ident { sym: String, span: bytes(1846..1852) }, Punct { char: ',', spacing: Alone, span: bytes(1852..1853) }, Ident { sym: Vec, span: bytes(1854..1857) }, Punct { char: '<', spacing: Joint, span: bytes(1857..1858) }, Punct { char: '&', spacing: Alone, span: bytes(1858..1859) }, Ident { sym: Edit, span: bytes(1859..1863) }, Punct { char: '>', spacing: Joint, span: bytes(1863..1864) }, Punct { char: '>', spacing: Alone, span: bytes(1864..1865) }, Punct { char: '=', spacing: Alone, span: bytes(1866..1867) }, Ident { sym: HashMap, span: bytes(1868..1875) }, Punct { char: ':', spacing: Joint, span: bytes(1875..1876) }, Punct { char: ':', spacing: Alone, span: bytes(1876..1877) }, Ident { sym: new, span: bytes(1877..1880) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1880..1882) }, Punct { char: ';', spacing: Alone, span: bytes(1882..1883) }, Ident { sym: for, span: bytes(1893..1896) }, Ident { sym: edit, span: bytes(1897..1901) }, Ident { sym: in, span: bytes(1902..1904) }, Punct { char: '&', spacing: Alone, span: bytes(1905..1906) }, Ident { sym: self, span: bytes(1906..1910) }, Punct { char: '.', spacing: Alone, span: bytes(1910..1911) }, Ident { sym: edits, span: bytes(1911..1916) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: file_groups, span: bytes(1931..1942) }, Punct { char: '.', spacing: Alone, span: bytes(1959..1960) }, Ident { sym: entry, span: bytes(1960..1965) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: edit, span: bytes(1966..1970) }, Punct { char: '.', spacing: Alone, span: bytes(1970..1971) }, Ident { sym: file_name, span: bytes(1971..1980) }, Punct { char: '.', spacing: Alone, span: bytes(1980..1981) }, Ident { sym: clone, span: bytes(1981..1986) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(1986..1988) }], span: bytes(1965..1989) }, Punct { char: '.', spacing: Alone, span: bytes(2006..2007) }, Ident { sym: or_default, span: bytes(2007..2017) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2017..2019) }, Punct { char: '.', spacing: Alone, span: bytes(2036..2037) }, Ident { sym: push, span: bytes(2037..2041) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: edit, span: bytes(2042..2046) }], span: bytes(2041..2047) }, Punct { char: ';', spacing: Alone, span: bytes(2047..2048) }], span: bytes(1917..2058) }, Ident { sym: for, span: bytes(2068..2071) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: file_name, span: bytes(2073..2082) }, Punct { char: ',', spacing: Alone, span: bytes(2082..2083) }, Ident { sym: edits, span: bytes(2084..2089) }], span: bytes(2072..2090) }, Ident { sym: in, span: bytes(2091..2093) }, Ident { sym: file_groups, span: bytes(2094..2105) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(2120..2123) }, Ident { sym: mut, span: bytes(2124..2127) }, Ident { sym: patchset, span: bytes(2128..2136) }, Punct { char: '=', spacing: Alone, span: bytes(2137..2138) }, Ident { sym: PatchSet, span: bytes(2139..2147) }, Punct { char: ':', spacing: Joint, span: bytes(2147..2148) }, Punct { char: ':', spacing: Alone, span: bytes(2148..2149) }, Ident { sym: new, span: bytes(2149..2152) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2152..2154) }, Punct { char: ';', spacing: Alone, span: bytes(2154..2155) }, Ident { sym: for, span: bytes(2169..2172) }, Ident { sym: edit, span: bytes(2173..2177) }, Ident { sym: in, span: bytes(2178..2180) }, Ident { sym: edits, span: bytes(2181..2186) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(2205..2208) }, Ident { sym: line_start, span: bytes(2209..2219) }, Punct { char: ':', spacing: Alone, span: bytes(2219..2220) }, Ident { sym: usize, span: bytes(2221..2226) }, Punct { char: '=', spacing: Alone, span: bytes(2227..2228) }, Ident { sym: edit, span: bytes(2229..2233) }, Punct { char: '.', spacing: Alone, span: bytes(2233..2234) }, Ident { sym: line_start, span: bytes(2234..2244) }, Punct { char: '.', spacing: Alone, span: bytes(2244..2245) }, Ident { sym: try_into, span: bytes(2245..2253) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2253..2255) }, Punct { char: '.', spacing: Alone, span: bytes(2255..2256) }, Ident { sym: map_err, span: bytes(2256..2263) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(2264..2265) }, Ident { sym: _, span: bytes(2265..2266) }, Punct { char: '|', spacing: Alone, span: bytes(2266..2267) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: io, span: bytes(2290..2292) }, Punct { char: ':', spacing: Joint, span: bytes(2292..2293) }, Punct { char: ':', spacing: Alone, span: bytes(2293..2294) }, Ident { sym: Error, span: bytes(2294..2299) }, Punct { char: ':', spacing: Joint, span: bytes(2299..2300) }, Punct { char: ':', spacing: Alone, span: bytes(2300..2301) }, Ident { sym: other, span: bytes(2301..2306) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: format, span: bytes(2307..2313) }, Punct { char: '!', spacing: Alone, span: bytes(2313..2314) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Invalid line_start: {}", span: bytes(2315..2339) }, Punct { char: ',', spacing: Alone, span: bytes(2339..2340) }, Ident { sym: edit, span: bytes(2341..2345) }, Punct { char: '.', spacing: Alone, span: bytes(2345..2346) }, Ident { sym: line_start, span: bytes(2346..2356) }], span: bytes(2314..2357) }], span: bytes(2306..2358) }], span: bytes(2268..2376) }], span: bytes(2263..2377) }, Punct { char: '?', spacing: Joint, span: bytes(2377..2378) }, Punct { char: ';', spacing: Alone, span: bytes(2378..2379) }, Ident { sym: let, span: bytes(2396..2399) }, Ident { sym: line_end, span: bytes(2400..2408) }, Punct { char: ':', spacing: Alone, span: bytes(2408..2409) }, Ident { sym: usize, span: bytes(2410..2415) }, Punct { char: '=', spacing: Alone, span: bytes(2416..2417) }, Ident { sym: edit, span: bytes(2418..2422) }, Punct { char: '.', spacing: Alone, span: bytes(2422..2423) }, Ident { sym: line_end, span: bytes(2423..2431) }, Punct { char: '.', spacing: Alone, span: bytes(2431..2432) }, Ident { sym: try_into, span: bytes(2432..2440) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2440..2442) }, Punct { char: '.', spacing: Alone, span: bytes(2442..2443) }, Ident { sym: map_err, span: bytes(2443..2450) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(2451..2452) }, Ident { sym: _, span: bytes(2452..2453) }, Punct { char: '|', spacing: Alone, span: bytes(2453..2454) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: io, span: bytes(2477..2479) }, Punct { char: ':', spacing: Joint, span: bytes(2479..2480) }, Punct { char: ':', spacing: Alone, span: bytes(2480..2481) }, Ident { sym: Error, span: bytes(2481..2486) }, Punct { char: ':', spacing: Joint, span: bytes(2486..2487) }, Punct { char: ':', spacing: Alone, span: bytes(2487..2488) }, Ident { sym: other, span: bytes(2488..2493) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: format, span: bytes(2494..2500) }, Punct { char: '!', spacing: Alone, span: bytes(2500..2501) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Invalid line_end: {}", span: bytes(2502..2524) }, Punct { char: ',', spacing: Alone, span: bytes(2524..2525) }, Ident { sym: edit, span: bytes(2526..2530) }, Punct { char: '.', spacing: Alone, span: bytes(2530..2531) }, Ident { sym: line_end, span: bytes(2531..2539) }], span: bytes(2501..2540) }], span: bytes(2493..2541) }], span: bytes(2455..2559) }], span: bytes(2450..2560) }, Punct { char: '?', spacing: Joint, span: bytes(2560..2561) }, Punct { char: ';', spacing: Alone, span: bytes(2561..2562) }, Ident { sym: let, span: bytes(2580..2583) }, Ident { sym: start, span: bytes(2584..2589) }, Punct { char: '=', spacing: Alone, span: bytes(2590..2591) }, Ident { sym: Boundary, span: bytes(2592..2600) }, Punct { char: ':', spacing: Joint, span: bytes(2600..2601) }, Punct { char: ':', spacing: Alone, span: bytes(2601..2602) }, Ident { sym: new, span: bytes(2602..2605) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Target, span: bytes(2606..2612) }, Punct { char: ':', spacing: Joint, span: bytes(2612..2613) }, Punct { char: ':', spacing: Alone, span: bytes(2613..2614) }, Ident { sym: Line, span: bytes(2614..2618) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line_start, span: bytes(2619..2629) }], span: bytes(2618..2630) }, Punct { char: ',', spacing: Alone, span: bytes(2630..2631) }, Ident { sym: BoundaryMode, span: bytes(2632..2644) }, Punct { char: ':', spacing: Joint, span: bytes(2644..2645) }, Punct { char: ':', spacing: Alone, span: bytes(2645..2646) }, Ident { sym: Include, span: bytes(2646..2653) }], span: bytes(2605..2654) }, Punct { char: ';', spacing: Alone, span: bytes(2654..2655) }, Ident { sym: let, span: bytes(2672..2675) }, Ident { sym: end, span: bytes(2676..2679) }, Punct { char: '=', spacing: Alone, span: bytes(2680..2681) }, Ident { sym: Boundary, span: bytes(2682..2690) }, Punct { char: ':', spacing: Joint, span: bytes(2690..2691) }, Punct { char: ':', spacing: Alone, span: bytes(2691..2692) }, Ident { sym: new, span: bytes(2692..2695) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Target, span: bytes(2696..2702) }, Punct { char: ':', spacing: Joint, span: bytes(2702..2703) }, Punct { char: ':', spacing: Alone, span: bytes(2703..2704) }, Ident { sym: Line, span: bytes(2704..2708) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line_end, span: bytes(2709..2717) }], span: bytes(2708..2718) }, Punct { char: ',', spacing: Alone, span: bytes(2718..2719) }, Ident { sym: BoundaryMode, span: bytes(2720..2732) }, Punct { char: ':', spacing: Joint, span: bytes(2732..2733) }, Punct { char: ':', spacing: Alone, span: bytes(2733..2734) }, Ident { sym: Exclude, span: bytes(2734..2741) }], span: bytes(2695..2742) }, Punct { char: ';', spacing: Alone, span: bytes(2742..2743) }, Ident { sym: let, span: bytes(2760..2763) }, Ident { sym: snippet, span: bytes(2764..2771) }, Punct { char: '=', spacing: Alone, span: bytes(2772..2773) }, Ident { sym: Snippet, span: bytes(2774..2781) }, Punct { char: ':', spacing: Joint, span: bytes(2781..2782) }, Punct { char: ':', spacing: Alone, span: bytes(2782..2783) }, Ident { sym: Between, span: bytes(2783..2790) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: start, span: bytes(2793..2798) }, Punct { char: ',', spacing: Alone, span: bytes(2798..2799) }, Ident { sym: end, span: bytes(2800..2803) }], span: bytes(2791..2805) }, Punct { char: ';', spacing: Alone, span: bytes(2805..2806) }, Ident { sym: let, span: bytes(2824..2827) }, Ident { sym: replacement, span: bytes(2828..2839) }, Punct { char: '=', spacing: Alone, span: bytes(2840..2841) }, Ident { sym: format, span: bytes(2842..2848) }, Punct { char: '!', spacing: Alone, span: bytes(2848..2849) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "\n{}\n\n", span: bytes(2850..2860) }, Punct { char: ',', spacing: Alone, span: bytes(2860..2861) }, Ident { sym: edit, span: bytes(2862..2866) }, Punct { char: '.', spacing: Alone, span: bytes(2866..2867) }, Ident { sym: section_content, span: bytes(2867..2882) }, Punct { char: '.', spacing: Alone, span: bytes(2882..2883) }, Ident { sym: trim, span: bytes(2883..2887) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2887..2889) }], span: bytes(2849..2890) }, Punct { char: ';', spacing: Alone, span: bytes(2890..2891) }, Ident { sym: let, span: bytes(2909..2912) }, Ident { sym: patch, span: bytes(2913..2918) }, Punct { char: '=', spacing: Alone, span: bytes(2919..2920) }, Ident { sym: Patch, span: bytes(2921..2926) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: file, span: bytes(2949..2953) }, Punct { char: ':', spacing: Alone, span: bytes(2953..2954) }, Ident { sym: file_name, span: bytes(2955..2964) }, Punct { char: '.', spacing: Alone, span: bytes(2964..2965) }, Ident { sym: clone, span: bytes(2965..2970) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2970..2972) }, Punct { char: ',', spacing: Alone, span: bytes(2972..2973) }, Ident { sym: snippet, span: bytes(2994..3001) }, Punct { char: ',', spacing: Alone, span: bytes(3001..3002) }, Ident { sym: replacement, span: bytes(3023..3034) }, Punct { char: ',', spacing: Alone, span: bytes(3034..3035) }], span: bytes(2927..3053) }, Punct { char: ';', spacing: Alone, span: bytes(3053..3054) }, Ident { sym: patchset, span: bytes(3072..3080) }, Punct { char: '.', spacing: Alone, span: bytes(3080..3081) }, Ident { sym: add, span: bytes(3081..3084) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: patch, span: bytes(3085..3090) }], span: bytes(3084..3091) }, Punct { char: ';', spacing: Alone, span: bytes(3091..3092) }], span: bytes(2187..3106) }, Ident { sym: let, span: bytes(3120..3123) }, Ident { sym: results, span: bytes(3124..3131) }, Punct { char: '=', spacing: Alone, span: bytes(3132..3133) }, Ident { sym: patchset, span: bytes(3134..3142) }, Punct { char: '.', spacing: Alone, span: bytes(3159..3160) }, Ident { sym: apply_to_files, span: bytes(3160..3174) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3174..3176) }, Punct { char: '.', spacing: Alone, span: bytes(3193..3194) }, Ident { sym: map_err, span: bytes(3194..3201) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(3202..3203) }, Ident { sym: e, span: bytes(3203..3204) }, Punct { char: '|', spacing: Alone, span: bytes(3204..3205) }, Ident { sym: io, span: bytes(3206..3208) }, Punct { char: ':', spacing: Joint, span: bytes(3208..3209) }, Punct { char: ':', spacing: Alone, span: bytes(3209..3210) }, Ident { sym: Error, span: bytes(3210..3215) }, Punct { char: ':', spacing: Joint, span: bytes(3215..3216) }, Punct { char: ':', spacing: Alone, span: bytes(3216..3217) }, Ident { sym: other, span: bytes(3217..3222) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: e, span: bytes(3223..3224) }, Punct { char: '.', spacing: Alone, span: bytes(3224..3225) }, Ident { sym: to_string, span: bytes(3225..3234) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3234..3236) }], span: bytes(3222..3237) }], span: bytes(3201..3238) }, Punct { char: '?', spacing: Joint, span: bytes(3238..3239) }, Punct { char: ';', spacing: Alone, span: bytes(3239..3240) }, Ident { sym: if, span: bytes(3254..3256) }, Ident { sym: let, span: bytes(3257..3260) }, Ident { sym: Some, span: bytes(3261..3265) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: new_content, span: bytes(3266..3277) }], span: bytes(3265..3278) }, Punct { char: '=', spacing: Alone, span: bytes(3279..3280) }, Ident { sym: results, span: bytes(3281..3288) }, Punct { char: '.', spacing: Alone, span: bytes(3288..3289) }, Ident { sym: get, span: bytes(3289..3292) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3293..3294) }, Ident { sym: file_name, span: bytes(3294..3303) }], span: bytes(3292..3304) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: std, span: bytes(3323..3326) }, Punct { char: ':', spacing: Joint, span: bytes(3326..3327) }, Punct { char: ':', spacing: Alone, span: bytes(3327..3328) }, Ident { sym: fs, span: bytes(3328..3330) }, Punct { char: ':', spacing: Joint, span: bytes(3330..3331) }, Punct { char: ':', spacing: Alone, span: bytes(3331..3332) }, Ident { sym: write, span: bytes(3332..3337) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(3338..3339) }, Ident { sym: file_name, span: bytes(3339..3348) }, Punct { char: ',', spacing: Alone, span: bytes(3348..3349) }, Ident { sym: new_content, span: bytes(3350..3361) }], span: bytes(3337..3362) }, Punct { char: '?', spacing: Joint, span: bytes(3362..3363) }, Punct { char: ';', spacing: Alone, span: bytes(3363..3364) }], span: bytes(3305..3378) }], span: bytes(2106..3388) }, Ident { sym: Ok, span: bytes(3398..3400) }, Group { delimiter: Parenthesis, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3401..3403) }], span: bytes(3400..3404) }], span: bytes(1807..3410) }) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: '#', spacing: Alone, span: bytes(3414..3415) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: cfg, span: bytes(3416..3419) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: test, span: bytes(3420..3424) }], span: bytes(3419..3425) }], span: bytes(3415..3426) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: '#', spacing: Alone, span: bytes(3427..3428) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: path, span: bytes(3429..3433) }, Punct { char: '=', spacing: Alone, span: bytes(3434..3435) }, Literal { lit: "tests/edit_plan.rs", span: bytes(3436..3456) }], span: bytes(3428..3457) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(3458..3461) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: tests, span: bytes(3462..3467) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(3467..3468) })
[SYNCDOC DEBUG] 
=== REFORMAT START ===
[SYNCDOC DEBUG] Original length: 3468
[SYNCDOC DEBUG] Transformed length: 1975
[SYNCDOC DEBUG] Formatted original length: 3468
[SYNCDOC DEBUG] Formatted transformed length: 2304
[SYNCDOC DEBUG] 
--- Formatted Original ---
[SYNCDOC DEBUG] //! The edit plan manages document modifications using textum patches.
//!
//! This module defines the transformation that work in the TUI manifests as actual edits on disk.
//! asterism uses textum for generic line-based patching that works with any text format.

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::io;
use textum::{Boundary, BoundaryMode, Patch, PatchSet, Snippet, Target};

/// Serialisable collection of file modifications for atomic application.
#[derive(Serialize, Deserialize, Clone)]
pub struct EditPlan {
    /// Individual section replacements grouped for batch processing.
    pub edits: Vec<Edit>,
}

/// Precise coordinates and content for replacing a section in a file.
#[derive(Serialize, Deserialize, Clone)]
pub struct Edit {
    /// Target file path for this modification.
    pub file_name: String,
    /// First line of the section to replace (inclusive).
    pub line_start: i64,
    /// Final line of the section to replace (exclusive).
    pub line_end: i64,
    /// Starting column of the section header.
    pub column_start: i64,
    /// Ending column of the section header.
    pub column_end: i64,
    /// New content replacing the section body.
    pub section_content: String,
    /// Section title for tracking and debugging edits.
    pub item_name: String,
}

impl EditPlan {
    /// Apply all edits in the plan using textum patches.
    ///
    /// Groups edits by file and uses textum's `PatchSet` to apply all changes
    /// atomically per file. Each edit targets a line range and replaces the
    /// content between those lines with the new section content.
    ///
    /// # Errors
    ///
    /// Returns an error if file operations, patching, or line number conversion fails.
    pub fn apply(&mut self) -> io::Result<()> {
        let mut file_groups: HashMap<String, Vec<&Edit>> = HashMap::new();

        for edit in &self.edits {
            file_groups
                .entry(edit.file_name.clone())
                .or_default()
                .push(edit);
        }

        for (file_name, edits) in file_groups {
            let mut patchset = PatchSet::new();

            for edit in edits {
                let line_start: usize = edit.line_start.try_into().map_err(|_| {
                    io::Error::other(format!("Invalid line_start: {}", edit.line_start))
                })?;
                let line_end: usize = edit.line_end.try_into().map_err(|_| {
                    io::Error::other(format!("Invalid line_end: {}", edit.line_end))
                })?;

                let start = Boundary::new(Target::Line(line_start), BoundaryMode::Include);
                let end = Boundary::new(Target::Line(line_end), BoundaryMode::Exclude);
                let snippet = Snippet::Between { start, end };

                let replacement = format!("\n{}\n\n", edit.section_content.trim());

                let patch = Patch {
                    file: file_name.clone(),
                    snippet,
                    replacement,
                };

                patchset.add(patch);
            }

            let results = patchset
                .apply_to_files()
                .map_err(|e| io::Error::other(e.to_string()))?;

            if let Some(new_content) = results.get(&file_name) {
                std::fs::write(&file_name, new_content)?;
            }
        }

        Ok(())
    }
}

#[cfg(test)]
#[path = "tests/edit_plan.rs"]
mod tests;

[SYNCDOC DEBUG] 
--- Formatted Transformed ---
[SYNCDOC DEBUG] # ! [doc = syncdoc :: module_doc ! ()]
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::io;
use textum::{Boundary, BoundaryMode, Patch, PatchSet, Snippet, Target};
#[syncdoc::omnidoc]
#[derive(Serialize, Deserialize, Clone)]
pub struct EditPlan {
    pub edits: Vec<Edit>,
}
#[syncdoc::omnidoc]
#[derive(Serialize, Deserialize, Clone)]
pub struct Edit {
    pub file_name: String,
    pub line_start: i64,
    pub line_end: i64,
    pub column_start: i64,
    pub column_end: i64,
    pub section_content: String,
    pub item_name: String,
}
#[syncdoc::omnidoc]
impl EditPlan {
    pub fn apply(&mut self) -> io::Result<()> {
        let mut file_groups: HashMap<String, Vec<&Edit>> = HashMap::new();
        for edit in &self.edits {
            file_groups
                .entry(edit.file_name.clone())
                .or_default()
                .push(edit);
        }
        for (file_name, edits) in file_groups {
            let mut patchset = PatchSet::new();
            for edit in edits {
                let line_start: usize = edit.line_start.try_into().map_err(|_| {
                    io::Error::other(format!("Invalid line_start: {}", edit.line_start))
                })?;
                let line_end: usize = edit.line_end.try_into().map_err(|_| {
                    io::Error::other(format!("Invalid line_end: {}", edit.line_end))
                })?;
                let start = Boundary::new(Target::Line(line_start), BoundaryMode::Include);
                let end = Boundary::new(Target::Line(line_end), BoundaryMode::Exclude);
                let snippet = Snippet::Between { start, end };
                let replacement = format!("\n{}\n\n", edit.section_content.trim());
                let patch = Patch {
                    file: file_name.clone(),
                    snippet,
                    replacement,
                };
                patchset.add(patch);
            }
            let results = patchset
                .apply_to_files()
                .map_err(|e| io::Error::other(e.to_string()))?;
            if let Some(new_content) = results.get(&file_name) {
                std::fs::write(&file_name, new_content)?;
            }
        }
        Ok(())
    }
}
#[cfg(test)]
#[path = "tests/edit_plan.rs"]
mod tests;

[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 98
[SYNCDOC DEBUG] After lines: 64
[SYNCDOC DEBUG] Hunks: 24
[SYNCDOC DEBUG] Hunk 0: before[0..5] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! The edit plan manages document modifications using textum patches."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module defines the transformation that work in the TUI manifests as actual edits on disk."
[SYNCDOC DEBUG]     [3]: "//! asterism uses textum for generic line-based patching that works with any text format."
[SYNCDOC DEBUG]     [4]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[9..11] -> after[5..6]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [9]: ""
[SYNCDOC DEBUG]     [10]: "/// Serialisable collection of file modifications for atomic application."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [5]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[13..14] -> after[8..8]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [13]: "    /// Individual section replacements grouped for batch processing."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 3: before[16..18] -> after[10..11]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [16]: ""
[SYNCDOC DEBUG]     [17]: "/// Precise coordinates and content for replacing a section in a file."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [10]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 4: before[20..21] -> after[13..13]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [20]: "    /// Target file path for this modification."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[22..23] -> after[14..14]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [22]: "    /// First line of the section to replace (inclusive)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[24..25] -> after[15..15]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [24]: "    /// Final line of the section to replace (exclusive)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 7: before[26..27] -> after[16..16]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [26]: "    /// Starting column of the section header."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 8: before[28..29] -> after[17..17]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [28]: "    /// Ending column of the section header."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 9: before[30..31] -> after[18..18]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [30]: "    /// New content replacing the section body."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 10: before[32..33] -> after[19..19]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [32]: "    /// Section title for tracking and debugging edits."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 11: before[35..36] -> after[21..22]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [35]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [21]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 12: before[37..46] -> after[23..23]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [37]: "    /// Apply all edits in the plan using textum patches."
[SYNCDOC DEBUG]     [38]: "    ///"
[SYNCDOC DEBUG]     [39]: "    /// Groups edits by file and uses textum's `PatchSet` to apply all changes"
[SYNCDOC DEBUG]     [40]: "    /// atomically per file. Each edit targets a line range and replaces the"
[SYNCDOC DEBUG]     [41]: "    /// content between those lines with the new section content."
[SYNCDOC DEBUG]     [42]: "    ///"
[SYNCDOC DEBUG]     [43]: "    /// # Errors"
[SYNCDOC DEBUG]     [44]: "    ///"
[SYNCDOC DEBUG]     [45]: "    /// Returns an error if file operations, patching, or line number conversion fails."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 13: before[48..49] -> after[25..25]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [48]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 14: before[55..56] -> after[31..31]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [55]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 15: before[58..59] -> after[33..33]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [58]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 16: before[66..67] -> after[40..40]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [66]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 17: before[70..71] -> after[43..43]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [70]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 18: before[72..73] -> after[44..44]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [72]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 19: before[78..79] -> after[49..49]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [78]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 20: before[81..82] -> after[51..51]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [81]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 21: before[85..86] -> after[54..54]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [85]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 22: before[90..91] -> after[58..58]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [90]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 23: before[94..95] -> after[61..61]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [94]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] DEBUG restore: Found 24 hunks
[SYNCDOC DEBUG]   Hunk 0: before[0..5] after[0..1]
[SYNCDOC DEBUG]   Hunk 1: before[9..11] after[5..6]
[SYNCDOC DEBUG]   Hunk 2: before[13..14] after[8..8]
[SYNCDOC DEBUG]   Hunk 3: before[16..18] after[10..11]
[SYNCDOC DEBUG]   Hunk 4: before[20..21] after[13..13]
[SYNCDOC DEBUG]   Hunk 5: before[22..23] after[14..14]
[SYNCDOC DEBUG]   Hunk 6: before[24..25] after[15..15]
[SYNCDOC DEBUG]   Hunk 7: before[26..27] after[16..16]
[SYNCDOC DEBUG]   Hunk 8: before[28..29] after[17..17]
[SYNCDOC DEBUG]   Hunk 9: before[30..31] after[18..18]
[SYNCDOC DEBUG]   Hunk 10: before[32..33] after[19..19]
[SYNCDOC DEBUG]   Hunk 11: before[35..36] after[21..22]
[SYNCDOC DEBUG]   Hunk 12: before[37..46] after[23..23]
[SYNCDOC DEBUG]   Hunk 13: before[48..49] after[25..25]
[SYNCDOC DEBUG]   Hunk 14: before[55..56] after[31..31]
[SYNCDOC DEBUG]   Hunk 15: before[58..59] after[33..33]
[SYNCDOC DEBUG]   Hunk 16: before[66..67] after[40..40]
[SYNCDOC DEBUG]   Hunk 17: before[70..71] after[43..43]
[SYNCDOC DEBUG]   Hunk 18: before[72..73] after[44..44]
[SYNCDOC DEBUG]   Hunk 19: before[78..79] after[49..49]
[SYNCDOC DEBUG]   Hunk 20: before[81..82] after[51..51]
[SYNCDOC DEBUG]   Hunk 21: before[85..86] after[54..54]
[SYNCDOC DEBUG]   Hunk 22: before[90..91] after[58..58]
[SYNCDOC DEBUG]   Hunk 23: before[94..95] after[61..61]
[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 98
[SYNCDOC DEBUG] After lines: 64
[SYNCDOC DEBUG] Hunks: 24
[SYNCDOC DEBUG] Hunk 0: before[0..5] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! The edit plan manages document modifications using textum patches."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module defines the transformation that work in the TUI manifests as actual edits on disk."
[SYNCDOC DEBUG]     [3]: "//! asterism uses textum for generic line-based patching that works with any text format."
[SYNCDOC DEBUG]     [4]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[9..11] -> after[5..6]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [9]: ""
[SYNCDOC DEBUG]     [10]: "/// Serialisable collection of file modifications for atomic application."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [5]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[13..14] -> after[8..8]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [13]: "    /// Individual section replacements grouped for batch processing."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 3: before[16..18] -> after[10..11]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [16]: ""
[SYNCDOC DEBUG]     [17]: "/// Precise coordinates and content for replacing a section in a file."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [10]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 4: before[20..21] -> after[13..13]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [20]: "    /// Target file path for this modification."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[22..23] -> after[14..14]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [22]: "    /// First line of the section to replace (inclusive)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[24..25] -> after[15..15]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [24]: "    /// Final line of the section to replace (exclusive)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 7: before[26..27] -> after[16..16]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [26]: "    /// Starting column of the section header."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 8: before[28..29] -> after[17..17]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [28]: "    /// Ending column of the section header."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 9: before[30..31] -> after[18..18]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [30]: "    /// New content replacing the section body."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 10: before[32..33] -> after[19..19]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [32]: "    /// Section title for tracking and debugging edits."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 11: before[35..36] -> after[21..22]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [35]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [21]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 12: before[37..46] -> after[23..23]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [37]: "    /// Apply all edits in the plan using textum patches."
[SYNCDOC DEBUG]     [38]: "    ///"
[SYNCDOC DEBUG]     [39]: "    /// Groups edits by file and uses textum's `PatchSet` to apply all changes"
[SYNCDOC DEBUG]     [40]: "    /// atomically per file. Each edit targets a line range and replaces the"
[SYNCDOC DEBUG]     [41]: "    /// content between those lines with the new section content."
[SYNCDOC DEBUG]     [42]: "    ///"
[SYNCDOC DEBUG]     [43]: "    /// # Errors"
[SYNCDOC DEBUG]     [44]: "    ///"
[SYNCDOC DEBUG]     [45]: "    /// Returns an error if file operations, patching, or line number conversion fails."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 13: before[48..49] -> after[25..25]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [48]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 14: before[55..56] -> after[31..31]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [55]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 15: before[58..59] -> after[33..33]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [58]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 16: before[66..67] -> after[40..40]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [66]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 17: before[70..71] -> after[43..43]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [70]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 18: before[72..73] -> after[44..44]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [72]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 19: before[78..79] -> after[49..49]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [78]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 20: before[81..82] -> after[51..51]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [81]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 21: before[85..86] -> after[54..54]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [85]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 22: before[90..91] -> after[58..58]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [90]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 23: before[94..95] -> after[61..61]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [94]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 0..5 (adds 1 lines, removes 5 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 9..11 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 13..14 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 16..18 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 20..21 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 22..23 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 24..25 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 26..27 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 28..29 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 30..31 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 32..33 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 35..36 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 37..46 (adds 0 lines, removes 9 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 48..49
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 55..56
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 58..59
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 66..67
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 70..71
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 72..73
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 78..79
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 81..82
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 85..86
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 90..91
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 94..95
[SYNCDOC DEBUG] Original != Result: true
[SYNCDOC DEBUG] 
=== BOOKEND DEBUG START ===
[SYNCDOC DEBUG] Input code length: 2318
[SYNCDOC DEBUG] 
Line 0: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       -> Starts with #!
[SYNCDOC DEBUG]       -> Checking trigger "syncdoc::module_doc!": true
[SYNCDOC DEBUG]       -> Has trigger: true
[SYNCDOC DEBUG]   -> NEEDS BOOKENDING
[SYNCDOC DEBUG]     reformat_line for: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     extract_bookend_content:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       Found #![ at position: 0
[SYNCDOC DEBUG]       Found ] at position: 29
[SYNCDOC DEBUG]       Extracted content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Got content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Created bookended expr: "const _: i32 = { doc=syncdoc::module_doc!() };"
[SYNCDOC DEBUG]     Rustfmt output: "const _: i32 = { doc = syncdoc::module_doc!() };\n"
[SYNCDOC DEBUG]     Stripped bookends: "doc = syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Final result: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG]   -> Reformatted to: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG] 
Line 1: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 2: "use serde::{Deserialize, Serialize};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use serde::{Deserialize, Serialize};"
[SYNCDOC DEBUG]       no_spaces: "useserde::{Deserialize,Serialize};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 3: "use std::collections::HashMap;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::collections::HashMap;"
[SYNCDOC DEBUG]       no_spaces: "usestd::collections::HashMap;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 4: "use std::io;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::io;"
[SYNCDOC DEBUG]       no_spaces: "usestd::io;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 5: "use textum::{Boundary, BoundaryMode, Patch, PatchSet, Snippet, Target};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use textum::{Boundary, BoundaryMode, Patch, PatchSet, Snippet, Target};"
[SYNCDOC DEBUG]       no_spaces: "usetextum::{Boundary,BoundaryMode,Patch,PatchSet,Snippet,Target};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 6: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 7: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 8: "#[derive(Serialize, Deserialize, Clone)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[derive(Serialize, Deserialize, Clone)]"
[SYNCDOC DEBUG]       no_spaces: "#[derive(Serialize,Deserialize,Clone)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 9: "pub struct EditPlan {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub struct EditPlan {"
[SYNCDOC DEBUG]       no_spaces: "pubstructEditPlan{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 10: "    pub edits: Vec<Edit>,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub edits: Vec<Edit>,"
[SYNCDOC DEBUG]       no_spaces: "pubedits:Vec<Edit>,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 11: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 12: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 13: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 14: "#[derive(Serialize, Deserialize, Clone)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[derive(Serialize, Deserialize, Clone)]"
[SYNCDOC DEBUG]       no_spaces: "#[derive(Serialize,Deserialize,Clone)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 15: "pub struct Edit {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub struct Edit {"
[SYNCDOC DEBUG]       no_spaces: "pubstructEdit{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 16: "    pub file_name: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub file_name: String,"
[SYNCDOC DEBUG]       no_spaces: "pubfile_name:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 17: "    pub line_start: i64,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub line_start: i64,"
[SYNCDOC DEBUG]       no_spaces: "publine_start:i64,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 18: "    pub line_end: i64,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub line_end: i64,"
[SYNCDOC DEBUG]       no_spaces: "publine_end:i64,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 19: "    pub column_start: i64,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub column_start: i64,"
[SYNCDOC DEBUG]       no_spaces: "pubcolumn_start:i64,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 20: "    pub column_end: i64,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub column_end: i64,"
[SYNCDOC DEBUG]       no_spaces: "pubcolumn_end:i64,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 21: "    pub section_content: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub section_content: String,"
[SYNCDOC DEBUG]       no_spaces: "pubsection_content:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 22: "    pub item_name: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub item_name: String,"
[SYNCDOC DEBUG]       no_spaces: "pubitem_name:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 23: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 24: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 25: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 26: "impl EditPlan {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "impl EditPlan {"
[SYNCDOC DEBUG]       no_spaces: "implEditPlan{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 27: "    pub fn apply(&mut self) -> io::Result<()> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub fn apply(&mut self) -> io::Result<()> {"
[SYNCDOC DEBUG]       no_spaces: "pubfnapply(&mutself)->io::Result<()>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 28: "        let mut file_groups: HashMap<String, Vec<&Edit>> = HashMap::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut file_groups: HashMap<String, Vec<&Edit>> = HashMap::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutfile_groups:HashMap<String,Vec<&Edit>>=HashMap::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 29: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 30: "        for edit in &self.edits {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for edit in &self.edits {"
[SYNCDOC DEBUG]       no_spaces: "foreditin&self.edits{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 31: "            file_groups"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file_groups"
[SYNCDOC DEBUG]       no_spaces: "file_groups"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 32: "                .entry(edit.file_name.clone())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".entry(edit.file_name.clone())"
[SYNCDOC DEBUG]       no_spaces: ".entry(edit.file_name.clone())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 33: "                .or_default()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".or_default()"
[SYNCDOC DEBUG]       no_spaces: ".or_default()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 34: "                .push(edit);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".push(edit);"
[SYNCDOC DEBUG]       no_spaces: ".push(edit);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 35: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 36: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 37: "        for (file_name, edits) in file_groups {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for (file_name, edits) in file_groups {"
[SYNCDOC DEBUG]       no_spaces: "for(file_name,edits)infile_groups{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 38: "            let mut patchset = PatchSet::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut patchset = PatchSet::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutpatchset=PatchSet::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 39: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 40: "            for edit in edits {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for edit in edits {"
[SYNCDOC DEBUG]       no_spaces: "foreditinedits{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 41: "                let line_start: usize = edit.line_start.try_into().map_err(|_| {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let line_start: usize = edit.line_start.try_into().map_err(|_| {"
[SYNCDOC DEBUG]       no_spaces: "letline_start:usize=edit.line_start.try_into().map_err(|_|{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 42: "                    io::Error::other(format!(\"Invalid line_start: {}\", edit.line_start))"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "io::Error::other(format!(\"Invalid line_start: {}\", edit.line_start))"
[SYNCDOC DEBUG]       no_spaces: "io::Error::other(format!(\"Invalidline_start:{}\",edit.line_start))"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 43: "                })?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "})?;"
[SYNCDOC DEBUG]       no_spaces: "})?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 44: "                let line_end: usize = edit.line_end.try_into().map_err(|_| {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let line_end: usize = edit.line_end.try_into().map_err(|_| {"
[SYNCDOC DEBUG]       no_spaces: "letline_end:usize=edit.line_end.try_into().map_err(|_|{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 45: "                    io::Error::other(format!(\"Invalid line_end: {}\", edit.line_end))"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "io::Error::other(format!(\"Invalid line_end: {}\", edit.line_end))"
[SYNCDOC DEBUG]       no_spaces: "io::Error::other(format!(\"Invalidline_end:{}\",edit.line_end))"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 46: "                })?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "})?;"
[SYNCDOC DEBUG]       no_spaces: "})?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 47: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 48: "                let start = Boundary::new(Target::Line(line_start), BoundaryMode::Include);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let start = Boundary::new(Target::Line(line_start), BoundaryMode::Include);"
[SYNCDOC DEBUG]       no_spaces: "letstart=Boundary::new(Target::Line(line_start),BoundaryMode::Include);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 49: "                let end = Boundary::new(Target::Line(line_end), BoundaryMode::Exclude);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let end = Boundary::new(Target::Line(line_end), BoundaryMode::Exclude);"
[SYNCDOC DEBUG]       no_spaces: "letend=Boundary::new(Target::Line(line_end),BoundaryMode::Exclude);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 50: "                let snippet = Snippet::Between { start, end };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let snippet = Snippet::Between { start, end };"
[SYNCDOC DEBUG]       no_spaces: "letsnippet=Snippet::Between{start,end};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 51: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 52: "                let replacement = format!(\"\\n{}\\n\\n\", edit.section_content.trim());"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let replacement = format!(\"\\n{}\\n\\n\", edit.section_content.trim());"
[SYNCDOC DEBUG]       no_spaces: "letreplacement=format!(\"\\n{}\\n\\n\",edit.section_content.trim());"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 53: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 54: "                let patch = Patch {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let patch = Patch {"
[SYNCDOC DEBUG]       no_spaces: "letpatch=Patch{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 55: "                    file: file_name.clone(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file: file_name.clone(),"
[SYNCDOC DEBUG]       no_spaces: "file:file_name.clone(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 56: "                    snippet,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "snippet,"
[SYNCDOC DEBUG]       no_spaces: "snippet,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 57: "                    replacement,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "replacement,"
[SYNCDOC DEBUG]       no_spaces: "replacement,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 58: "                };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 59: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 60: "                patchset.add(patch);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "patchset.add(patch);"
[SYNCDOC DEBUG]       no_spaces: "patchset.add(patch);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 61: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 62: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 63: "            let results = patchset"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let results = patchset"
[SYNCDOC DEBUG]       no_spaces: "letresults=patchset"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 64: "                .apply_to_files()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".apply_to_files()"
[SYNCDOC DEBUG]       no_spaces: ".apply_to_files()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 65: "                .map_err(|e| io::Error::other(e.to_string()))?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map_err(|e| io::Error::other(e.to_string()))?;"
[SYNCDOC DEBUG]       no_spaces: ".map_err(|e|io::Error::other(e.to_string()))?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 66: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 67: "            if let Some(new_content) = results.get(&file_name) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(new_content) = results.get(&file_name) {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(new_content)=results.get(&file_name){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 68: "                std::fs::write(&file_name, new_content)?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "std::fs::write(&file_name, new_content)?;"
[SYNCDOC DEBUG]       no_spaces: "std::fs::write(&file_name,new_content)?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 69: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 70: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 71: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 72: "        Ok(())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Ok(())"
[SYNCDOC DEBUG]       no_spaces: "Ok(())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 73: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 74: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 75: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 76: "#[cfg(test)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[cfg(test)]"
[SYNCDOC DEBUG]       no_spaces: "#[cfg(test)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 77: "#[path = \"tests/edit_plan.rs\"]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[path = \"tests/edit_plan.rs\"]"
[SYNCDOC DEBUG]       no_spaces: "#[path=\"tests/edit_plan.rs\"]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 78: "mod tests;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "mod tests;"
[SYNCDOC DEBUG]       no_spaces: "modtests;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Final result length: 2312
[SYNCDOC DEBUG] === BOOKEND DEBUG END ===

[SYNCDOC DEBUG] After bookending: 1975
[SYNCDOC DEBUG] 
--- Final Result ---
[SYNCDOC DEBUG] #![doc = syncdoc::module_doc!()]

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::io;
use textum::{Boundary, BoundaryMode, Patch, PatchSet, Snippet, Target};

#[syncdoc::omnidoc]
#[derive(Serialize, Deserialize, Clone)]
pub struct EditPlan {
    pub edits: Vec<Edit>,
}

#[syncdoc::omnidoc]
#[derive(Serialize, Deserialize, Clone)]
pub struct Edit {
    pub file_name: String,
    pub line_start: i64,
    pub line_end: i64,
    pub column_start: i64,
    pub column_end: i64,
    pub section_content: String,
    pub item_name: String,
}

#[syncdoc::omnidoc]
impl EditPlan {
    pub fn apply(&mut self) -> io::Result<()> {
        let mut file_groups: HashMap<String, Vec<&Edit>> = HashMap::new();

        for edit in &self.edits {
            file_groups
                .entry(edit.file_name.clone())
                .or_default()
                .push(edit);
        }

        for (file_name, edits) in file_groups {
            let mut patchset = PatchSet::new();

            for edit in edits {
                let line_start: usize = edit.line_start.try_into().map_err(|_| {
                    io::Error::other(format!("Invalid line_start: {}", edit.line_start))
                })?;
                let line_end: usize = edit.line_end.try_into().map_err(|_| {
                    io::Error::other(format!("Invalid line_end: {}", edit.line_end))
                })?;

                let start = Boundary::new(Target::Line(line_start), BoundaryMode::Include);
                let end = Boundary::new(Target::Line(line_end), BoundaryMode::Exclude);
                let snippet = Snippet::Between { start, end };

                let replacement = format!("\n{}\n\n", edit.section_content.trim());

                let patch = Patch {
                    file: file_name.clone(),
                    snippet,
                    replacement,
                };

                patchset.add(patch);
            }

            let results = patchset
                .apply_to_files()
                .map_err(|e| io::Error::other(e.to_string()))?;

            if let Some(new_content) = results.get(&file_name) {
                std::fs::write(&file_name, new_content)?;
            }
        }

        Ok(())
    }
}

#[cfg(test)]
#[path = "tests/edit_plan.rs"]
mod tests;

[SYNCDOC DEBUG] === REFORMAT END ===

[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: pub, span: bytes(3555..3558) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(3559..3562) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: edit_plan, span: bytes(3563..3572) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(3572..3573) })
[SYNCDOC DEBUG] 
=== REFORMAT START ===
[SYNCDOC DEBUG] Original length: 19
[SYNCDOC DEBUG] Transformed length: 19
[SYNCDOC DEBUG] Formatted original length: 19
[SYNCDOC DEBUG] Formatted transformed length: 19
[SYNCDOC DEBUG] 
--- Formatted Original ---
[SYNCDOC DEBUG] pub mod edit_plan;

[SYNCDOC DEBUG] 
--- Formatted Transformed ---
[SYNCDOC DEBUG] pub mod edit_plan;

[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 1
[SYNCDOC DEBUG] After lines: 1
[SYNCDOC DEBUG] Hunks: 0
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] DEBUG restore: Found 0 hunks
[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 1
[SYNCDOC DEBUG] After lines: 1
[SYNCDOC DEBUG] Hunks: 0
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] Original != Result: true
[SYNCDOC DEBUG] 
=== BOOKEND DEBUG START ===
[SYNCDOC DEBUG] Input code length: 18
[SYNCDOC DEBUG] 
Line 0: "pub mod edit_plan;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub mod edit_plan;"
[SYNCDOC DEBUG]       no_spaces: "pubmodedit_plan;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Final result length: 18
[SYNCDOC DEBUG] === BOOKEND DEBUG END ===

[SYNCDOC DEBUG] After bookending: 19
[SYNCDOC DEBUG] 
--- Final Result ---
[SYNCDOC DEBUG] pub mod edit_plan;

[SYNCDOC DEBUG] === REFORMAT END ===


=== Migration Summary ===
Processed 2 file(s)
Extracted 12 documentation(s)
Touched 1 missing file(s)
Rewrote 2 file(s)
