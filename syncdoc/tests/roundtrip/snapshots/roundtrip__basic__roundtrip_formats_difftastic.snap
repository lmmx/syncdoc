---
source: syncdoc/tests/roundtrip/basic.rs
expression: result.migrate_stderr
---
[SYNCDOC DEBUG] get_docs_path called:
[SYNCDOC DEBUG]   source_file: src
[SYNCDOC DEBUG]   manifest_dir: /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   docs_path from toml: docs
[SYNCDOC DEBUG]   manifest_path (canonical): /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   source_dir (canonical): /tmp/.tmpXXXXXX
[SYNCDOC DEBUG]   relative_path (stripped): 
[SYNCDOC DEBUG]   depth: 0
[SYNCDOC DEBUG]   final result: docs
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(226..229) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: crate, span: bytes(230..235) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(235..236) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(236..237) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: formats, span: bytes(237..244) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(244..245) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(245..246) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: Format, span: bytes(246..252) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(252..253) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(254..257) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: crate, span: bytes(258..263) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(263..264) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(264..265) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: section, span: bytes(265..272) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(272..273) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(273..274) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: ChunkType, span: bytes(275..284) }, Punct { char: ',', spacing: Alone, span: bytes(284..285) }, Ident { sym: Section, span: bytes(286..293) }], span: bytes(274..294) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(294..295) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(296..299) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: ratatui, span: bytes(300..307) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(307..308) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(308..309) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: style, span: bytes(315..320) }, Punct { char: ':', spacing: Joint, span: bytes(320..321) }, Punct { char: ':', spacing: Alone, span: bytes(321..322) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: Color, span: bytes(323..328) }, Punct { char: ',', spacing: Alone, span: bytes(328..329) }, Ident { sym: Style, span: bytes(330..335) }], span: bytes(322..336) }, Punct { char: ',', spacing: Alone, span: bytes(336..337) }, Ident { sym: text, span: bytes(342..346) }, Punct { char: ':', spacing: Joint, span: bytes(346..347) }, Punct { char: ':', spacing: Alone, span: bytes(347..348) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: Line, span: bytes(349..353) }, Punct { char: ',', spacing: Alone, span: bytes(353..354) }, Ident { sym: Span, span: bytes(355..359) }], span: bytes(348..360) }, Punct { char: ',', spacing: Alone, span: bytes(360..361) }], span: bytes(309..363) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(363..364) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(365..368) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: serde, span: bytes(369..374) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(374..375) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(375..376) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: Deserialize, span: bytes(377..388) }, Punct { char: ',', spacing: Alone, span: bytes(388..389) }, Ident { sym: Serialize, span: bytes(390..399) }], span: bytes(376..400) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(400..401) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(402..405) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: serde_json, span: bytes(406..416) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(416..417) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(417..418) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: Value, span: bytes(418..423) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(423..424) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(425..428) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(429..432) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(432..433) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(433..434) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: fmt, span: bytes(434..437) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(437..438) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(438..439) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: Write, span: bytes(439..444) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(444..445) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(446..449) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(450..453) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(453..454) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(454..455) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: path, span: bytes(455..459) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(459..460) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(460..461) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: Path, span: bytes(461..465) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(465..466) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: use, span: bytes(467..470) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: std, span: bytes(471..474) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Joint, span: bytes(474..475) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ':', spacing: Alone, span: bytes(475..476) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Brace, stream: TokenStream [Ident { sym: fs, span: bytes(477..479) }, Punct { char: ',', spacing: Alone, span: bytes(479..480) }, Ident { sym: io, span: bytes(481..483) }], span: bytes(476..484) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(484..485) })
[SYNCDOC DEBUG] Processing item type: Struct
[SYNCDOC DEBUG] Processing item: Struct(StructSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(487..529) }, Punct { char: '=', spacing: Alone, span: bytes(487..529) }, Literal { lit: " Represents a file in difftastic output", span: bytes(487..529) }], span: bytes(487..529) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: derive, span: bytes(532..538) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Debug, span: bytes(539..544) }, Punct { char: ',', spacing: Alone, span: bytes(544..545) }, Ident { sym: Serialize, span: bytes(546..555) }, Punct { char: ',', spacing: Alone, span: bytes(555..556) }, Ident { sym: Deserialize, span: bytes(557..568) }], span: bytes(538..569) }], span: bytes(531..570) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(571..574) }, string: "pub" }))), _struct: KStruct(Cached<proc_macro2::Ident> { value: Ident { sym: struct, span: bytes(575..581) }, string: "struct" }), name: Ident { sym: DifftFile, span: bytes(582..591) }, generics: None, where_clause: None, body: Named(BraceGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(598..672) }, Punct { char: '=', spacing: Alone, span: bytes(598..672) }, Literal { lit: " Programming language identified by difftastic for syntax highlighting.", span: bytes(598..672) }], span: bytes(598..672) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(677..680) }, string: "pub" }))), name: Ident { sym: language, span: bytes(681..689) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(691..697) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(703..749) }, Punct { char: '=', spacing: Alone, span: bytes(703..749) }, Literal { lit: " File path relative to the comparison root.", span: bytes(703..749) }], span: bytes(703..749) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(754..757) }, string: "pub" }))), name: Ident { sym: path, span: bytes(758..762) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(764..770) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(776..844) }, Punct { char: '=', spacing: Alone, span: bytes(776..844) }, Literal { lit: " Grouped diff hunks, each containing lines that changed together.", span: bytes(776..844) }], span: bytes(776..844) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: serde, span: bytes(851..856) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: default, span: bytes(857..864) }], span: bytes(856..865) }], span: bytes(850..866) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(871..874) }, string: "pub" }))), name: Ident { sym: chunks, span: bytes(875..881) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Option, span: bytes(883..889) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(890..893) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(894..897) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: DifftLine, span: bytes(898..907) })) }], third: Operator<'>'> })) }], third: Operator<'>'> })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(916..991) }, Punct { char: '=', spacing: Alone, span: bytes(916..991) }, Literal { lit: " Change classification: \"unchanged\", \"changed\", \"created\", or \"deleted\".", span: bytes(916..991) }], span: bytes(916..991) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(996..999) }, string: "pub" }))), name: Ident { sym: status, span: bytes(1000..1006) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(1008..1014) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }])))) })
[SYNCDOC DEBUG] Processing item type: Struct
[SYNCDOC DEBUG] Processing item: Struct(StructSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1019..1056) }, Punct { char: '=', spacing: Alone, span: bytes(1019..1056) }, Literal { lit: " Represents a line in a diff chunk", span: bytes(1019..1056) }], span: bytes(1019..1056) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: derive, span: bytes(1059..1065) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Debug, span: bytes(1066..1071) }, Punct { char: ',', spacing: Alone, span: bytes(1071..1072) }, Ident { sym: Serialize, span: bytes(1073..1082) }, Punct { char: ',', spacing: Alone, span: bytes(1082..1083) }, Ident { sym: Deserialize, span: bytes(1084..1095) }], span: bytes(1065..1096) }], span: bytes(1058..1097) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1098..1101) }, string: "pub" }))), _struct: KStruct(Cached<proc_macro2::Ident> { value: Ident { sym: struct, span: bytes(1102..1108) }, string: "struct" }), name: Ident { sym: DifftLine, span: bytes(1109..1118) }, generics: None, where_clause: None, body: Named(BraceGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1125..1200) }, Punct { char: '=', spacing: Alone, span: bytes(1125..1200) }, Literal { lit: " Left-hand (original) side of the comparison, absent for pure additions.", span: bytes(1125..1200) }], span: bytes(1125..1200) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: serde, span: bytes(1207..1212) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: skip_serializing_if, span: bytes(1213..1232) }, Punct { char: '=', spacing: Alone, span: bytes(1233..1234) }, Literal { lit: "Option::is_none", span: bytes(1235..1252) }], span: bytes(1212..1253) }], span: bytes(1206..1254) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1259..1262) }, string: "pub" }))), name: Ident { sym: lhs, span: bytes(1263..1266) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Option, span: bytes(1268..1274) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: DifftSide, span: bytes(1275..1284) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1291..1367) }, Punct { char: '=', spacing: Alone, span: bytes(1291..1367) }, Literal { lit: " Right-hand (modified) side of the comparison, absent for pure deletions.", span: bytes(1291..1367) }], span: bytes(1291..1367) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: serde, span: bytes(1374..1379) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: skip_serializing_if, span: bytes(1380..1399) }, Punct { char: '=', spacing: Alone, span: bytes(1400..1401) }, Literal { lit: "Option::is_none", span: bytes(1402..1419) }], span: bytes(1379..1420) }], span: bytes(1373..1421) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1426..1429) }, string: "pub" }))), name: Ident { sym: rhs, span: bytes(1430..1433) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Option, span: bytes(1435..1441) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: DifftSide, span: bytes(1442..1451) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }])))) })
[SYNCDOC DEBUG] Processing item type: Struct
[SYNCDOC DEBUG] Processing item: Struct(StructSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1457..1511) }, Punct { char: '=', spacing: Alone, span: bytes(1457..1511) }, Literal { lit: " Represents one side (left or right) of a diff line", span: bytes(1457..1511) }], span: bytes(1457..1511) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: derive, span: bytes(1514..1520) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Debug, span: bytes(1521..1526) }, Punct { char: ',', spacing: Alone, span: bytes(1526..1527) }, Ident { sym: Serialize, span: bytes(1528..1537) }, Punct { char: ',', spacing: Alone, span: bytes(1537..1538) }, Ident { sym: Deserialize, span: bytes(1539..1550) }], span: bytes(1520..1551) }], span: bytes(1513..1552) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1553..1556) }, string: "pub" }))), _struct: KStruct(Cached<proc_macro2::Ident> { value: Ident { sym: struct, span: bytes(1557..1563) }, string: "struct" }), name: Ident { sym: DifftSide, span: bytes(1564..1573) }, generics: None, where_clause: None, body: Named(BraceGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1580..1638) }, Punct { char: '=', spacing: Alone, span: bytes(1580..1638) }, Literal { lit: " Original line position in the source file (1-indexed).", span: bytes(1580..1638) }], span: bytes(1580..1638) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1643..1646) }, string: "pub" }))), name: Ident { sym: line_number, span: bytes(1647..1658) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: u32, span: bytes(1660..1663) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1669..1737) }, Punct { char: '=', spacing: Alone, span: bytes(1669..1737) }, Literal { lit: " Structural changes within this line, ordered by column position.", span: bytes(1669..1737) }], span: bytes(1669..1737) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1742..1745) }, string: "pub" }))), name: Ident { sym: changes, span: bytes(1746..1753) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(1755..1758) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: DifftChange, span: bytes(1759..1770) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }])))) })
[SYNCDOC DEBUG] Processing item type: Struct
[SYNCDOC DEBUG] Processing item: Struct(StructSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1776..1813) }, Punct { char: '=', spacing: Alone, span: bytes(1776..1813) }, Literal { lit: " Represents a change within a line", span: bytes(1776..1813) }], span: bytes(1776..1813) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: derive, span: bytes(1816..1822) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Debug, span: bytes(1823..1828) }, Punct { char: ',', spacing: Alone, span: bytes(1828..1829) }, Ident { sym: Serialize, span: bytes(1830..1839) }, Punct { char: ',', spacing: Alone, span: bytes(1839..1840) }, Ident { sym: Deserialize, span: bytes(1841..1852) }], span: bytes(1822..1853) }], span: bytes(1815..1854) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1855..1858) }, string: "pub" }))), _struct: KStruct(Cached<proc_macro2::Ident> { value: Ident { sym: struct, span: bytes(1859..1865) }, string: "struct" }), name: Ident { sym: DifftChange, span: bytes(1866..1877) }, generics: None, where_clause: None, body: Named(BraceGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1884..1939) }, Punct { char: '=', spacing: Alone, span: bytes(1884..1939) }, Literal { lit: " Column offset where this change begins (0-indexed).", span: bytes(1884..1939) }], span: bytes(1884..1939) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(1944..1947) }, string: "pub" }))), name: Ident { sym: start, span: bytes(1948..1953) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: u32, span: bytes(1955..1958) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(1964..2017) }, Punct { char: '=', spacing: Alone, span: bytes(1964..2017) }, Literal { lit: " Column offset where this change ends (exclusive).", span: bytes(1964..2017) }], span: bytes(1964..2017) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(2022..2025) }, string: "pub" }))), name: Ident { sym: end, span: bytes(2026..2029) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: u32, span: bytes(2031..2034) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2040..2080) }, Punct { char: '=', spacing: Alone, span: bytes(2040..2080) }, Literal { lit: " Text content of this change segment.", span: bytes(2040..2080) }], span: bytes(2040..2080) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(2085..2088) }, string: "pub" }))), name: Ident { sym: content, span: bytes(2089..2096) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(2098..2104) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::StructField, unsynn::operator::Operator<','>> { value: StructField { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2110..2206) }, Punct { char: '=', spacing: Alone, span: bytes(2110..2206) }, Literal { lit: " Syntax category for rendering: \"delimiter\", \"string\", \"keyword\", \"comment\", \"type\", \"normal\"", span: bytes(2110..2206) }], span: bytes(2110..2206) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2211..2240) }, Punct { char: '=', spacing: Alone, span: bytes(2211..2240) }, Literal { lit: " or \"`tree_sitter_error`\".", span: bytes(2211..2240) }], span: bytes(2211..2240) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(2245..2248) }, string: "pub" }))), name: Ident { sym: highlight, span: bytes(2249..2258) }, _colon: Operator<':'>, field_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::operator::Operator<','>, unsynn::group::BraceGroup>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(2260..2266) })) }, delimiter: Some(Nothing) }]) }, delimiter: Some(Operator<','>) }])))) })
[SYNCDOC DEBUG] Processing item type: Struct
[SYNCDOC DEBUG] Processing item: Struct(StructSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(2271..2300) }, Punct { char: '=', spacing: Alone, span: bytes(2271..2300) }, Literal { lit: " Difftastic format handler", span: bytes(2271..2300) }], span: bytes(2271..2300) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(2301..2304) }, string: "pub" }))), _struct: KStruct(Cached<proc_macro2::Ident> { value: Ident { sym: struct, span: bytes(2305..2311) }, string: "struct" }), name: Ident { sym: DifftasticFormat, span: bytes(2312..2328) }, generics: None, where_clause: None, body: Unit(Operator<';'>) })
[SYNCDOC DEBUG] Processing item type: ImplBlock
[SYNCDOC DEBUG] Processing item: ImplBlock(ImplBlockSig { attributes: None, _impl: KImpl(Cached<proc_macro2::Ident> { value: Ident { sym: impl, span: bytes(2331..2335) }, string: "impl" }), generics: None, target_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree> { first: Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, second: Ident { sym: Format, span: bytes(2336..2342) } }, delimiter: Some(Nothing) }]), for_trait: Some(Cons<syncdoc_core::parse::KFor, unsynn::container::Repeats<1, usize::MAX, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, proc_macro2::TokenTree>>> { first: KFor(Cached<proc_macro2::Ident> { value: Ident { sym: for, span: bytes(2343..2346) }, string: "for" }), second: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, proc_macro2::TokenTree> { first: Except<unsynn::group::BraceGroup>, second: Ident { sym: DifftasticFormat, span: bytes(2347..2363) } }, delimiter: Some(Nothing) }]) }), where_clause: None, items: BraceGroupContaining < syncdoc_core::parse::ModuleContent>(ModuleContent { inner_attrs: None, items: Repeats<1, 18446744073709551615, syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2370..2372) }, string: "fn" }), name: Ident { sym: file_extension, span: bytes(2373..2387) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2389..2393) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(2398..2399) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2399..2400) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2400..2406) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2407..2410) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Literal { lit: "diff", span: bytes(2421..2427) }], span: bytes(2411..2433) }) }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2439..2441) }, string: "fn" }), name: Ident { sym: language, span: bytes(2442..2450) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2452..2456) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: tree_sitter, span: bytes(2461..2472) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(2472..2473) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(2473..2474) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Language, span: bytes(2474..2482) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: tree_sitter_md, span: bytes(2547..2561) }, Punct { char: ':', spacing: Joint, span: bytes(2561..2562) }, Punct { char: ':', spacing: Alone, span: bytes(2562..2563) }, Ident { sym: LANGUAGE, span: bytes(2563..2571) }, Punct { char: '.', spacing: Alone, span: bytes(2571..2572) }, Ident { sym: into, span: bytes(2572..2576) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2576..2578) }], span: bytes(2483..2584) }) }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2590..2592) }, string: "fn" }), name: Ident { sym: section_query, span: bytes(2593..2606) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2608..2612) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(2617..2618) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2618..2619) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2619..2625) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2626..2629) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Literal { lit: "", span: bytes(2640..2642) }], span: bytes(2630..2648) }) }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2654..2656) }, string: "fn" }), name: Ident { sym: title_query, span: bytes(2657..2668) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2670..2674) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(2679..2680) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2680..2681) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2681..2687) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2688..2691) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Literal { lit: "", span: bytes(2702..2704) }], span: bytes(2692..2710) }) }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2716..2718) }, string: "fn" }), name: Ident { sym: format_section_display, span: bytes(2719..2741) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2743..2747) }, string: "self" }) })), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: level, span: bytes(2749..2754) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: usize, span: bytes(2756..2761) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: title, span: bytes(2763..2768) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(2770..2771) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2771..2774) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Line, span: bytes(2779..2783) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2784..2785) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2785..2791) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(2878..2880) }, Ident { sym: title, span: bytes(2881..2886) }, Punct { char: '.', spacing: Alone, span: bytes(2886..2887) }, Ident { sym: contains, span: bytes(2887..2895) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "@@", span: bytes(2896..2900) }], span: bytes(2895..2901) }, Punct { char: '&', spacing: Joint, span: bytes(2902..2903) }, Punct { char: '&', spacing: Alone, span: bytes(2903..2904) }, Ident { sym: title, span: bytes(2905..2910) }, Punct { char: '.', spacing: Alone, span: bytes(2910..2911) }, Ident { sym: starts_with, span: bytes(2911..2922) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '(', span: bytes(2923..2926) }], span: bytes(2922..2927) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(2942..2944) }, Ident { sym: let, span: bytes(2945..2948) }, Ident { sym: Some, span: bytes(2949..2953) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: close_paren, span: bytes(2954..2965) }], span: bytes(2953..2966) }, Punct { char: '=', spacing: Alone, span: bytes(2967..2968) }, Ident { sym: title, span: bytes(2969..2974) }, Punct { char: '.', spacing: Alone, span: bytes(2974..2975) }, Ident { sym: find, span: bytes(2975..2979) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ')', span: bytes(2980..2983) }], span: bytes(2979..2984) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(3003..3006) }, Ident { sym: hunk_num, span: bytes(3007..3015) }, Punct { char: '=', spacing: Alone, span: bytes(3016..3017) }, Punct { char: '&', spacing: Alone, span: bytes(3018..3019) }, Ident { sym: title, span: bytes(3019..3024) }, Group { delimiter: Bracket, stream: TokenStream [Punct { char: '.', spacing: Joint, span: bytes(3025..3026) }, Punct { char: '.', spacing: Joint, span: bytes(3026..3027) }, Punct { char: '=', spacing: Alone, span: bytes(3027..3028) }, Ident { sym: close_paren, span: bytes(3028..3039) }], span: bytes(3024..3040) }, Punct { char: ';', spacing: Alone, span: bytes(3040..3041) }, Ident { sym: let, span: bytes(3058..3061) }, Ident { sym: rest, span: bytes(3062..3066) }, Punct { char: '=', spacing: Alone, span: bytes(3067..3068) }, Punct { char: '&', spacing: Alone, span: bytes(3069..3070) }, Ident { sym: title, span: bytes(3070..3075) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: close_paren, span: bytes(3076..3087) }, Punct { char: '+', spacing: Alone, span: bytes(3088..3089) }, Literal { lit: 1, span: bytes(3090..3091) }, Punct { char: '.', spacing: Joint, span: bytes(3091..3092) }, Punct { char: '.', spacing: Alone, span: bytes(3092..3093) }], span: bytes(3075..3094) }, Punct { char: '.', spacing: Alone, span: bytes(3094..3095) }, Ident { sym: trim, span: bytes(3095..3099) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3099..3101) }, Punct { char: ';', spacing: Alone, span: bytes(3101..3102) }, Ident { sym: let, span: bytes(3180..3183) }, Ident { sym: color, span: bytes(3184..3189) }, Punct { char: '=', spacing: Alone, span: bytes(3190..3191) }, Ident { sym: Self, span: bytes(3192..3196) }, Punct { char: ':', spacing: Joint, span: bytes(3196..3197) }, Punct { char: ':', spacing: Alone, span: bytes(3197..3198) }, Ident { sym: determine_hunk_color_from_header, span: bytes(3198..3230) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rest, span: bytes(3231..3235) }], span: bytes(3230..3236) }, Punct { char: ';', spacing: Alone, span: bytes(3236..3237) }, Ident { sym: let, span: bytes(3255..3258) }, Ident { sym: spans, span: bytes(3259..3264) }, Punct { char: '=', spacing: Alone, span: bytes(3265..3266) }, Ident { sym: vec, span: bytes(3267..3270) }, Punct { char: '!', spacing: Alone, span: bytes(3270..3271) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: Span, span: bytes(3293..3297) }, Punct { char: ':', spacing: Joint, span: bytes(3297..3298) }, Punct { char: ':', spacing: Alone, span: bytes(3298..3299) }, Ident { sym: styled, span: bytes(3299..3305) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: hunk_num, span: bytes(3306..3314) }, Punct { char: '.', spacing: Alone, span: bytes(3314..3315) }, Ident { sym: to_string, span: bytes(3315..3324) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3324..3326) }, Punct { char: ',', spacing: Alone, span: bytes(3326..3327) }, Ident { sym: Style, span: bytes(3328..3333) }, Punct { char: ':', spacing: Joint, span: bytes(3333..3334) }, Punct { char: ':', spacing: Alone, span: bytes(3334..3335) }, Ident { sym: default, span: bytes(3335..3342) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3342..3344) }, Punct { char: '.', spacing: Alone, span: bytes(3344..3345) }, Ident { sym: fg, span: bytes(3345..3347) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: color, span: bytes(3348..3353) }], span: bytes(3347..3354) }], span: bytes(3305..3355) }, Punct { char: ',', spacing: Alone, span: bytes(3355..3356) }, Ident { sym: Span, span: bytes(3377..3381) }, Punct { char: ':', spacing: Joint, span: bytes(3381..3382) }, Punct { char: ':', spacing: Alone, span: bytes(3382..3383) }, Ident { sym: raw, span: bytes(3383..3386) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: " ", span: bytes(3387..3390) }], span: bytes(3386..3391) }, Punct { char: ',', spacing: Alone, span: bytes(3391..3392) }, Ident { sym: Span, span: bytes(3413..3417) }, Punct { char: ':', spacing: Joint, span: bytes(3417..3418) }, Punct { char: ':', spacing: Alone, span: bytes(3418..3419) }, Ident { sym: raw, span: bytes(3419..3422) }, Group { delimiter: Parenthesis, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '*', spacing: Alone, span: bytes(3424..3425) }, Ident { sym: rest, span: bytes(3425..3429) }], span: bytes(3423..3430) }, Punct { char: '.', spacing: Alone, span: bytes(3430..3431) }, Ident { sym: to_string, span: bytes(3431..3440) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3440..3442) }], span: bytes(3422..3443) }, Punct { char: ',', spacing: Alone, span: bytes(3443..3444) }], span: bytes(3271..3462) }, Punct { char: ';', spacing: Alone, span: bytes(3462..3463) }, Ident { sym: return, span: bytes(3481..3487) }, Ident { sym: Line, span: bytes(3488..3492) }, Punct { char: ':', spacing: Joint, span: bytes(3492..3493) }, Punct { char: ':', spacing: Alone, span: bytes(3493..3494) }, Ident { sym: from, span: bytes(3494..3498) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: spans, span: bytes(3499..3504) }], span: bytes(3498..3505) }, Punct { char: ';', spacing: Alone, span: bytes(3505..3506) }], span: bytes(2985..3520) }], span: bytes(2928..3530) }, Ident { sym: let, span: bytes(3584..3587) }, Ident { sym: color, span: bytes(3588..3593) }, Punct { char: '=', spacing: Alone, span: bytes(3594..3595) }, Ident { sym: if, span: bytes(3596..3598) }, Ident { sym: level, span: bytes(3599..3604) }, Punct { char: '=', spacing: Joint, span: bytes(3605..3606) }, Punct { char: '=', spacing: Alone, span: bytes(3606..3607) }, Literal { lit: 0, span: bytes(3608..3609) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: Color, span: bytes(3624..3629) }, Punct { char: ':', spacing: Joint, span: bytes(3629..3630) }, Punct { char: ':', spacing: Alone, span: bytes(3630..3631) }, Ident { sym: Cyan, span: bytes(3631..3635) }], span: bytes(3610..3654) }, Ident { sym: else, span: bytes(3655..3659) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: Color, span: bytes(3674..3679) }, Punct { char: ':', spacing: Joint, span: bytes(3679..3680) }, Punct { char: ':', spacing: Alone, span: bytes(3680..3681) }, Ident { sym: LightYellow, span: bytes(3681..3692) }], span: bytes(3660..3711) }, Punct { char: ';', spacing: Alone, span: bytes(3711..3712) }, Ident { sym: let, span: bytes(3722..3725) }, Ident { sym: spans, span: bytes(3726..3731) }, Punct { char: '=', spacing: Alone, span: bytes(3732..3733) }, Ident { sym: vec, span: bytes(3734..3737) }, Punct { char: '!', spacing: Alone, span: bytes(3737..3738) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: Span, span: bytes(3752..3756) }, Punct { char: ':', spacing: Joint, span: bytes(3756..3757) }, Punct { char: ':', spacing: Alone, span: bytes(3757..3758) }, Ident { sym: styled, span: bytes(3758..3764) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: " ", span: bytes(3765..3769) }, Punct { char: ',', spacing: Alone, span: bytes(3769..3770) }, Ident { sym: Style, span: bytes(3771..3776) }, Punct { char: ':', spacing: Joint, span: bytes(3776..3777) }, Punct { char: ':', spacing: Alone, span: bytes(3777..3778) }, Ident { sym: default, span: bytes(3778..3785) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3785..3787) }, Punct { char: '.', spacing: Alone, span: bytes(3787..3788) }, Ident { sym: fg, span: bytes(3788..3790) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: color, span: bytes(3791..3796) }], span: bytes(3790..3797) }], span: bytes(3764..3798) }, Punct { char: ',', spacing: Alone, span: bytes(3798..3799) }, Ident { sym: Span, span: bytes(3812..3816) }, Punct { char: ':', spacing: Joint, span: bytes(3816..3817) }, Punct { char: ':', spacing: Alone, span: bytes(3817..3818) }, Ident { sym: raw, span: bytes(3818..3821) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: title, span: bytes(3822..3827) }, Punct { char: '.', spacing: Alone, span: bytes(3827..3828) }, Ident { sym: to_string, span: bytes(3828..3837) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3837..3839) }], span: bytes(3821..3840) }, Punct { char: ',', spacing: Alone, span: bytes(3840..3841) }], span: bytes(3738..3851) }, Punct { char: ';', spacing: Alone, span: bytes(3851..3852) }, Ident { sym: Line, span: bytes(3862..3866) }, Punct { char: ':', spacing: Joint, span: bytes(3866..3867) }, Punct { char: ':', spacing: Alone, span: bytes(3867..3868) }, Ident { sym: from, span: bytes(3868..3872) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: spans, span: bytes(3873..3878) }], span: bytes(3872..3879) }], span: bytes(2793..3885) }) }), delimiter: Some(Nothing) }]) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2370..2372) }, string: "fn" }), name: Ident { sym: file_extension, span: bytes(2373..2387) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2389..2393) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(2398..2399) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2399..2400) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2400..2406) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2407..2410) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Literal { lit: "diff", span: bytes(2421..2427) }], span: bytes(2411..2433) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2439..2441) }, string: "fn" }), name: Ident { sym: language, span: bytes(2442..2450) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2452..2456) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: tree_sitter, span: bytes(2461..2472) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(2472..2473) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(2473..2474) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Language, span: bytes(2474..2482) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: tree_sitter_md, span: bytes(2547..2561) }, Punct { char: ':', spacing: Joint, span: bytes(2561..2562) }, Punct { char: ':', spacing: Alone, span: bytes(2562..2563) }, Ident { sym: LANGUAGE, span: bytes(2563..2571) }, Punct { char: '.', spacing: Alone, span: bytes(2571..2572) }, Ident { sym: into, span: bytes(2572..2576) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(2576..2578) }], span: bytes(2483..2584) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2590..2592) }, string: "fn" }), name: Ident { sym: section_query, span: bytes(2593..2606) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2608..2612) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(2617..2618) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2618..2619) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2619..2625) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2626..2629) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Literal { lit: "", span: bytes(2640..2642) }], span: bytes(2630..2648) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2654..2656) }, string: "fn" }), name: Ident { sym: title_query, span: bytes(2657..2668) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2670..2674) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(2679..2680) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2680..2681) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2681..2687) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2688..2691) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Literal { lit: "", span: bytes(2702..2704) }], span: bytes(2692..2710) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(2716..2718) }, string: "fn" }), name: Ident { sym: format_section_display, span: bytes(2719..2741) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(2743..2747) }, string: "self" }) })), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: level, span: bytes(2749..2754) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: usize, span: bytes(2756..2761) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: title, span: bytes(2763..2768) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(2770..2771) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(2771..2774) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Line, span: bytes(2779..2783) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(2784..2785) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(2785..2791) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(2878..2880) }, Ident { sym: title, span: bytes(2881..2886) }, Punct { char: '.', spacing: Alone, span: bytes(2886..2887) }, Ident { sym: contains, span: bytes(2887..2895) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "@@", span: bytes(2896..2900) }], span: bytes(2895..2901) }, Punct { char: '&', spacing: Joint, span: bytes(2902..2903) }, Punct { char: '&', spacing: Alone, span: bytes(2903..2904) }, Ident { sym: title, span: bytes(2905..2910) }, Punct { char: '.', spacing: Alone, span: bytes(2910..2911) }, Ident { sym: starts_with, span: bytes(2911..2922) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '(', span: bytes(2923..2926) }], span: bytes(2922..2927) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(2942..2944) }, Ident { sym: let, span: bytes(2945..2948) }, Ident { sym: Some, span: bytes(2949..2953) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: close_paren, span: bytes(2954..2965) }], span: bytes(2953..2966) }, Punct { char: '=', spacing: Alone, span: bytes(2967..2968) }, Ident { sym: title, span: bytes(2969..2974) }, Punct { char: '.', spacing: Alone, span: bytes(2974..2975) }, Ident { sym: find, span: bytes(2975..2979) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ')', span: bytes(2980..2983) }], span: bytes(2979..2984) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(3003..3006) }, Ident { sym: hunk_num, span: bytes(3007..3015) }, Punct { char: '=', spacing: Alone, span: bytes(3016..3017) }, Punct { char: '&', spacing: Alone, span: bytes(3018..3019) }, Ident { sym: title, span: bytes(3019..3024) }, Group { delimiter: Bracket, stream: TokenStream [Punct { char: '.', spacing: Joint, span: bytes(3025..3026) }, Punct { char: '.', spacing: Joint, span: bytes(3026..3027) }, Punct { char: '=', spacing: Alone, span: bytes(3027..3028) }, Ident { sym: close_paren, span: bytes(3028..3039) }], span: bytes(3024..3040) }, Punct { char: ';', spacing: Alone, span: bytes(3040..3041) }, Ident { sym: let, span: bytes(3058..3061) }, Ident { sym: rest, span: bytes(3062..3066) }, Punct { char: '=', spacing: Alone, span: bytes(3067..3068) }, Punct { char: '&', spacing: Alone, span: bytes(3069..3070) }, Ident { sym: title, span: bytes(3070..3075) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: close_paren, span: bytes(3076..3087) }, Punct { char: '+', spacing: Alone, span: bytes(3088..3089) }, Literal { lit: 1, span: bytes(3090..3091) }, Punct { char: '.', spacing: Joint, span: bytes(3091..3092) }, Punct { char: '.', spacing: Alone, span: bytes(3092..3093) }], span: bytes(3075..3094) }, Punct { char: '.', spacing: Alone, span: bytes(3094..3095) }, Ident { sym: trim, span: bytes(3095..3099) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3099..3101) }, Punct { char: ';', spacing: Alone, span: bytes(3101..3102) }, Ident { sym: let, span: bytes(3180..3183) }, Ident { sym: color, span: bytes(3184..3189) }, Punct { char: '=', spacing: Alone, span: bytes(3190..3191) }, Ident { sym: Self, span: bytes(3192..3196) }, Punct { char: ':', spacing: Joint, span: bytes(3196..3197) }, Punct { char: ':', spacing: Alone, span: bytes(3197..3198) }, Ident { sym: determine_hunk_color_from_header, span: bytes(3198..3230) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rest, span: bytes(3231..3235) }], span: bytes(3230..3236) }, Punct { char: ';', spacing: Alone, span: bytes(3236..3237) }, Ident { sym: let, span: bytes(3255..3258) }, Ident { sym: spans, span: bytes(3259..3264) }, Punct { char: '=', spacing: Alone, span: bytes(3265..3266) }, Ident { sym: vec, span: bytes(3267..3270) }, Punct { char: '!', spacing: Alone, span: bytes(3270..3271) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: Span, span: bytes(3293..3297) }, Punct { char: ':', spacing: Joint, span: bytes(3297..3298) }, Punct { char: ':', spacing: Alone, span: bytes(3298..3299) }, Ident { sym: styled, span: bytes(3299..3305) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: hunk_num, span: bytes(3306..3314) }, Punct { char: '.', spacing: Alone, span: bytes(3314..3315) }, Ident { sym: to_string, span: bytes(3315..3324) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3324..3326) }, Punct { char: ',', spacing: Alone, span: bytes(3326..3327) }, Ident { sym: Style, span: bytes(3328..3333) }, Punct { char: ':', spacing: Joint, span: bytes(3333..3334) }, Punct { char: ':', spacing: Alone, span: bytes(3334..3335) }, Ident { sym: default, span: bytes(3335..3342) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3342..3344) }, Punct { char: '.', spacing: Alone, span: bytes(3344..3345) }, Ident { sym: fg, span: bytes(3345..3347) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: color, span: bytes(3348..3353) }], span: bytes(3347..3354) }], span: bytes(3305..3355) }, Punct { char: ',', spacing: Alone, span: bytes(3355..3356) }, Ident { sym: Span, span: bytes(3377..3381) }, Punct { char: ':', spacing: Joint, span: bytes(3381..3382) }, Punct { char: ':', spacing: Alone, span: bytes(3382..3383) }, Ident { sym: raw, span: bytes(3383..3386) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: " ", span: bytes(3387..3390) }], span: bytes(3386..3391) }, Punct { char: ',', spacing: Alone, span: bytes(3391..3392) }, Ident { sym: Span, span: bytes(3413..3417) }, Punct { char: ':', spacing: Joint, span: bytes(3417..3418) }, Punct { char: ':', spacing: Alone, span: bytes(3418..3419) }, Ident { sym: raw, span: bytes(3419..3422) }, Group { delimiter: Parenthesis, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '*', spacing: Alone, span: bytes(3424..3425) }, Ident { sym: rest, span: bytes(3425..3429) }], span: bytes(3423..3430) }, Punct { char: '.', spacing: Alone, span: bytes(3430..3431) }, Ident { sym: to_string, span: bytes(3431..3440) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3440..3442) }], span: bytes(3422..3443) }, Punct { char: ',', spacing: Alone, span: bytes(3443..3444) }], span: bytes(3271..3462) }, Punct { char: ';', spacing: Alone, span: bytes(3462..3463) }, Ident { sym: return, span: bytes(3481..3487) }, Ident { sym: Line, span: bytes(3488..3492) }, Punct { char: ':', spacing: Joint, span: bytes(3492..3493) }, Punct { char: ':', spacing: Alone, span: bytes(3493..3494) }, Ident { sym: from, span: bytes(3494..3498) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: spans, span: bytes(3499..3504) }], span: bytes(3498..3505) }, Punct { char: ';', spacing: Alone, span: bytes(3505..3506) }], span: bytes(2985..3520) }], span: bytes(2928..3530) }, Ident { sym: let, span: bytes(3584..3587) }, Ident { sym: color, span: bytes(3588..3593) }, Punct { char: '=', spacing: Alone, span: bytes(3594..3595) }, Ident { sym: if, span: bytes(3596..3598) }, Ident { sym: level, span: bytes(3599..3604) }, Punct { char: '=', spacing: Joint, span: bytes(3605..3606) }, Punct { char: '=', spacing: Alone, span: bytes(3606..3607) }, Literal { lit: 0, span: bytes(3608..3609) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: Color, span: bytes(3624..3629) }, Punct { char: ':', spacing: Joint, span: bytes(3629..3630) }, Punct { char: ':', spacing: Alone, span: bytes(3630..3631) }, Ident { sym: Cyan, span: bytes(3631..3635) }], span: bytes(3610..3654) }, Ident { sym: else, span: bytes(3655..3659) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: Color, span: bytes(3674..3679) }, Punct { char: ':', spacing: Joint, span: bytes(3679..3680) }, Punct { char: ':', spacing: Alone, span: bytes(3680..3681) }, Ident { sym: LightYellow, span: bytes(3681..3692) }], span: bytes(3660..3711) }, Punct { char: ';', spacing: Alone, span: bytes(3711..3712) }, Ident { sym: let, span: bytes(3722..3725) }, Ident { sym: spans, span: bytes(3726..3731) }, Punct { char: '=', spacing: Alone, span: bytes(3732..3733) }, Ident { sym: vec, span: bytes(3734..3737) }, Punct { char: '!', spacing: Alone, span: bytes(3737..3738) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: Span, span: bytes(3752..3756) }, Punct { char: ':', spacing: Joint, span: bytes(3756..3757) }, Punct { char: ':', spacing: Alone, span: bytes(3757..3758) }, Ident { sym: styled, span: bytes(3758..3764) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: " ", span: bytes(3765..3769) }, Punct { char: ',', spacing: Alone, span: bytes(3769..3770) }, Ident { sym: Style, span: bytes(3771..3776) }, Punct { char: ':', spacing: Joint, span: bytes(3776..3777) }, Punct { char: ':', spacing: Alone, span: bytes(3777..3778) }, Ident { sym: default, span: bytes(3778..3785) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3785..3787) }, Punct { char: '.', spacing: Alone, span: bytes(3787..3788) }, Ident { sym: fg, span: bytes(3788..3790) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: color, span: bytes(3791..3796) }], span: bytes(3790..3797) }], span: bytes(3764..3798) }, Punct { char: ',', spacing: Alone, span: bytes(3798..3799) }, Ident { sym: Span, span: bytes(3812..3816) }, Punct { char: ':', spacing: Joint, span: bytes(3816..3817) }, Punct { char: ':', spacing: Alone, span: bytes(3817..3818) }, Ident { sym: raw, span: bytes(3818..3821) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: title, span: bytes(3822..3827) }, Punct { char: '.', spacing: Alone, span: bytes(3827..3828) }, Ident { sym: to_string, span: bytes(3828..3837) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(3837..3839) }], span: bytes(3821..3840) }, Punct { char: ',', spacing: Alone, span: bytes(3840..3841) }], span: bytes(3738..3851) }, Punct { char: ';', spacing: Alone, span: bytes(3851..3852) }, Ident { sym: Line, span: bytes(3862..3866) }, Punct { char: ':', spacing: Joint, span: bytes(3866..3867) }, Punct { char: ':', spacing: Alone, span: bytes(3867..3868) }, Ident { sym: from, span: bytes(3868..3872) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: spans, span: bytes(3873..3878) }], span: bytes(3872..3879) }], span: bytes(2793..3885) }) })
[SYNCDOC DEBUG] Processing item type: ImplBlock
[SYNCDOC DEBUG] Processing item: ImplBlock(ImplBlockSig { attributes: None, _impl: KImpl(Cached<proc_macro2::Ident> { value: Ident { sym: impl, span: bytes(3889..3893) }, string: "impl" }), generics: None, target_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, proc_macro2::TokenTree> { first: Except<unsynn::combinator::Either<syncdoc_core::parse::KFor, unsynn::group::BraceGroup>>, second: Ident { sym: DifftasticFormat, span: bytes(3894..3910) } }, delimiter: Some(Nothing) }]), for_trait: None, where_clause: None, items: BraceGroupContaining < syncdoc_core::parse::ModuleContent>(ModuleContent { inner_attrs: None, items: Repeats<1, 18446744073709551615, syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(3917..3971) }, Punct { char: '=', spacing: Alone, span: bytes(3917..3971) }, Literal { lit: " Determine hunk color from the header string itself", span: bytes(3917..3971) }], span: bytes(3917..3971) }) }, delimiter: Some(Nothing) }])), visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(3976..3978) }, string: "fn" }), name: Ident { sym: determine_hunk_color_from_header, span: bytes(3979..4011) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: header, span: bytes(4012..4018) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(4020..4021) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(4021..4024) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Color, span: bytes(4029..4034) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(4078..4080) }, Ident { sym: let, span: bytes(4081..4084) }, Ident { sym: Some, span: bytes(4085..4089) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: hunk_part, span: bytes(4090..4099) }], span: bytes(4089..4100) }, Punct { char: '=', spacing: Alone, span: bytes(4101..4102) }, Ident { sym: header, span: bytes(4103..4109) }, Punct { char: '.', spacing: Alone, span: bytes(4109..4110) }, Ident { sym: strip_prefix, span: bytes(4110..4122) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "@@", span: bytes(4123..4127) }], span: bytes(4122..4128) }, Punct { char: '.', spacing: Alone, span: bytes(4128..4129) }, Ident { sym: and_then, span: bytes(4129..4137) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4138..4139) }, Ident { sym: s, span: bytes(4139..4140) }, Punct { char: '|', spacing: Alone, span: bytes(4140..4141) }, Ident { sym: s, span: bytes(4142..4143) }, Punct { char: '.', spacing: Alone, span: bytes(4143..4144) }, Ident { sym: split, span: bytes(4144..4149) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "@@", span: bytes(4150..4154) }], span: bytes(4149..4155) }, Punct { char: '.', spacing: Alone, span: bytes(4155..4156) }, Ident { sym: next, span: bytes(4156..4160) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4160..4162) }], span: bytes(4137..4163) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(4178..4181) }, Ident { sym: parts, span: bytes(4182..4187) }, Punct { char: ':', spacing: Alone, span: bytes(4187..4188) }, Ident { sym: Vec, span: bytes(4189..4192) }, Punct { char: '<', spacing: Joint, span: bytes(4192..4193) }, Punct { char: '&', spacing: Alone, span: bytes(4193..4194) }, Ident { sym: str, span: bytes(4194..4197) }, Punct { char: '>', spacing: Alone, span: bytes(4197..4198) }, Punct { char: '=', spacing: Alone, span: bytes(4199..4200) }, Ident { sym: hunk_part, span: bytes(4201..4210) }, Punct { char: '.', spacing: Alone, span: bytes(4210..4211) }, Ident { sym: split_whitespace, span: bytes(4211..4227) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4227..4229) }, Punct { char: '.', spacing: Alone, span: bytes(4229..4230) }, Ident { sym: collect, span: bytes(4230..4237) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4237..4239) }, Punct { char: ';', spacing: Alone, span: bytes(4239..4240) }, Ident { sym: if, span: bytes(4253..4255) }, Ident { sym: parts, span: bytes(4256..4261) }, Punct { char: '.', spacing: Alone, span: bytes(4261..4262) }, Ident { sym: len, span: bytes(4262..4265) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4265..4267) }, Punct { char: '>', spacing: Joint, span: bytes(4268..4269) }, Punct { char: '=', spacing: Alone, span: bytes(4269..4270) }, Literal { lit: 2, span: bytes(4271..4272) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(4291..4294) }, Ident { sym: lhs, span: bytes(4295..4298) }, Punct { char: '=', spacing: Alone, span: bytes(4299..4300) }, Ident { sym: parts, span: bytes(4301..4306) }, Group { delimiter: Bracket, stream: TokenStream [Literal { lit: 0, span: bytes(4307..4308) }], span: bytes(4306..4309) }, Punct { char: '.', spacing: Alone, span: bytes(4309..4310) }, Ident { sym: trim_start_matches, span: bytes(4310..4328) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '-', span: bytes(4329..4332) }], span: bytes(4328..4333) }, Punct { char: ';', spacing: Alone, span: bytes(4333..4334) }, Ident { sym: let, span: bytes(4351..4354) }, Ident { sym: rhs, span: bytes(4355..4358) }, Punct { char: '=', spacing: Alone, span: bytes(4359..4360) }, Ident { sym: parts, span: bytes(4361..4366) }, Group { delimiter: Bracket, stream: TokenStream [Literal { lit: 1, span: bytes(4367..4368) }], span: bytes(4366..4369) }, Punct { char: '.', spacing: Alone, span: bytes(4369..4370) }, Ident { sym: trim_start_matches, span: bytes(4370..4388) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '+', span: bytes(4389..4392) }], span: bytes(4388..4393) }, Punct { char: ';', spacing: Alone, span: bytes(4393..4394) }, Ident { sym: let, span: bytes(4412..4415) }, Ident { sym: lhs_count, span: bytes(4416..4425) }, Punct { char: '=', spacing: Alone, span: bytes(4426..4427) }, Ident { sym: lhs, span: bytes(4428..4431) }, Punct { char: '.', spacing: Alone, span: bytes(4452..4453) }, Ident { sym: split, span: bytes(4453..4458) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ',', span: bytes(4459..4462) }], span: bytes(4458..4463) }, Punct { char: '.', spacing: Alone, span: bytes(4484..4485) }, Ident { sym: nth, span: bytes(4485..4488) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4489..4490) }], span: bytes(4488..4491) }, Punct { char: '.', spacing: Alone, span: bytes(4512..4513) }, Ident { sym: and_then, span: bytes(4513..4521) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4522..4523) }, Ident { sym: s, span: bytes(4523..4524) }, Punct { char: '|', spacing: Alone, span: bytes(4524..4525) }, Ident { sym: s, span: bytes(4526..4527) }, Punct { char: '.', spacing: Alone, span: bytes(4527..4528) }, Ident { sym: parse, span: bytes(4528..4533) }, Punct { char: ':', spacing: Joint, span: bytes(4533..4534) }, Punct { char: ':', spacing: Joint, span: bytes(4534..4535) }, Punct { char: '<', spacing: Alone, span: bytes(4535..4536) }, Ident { sym: u32, span: bytes(4536..4539) }, Punct { char: '>', spacing: Alone, span: bytes(4539..4540) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4540..4542) }, Punct { char: '.', spacing: Alone, span: bytes(4542..4543) }, Ident { sym: ok, span: bytes(4543..4545) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4545..4547) }], span: bytes(4521..4548) }, Punct { char: '.', spacing: Alone, span: bytes(4569..4570) }, Ident { sym: unwrap_or, span: bytes(4570..4579) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4580..4581) }], span: bytes(4579..4582) }, Punct { char: ';', spacing: Alone, span: bytes(4582..4583) }, Ident { sym: let, span: bytes(4600..4603) }, Ident { sym: rhs_count, span: bytes(4604..4613) }, Punct { char: '=', spacing: Alone, span: bytes(4614..4615) }, Ident { sym: rhs, span: bytes(4616..4619) }, Punct { char: '.', spacing: Alone, span: bytes(4640..4641) }, Ident { sym: split, span: bytes(4641..4646) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ',', span: bytes(4647..4650) }], span: bytes(4646..4651) }, Punct { char: '.', spacing: Alone, span: bytes(4672..4673) }, Ident { sym: nth, span: bytes(4673..4676) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4677..4678) }], span: bytes(4676..4679) }, Punct { char: '.', spacing: Alone, span: bytes(4700..4701) }, Ident { sym: and_then, span: bytes(4701..4709) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4710..4711) }, Ident { sym: s, span: bytes(4711..4712) }, Punct { char: '|', spacing: Alone, span: bytes(4712..4713) }, Ident { sym: s, span: bytes(4714..4715) }, Punct { char: '.', spacing: Alone, span: bytes(4715..4716) }, Ident { sym: parse, span: bytes(4716..4721) }, Punct { char: ':', spacing: Joint, span: bytes(4721..4722) }, Punct { char: ':', spacing: Joint, span: bytes(4722..4723) }, Punct { char: '<', spacing: Alone, span: bytes(4723..4724) }, Ident { sym: u32, span: bytes(4724..4727) }, Punct { char: '>', spacing: Alone, span: bytes(4727..4728) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4728..4730) }, Punct { char: '.', spacing: Alone, span: bytes(4730..4731) }, Ident { sym: ok, span: bytes(4731..4733) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4733..4735) }], span: bytes(4709..4736) }, Punct { char: '.', spacing: Alone, span: bytes(4757..4758) }, Ident { sym: unwrap_or, span: bytes(4758..4767) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4768..4769) }], span: bytes(4767..4770) }, Punct { char: ';', spacing: Alone, span: bytes(4770..4771) }, Ident { sym: let, span: bytes(4855..4858) }, Ident { sym: lhs_start, span: bytes(4859..4868) }, Punct { char: '=', spacing: Alone, span: bytes(4869..4870) }, Ident { sym: lhs, span: bytes(4871..4874) }, Punct { char: '.', spacing: Alone, span: bytes(4895..4896) }, Ident { sym: split, span: bytes(4896..4901) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ',', span: bytes(4902..4905) }], span: bytes(4901..4906) }, Punct { char: '.', spacing: Alone, span: bytes(4927..4928) }, Ident { sym: next, span: bytes(4928..4932) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4932..4934) }, Punct { char: '.', spacing: Alone, span: bytes(4955..4956) }, Ident { sym: and_then, span: bytes(4956..4964) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4965..4966) }, Ident { sym: s, span: bytes(4966..4967) }, Punct { char: '|', spacing: Alone, span: bytes(4967..4968) }, Ident { sym: s, span: bytes(4969..4970) }, Punct { char: '.', spacing: Alone, span: bytes(4970..4971) }, Ident { sym: parse, span: bytes(4971..4976) }, Punct { char: ':', spacing: Joint, span: bytes(4976..4977) }, Punct { char: ':', spacing: Joint, span: bytes(4977..4978) }, Punct { char: '<', spacing: Alone, span: bytes(4978..4979) }, Ident { sym: u32, span: bytes(4979..4982) }, Punct { char: '>', spacing: Alone, span: bytes(4982..4983) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4983..4985) }, Punct { char: '.', spacing: Alone, span: bytes(4985..4986) }, Ident { sym: ok, span: bytes(4986..4988) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4988..4990) }], span: bytes(4964..4991) }, Punct { char: '.', spacing: Alone, span: bytes(5012..5013) }, Ident { sym: unwrap_or, span: bytes(5013..5022) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(5023..5024) }], span: bytes(5022..5025) }, Punct { char: ';', spacing: Alone, span: bytes(5025..5026) }, Ident { sym: if, span: bytes(5044..5046) }, Ident { sym: lhs_start, span: bytes(5047..5056) }, Punct { char: '=', spacing: Joint, span: bytes(5057..5058) }, Punct { char: '=', spacing: Alone, span: bytes(5058..5059) }, Literal { lit: 0, span: bytes(5060..5061) }, Punct { char: '&', spacing: Joint, span: bytes(5062..5063) }, Punct { char: '&', spacing: Alone, span: bytes(5063..5064) }, Ident { sym: lhs_count, span: bytes(5065..5074) }, Punct { char: '=', spacing: Joint, span: bytes(5075..5076) }, Punct { char: '=', spacing: Alone, span: bytes(5076..5077) }, Literal { lit: 0, span: bytes(5078..5079) }, Punct { char: '&', spacing: Joint, span: bytes(5080..5081) }, Punct { char: '&', spacing: Alone, span: bytes(5081..5082) }, Ident { sym: rhs_count, span: bytes(5083..5092) }, Punct { char: '>', spacing: Alone, span: bytes(5093..5094) }, Literal { lit: 0, span: bytes(5095..5096) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5119..5125) }, Ident { sym: Color, span: bytes(5126..5131) }, Punct { char: ':', spacing: Joint, span: bytes(5131..5132) }, Punct { char: ':', spacing: Alone, span: bytes(5132..5133) }, Ident { sym: Green, span: bytes(5133..5138) }, Punct { char: ';', spacing: Alone, span: bytes(5138..5139) }], span: bytes(5097..5169) }, Ident { sym: else, span: bytes(5170..5174) }, Ident { sym: if, span: bytes(5175..5177) }, Ident { sym: lhs_count, span: bytes(5178..5187) }, Punct { char: '>', spacing: Alone, span: bytes(5188..5189) }, Literal { lit: 0, span: bytes(5190..5191) }, Punct { char: '&', spacing: Joint, span: bytes(5192..5193) }, Punct { char: '&', spacing: Alone, span: bytes(5193..5194) }, Ident { sym: rhs_count, span: bytes(5195..5204) }, Punct { char: '=', spacing: Joint, span: bytes(5205..5206) }, Punct { char: '=', spacing: Alone, span: bytes(5206..5207) }, Literal { lit: 0, span: bytes(5208..5209) }, Punct { char: '&', spacing: Joint, span: bytes(5210..5211) }, Punct { char: '&', spacing: Alone, span: bytes(5211..5212) }, Ident { sym: rhs, span: bytes(5213..5216) }, Punct { char: '.', spacing: Alone, span: bytes(5216..5217) }, Ident { sym: starts_with, span: bytes(5217..5228) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "0,", span: bytes(5229..5233) }], span: bytes(5228..5234) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5257..5263) }, Ident { sym: Color, span: bytes(5264..5269) }, Punct { char: ':', spacing: Joint, span: bytes(5269..5270) }, Punct { char: ':', spacing: Alone, span: bytes(5270..5271) }, Ident { sym: Red, span: bytes(5271..5274) }, Punct { char: ';', spacing: Alone, span: bytes(5274..5275) }], span: bytes(5235..5305) }, Ident { sym: else, span: bytes(5306..5310) }, Ident { sym: if, span: bytes(5311..5313) }, Ident { sym: lhs_count, span: bytes(5314..5323) }, Punct { char: '=', spacing: Joint, span: bytes(5324..5325) }, Punct { char: '=', spacing: Alone, span: bytes(5325..5326) }, Literal { lit: 0, span: bytes(5327..5328) }, Punct { char: '&', spacing: Joint, span: bytes(5329..5330) }, Punct { char: '&', spacing: Alone, span: bytes(5330..5331) }, Ident { sym: rhs_count, span: bytes(5332..5341) }, Punct { char: '>', spacing: Alone, span: bytes(5342..5343) }, Literal { lit: 0, span: bytes(5344..5345) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5368..5374) }, Ident { sym: Color, span: bytes(5375..5380) }, Punct { char: ':', spacing: Joint, span: bytes(5380..5381) }, Punct { char: ':', spacing: Alone, span: bytes(5381..5382) }, Ident { sym: Green, span: bytes(5382..5387) }, Punct { char: ';', spacing: Alone, span: bytes(5387..5388) }], span: bytes(5346..5423) }, Ident { sym: else, span: bytes(5424..5428) }, Ident { sym: if, span: bytes(5429..5431) }, Ident { sym: lhs_count, span: bytes(5432..5441) }, Punct { char: '>', spacing: Alone, span: bytes(5442..5443) }, Literal { lit: 0, span: bytes(5444..5445) }, Punct { char: '&', spacing: Joint, span: bytes(5446..5447) }, Punct { char: '&', spacing: Alone, span: bytes(5447..5448) }, Ident { sym: rhs_count, span: bytes(5449..5458) }, Punct { char: '=', spacing: Joint, span: bytes(5459..5460) }, Punct { char: '=', spacing: Alone, span: bytes(5460..5461) }, Literal { lit: 0, span: bytes(5462..5463) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5486..5492) }, Ident { sym: Color, span: bytes(5493..5498) }, Punct { char: ':', spacing: Joint, span: bytes(5498..5499) }, Punct { char: ':', spacing: Alone, span: bytes(5499..5500) }, Ident { sym: Red, span: bytes(5500..5503) }, Punct { char: ';', spacing: Alone, span: bytes(5503..5504) }], span: bytes(5464..5539) }], span: bytes(4273..5553) }], span: bytes(4164..5563) }, Ident { sym: Color, span: bytes(5572..5577) }, Punct { char: ':', spacing: Joint, span: bytes(5577..5578) }, Punct { char: ':', spacing: Alone, span: bytes(5578..5579) }, Ident { sym: LightYellow, span: bytes(5579..5590) }], span: bytes(4035..5612) }) }), delimiter: Some(Nothing) }]) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(3917..3971) }, Punct { char: '=', spacing: Alone, span: bytes(3917..3971) }, Literal { lit: " Determine hunk color from the header string itself", span: bytes(3917..3971) }], span: bytes(3917..3971) }) }, delimiter: Some(Nothing) }])), visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(3976..3978) }, string: "fn" }), name: Ident { sym: determine_hunk_color_from_header, span: bytes(3979..4011) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: header, span: bytes(4012..4018) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(4020..4021) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(4021..4024) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Color, span: bytes(4029..4034) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(4078..4080) }, Ident { sym: let, span: bytes(4081..4084) }, Ident { sym: Some, span: bytes(4085..4089) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: hunk_part, span: bytes(4090..4099) }], span: bytes(4089..4100) }, Punct { char: '=', spacing: Alone, span: bytes(4101..4102) }, Ident { sym: header, span: bytes(4103..4109) }, Punct { char: '.', spacing: Alone, span: bytes(4109..4110) }, Ident { sym: strip_prefix, span: bytes(4110..4122) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "@@", span: bytes(4123..4127) }], span: bytes(4122..4128) }, Punct { char: '.', spacing: Alone, span: bytes(4128..4129) }, Ident { sym: and_then, span: bytes(4129..4137) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4138..4139) }, Ident { sym: s, span: bytes(4139..4140) }, Punct { char: '|', spacing: Alone, span: bytes(4140..4141) }, Ident { sym: s, span: bytes(4142..4143) }, Punct { char: '.', spacing: Alone, span: bytes(4143..4144) }, Ident { sym: split, span: bytes(4144..4149) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "@@", span: bytes(4150..4154) }], span: bytes(4149..4155) }, Punct { char: '.', spacing: Alone, span: bytes(4155..4156) }, Ident { sym: next, span: bytes(4156..4160) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4160..4162) }], span: bytes(4137..4163) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(4178..4181) }, Ident { sym: parts, span: bytes(4182..4187) }, Punct { char: ':', spacing: Alone, span: bytes(4187..4188) }, Ident { sym: Vec, span: bytes(4189..4192) }, Punct { char: '<', spacing: Joint, span: bytes(4192..4193) }, Punct { char: '&', spacing: Alone, span: bytes(4193..4194) }, Ident { sym: str, span: bytes(4194..4197) }, Punct { char: '>', spacing: Alone, span: bytes(4197..4198) }, Punct { char: '=', spacing: Alone, span: bytes(4199..4200) }, Ident { sym: hunk_part, span: bytes(4201..4210) }, Punct { char: '.', spacing: Alone, span: bytes(4210..4211) }, Ident { sym: split_whitespace, span: bytes(4211..4227) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4227..4229) }, Punct { char: '.', spacing: Alone, span: bytes(4229..4230) }, Ident { sym: collect, span: bytes(4230..4237) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4237..4239) }, Punct { char: ';', spacing: Alone, span: bytes(4239..4240) }, Ident { sym: if, span: bytes(4253..4255) }, Ident { sym: parts, span: bytes(4256..4261) }, Punct { char: '.', spacing: Alone, span: bytes(4261..4262) }, Ident { sym: len, span: bytes(4262..4265) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4265..4267) }, Punct { char: '>', spacing: Joint, span: bytes(4268..4269) }, Punct { char: '=', spacing: Alone, span: bytes(4269..4270) }, Literal { lit: 2, span: bytes(4271..4272) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(4291..4294) }, Ident { sym: lhs, span: bytes(4295..4298) }, Punct { char: '=', spacing: Alone, span: bytes(4299..4300) }, Ident { sym: parts, span: bytes(4301..4306) }, Group { delimiter: Bracket, stream: TokenStream [Literal { lit: 0, span: bytes(4307..4308) }], span: bytes(4306..4309) }, Punct { char: '.', spacing: Alone, span: bytes(4309..4310) }, Ident { sym: trim_start_matches, span: bytes(4310..4328) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '-', span: bytes(4329..4332) }], span: bytes(4328..4333) }, Punct { char: ';', spacing: Alone, span: bytes(4333..4334) }, Ident { sym: let, span: bytes(4351..4354) }, Ident { sym: rhs, span: bytes(4355..4358) }, Punct { char: '=', spacing: Alone, span: bytes(4359..4360) }, Ident { sym: parts, span: bytes(4361..4366) }, Group { delimiter: Bracket, stream: TokenStream [Literal { lit: 1, span: bytes(4367..4368) }], span: bytes(4366..4369) }, Punct { char: '.', spacing: Alone, span: bytes(4369..4370) }, Ident { sym: trim_start_matches, span: bytes(4370..4388) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '+', span: bytes(4389..4392) }], span: bytes(4388..4393) }, Punct { char: ';', spacing: Alone, span: bytes(4393..4394) }, Ident { sym: let, span: bytes(4412..4415) }, Ident { sym: lhs_count, span: bytes(4416..4425) }, Punct { char: '=', spacing: Alone, span: bytes(4426..4427) }, Ident { sym: lhs, span: bytes(4428..4431) }, Punct { char: '.', spacing: Alone, span: bytes(4452..4453) }, Ident { sym: split, span: bytes(4453..4458) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ',', span: bytes(4459..4462) }], span: bytes(4458..4463) }, Punct { char: '.', spacing: Alone, span: bytes(4484..4485) }, Ident { sym: nth, span: bytes(4485..4488) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4489..4490) }], span: bytes(4488..4491) }, Punct { char: '.', spacing: Alone, span: bytes(4512..4513) }, Ident { sym: and_then, span: bytes(4513..4521) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4522..4523) }, Ident { sym: s, span: bytes(4523..4524) }, Punct { char: '|', spacing: Alone, span: bytes(4524..4525) }, Ident { sym: s, span: bytes(4526..4527) }, Punct { char: '.', spacing: Alone, span: bytes(4527..4528) }, Ident { sym: parse, span: bytes(4528..4533) }, Punct { char: ':', spacing: Joint, span: bytes(4533..4534) }, Punct { char: ':', spacing: Joint, span: bytes(4534..4535) }, Punct { char: '<', spacing: Alone, span: bytes(4535..4536) }, Ident { sym: u32, span: bytes(4536..4539) }, Punct { char: '>', spacing: Alone, span: bytes(4539..4540) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4540..4542) }, Punct { char: '.', spacing: Alone, span: bytes(4542..4543) }, Ident { sym: ok, span: bytes(4543..4545) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4545..4547) }], span: bytes(4521..4548) }, Punct { char: '.', spacing: Alone, span: bytes(4569..4570) }, Ident { sym: unwrap_or, span: bytes(4570..4579) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4580..4581) }], span: bytes(4579..4582) }, Punct { char: ';', spacing: Alone, span: bytes(4582..4583) }, Ident { sym: let, span: bytes(4600..4603) }, Ident { sym: rhs_count, span: bytes(4604..4613) }, Punct { char: '=', spacing: Alone, span: bytes(4614..4615) }, Ident { sym: rhs, span: bytes(4616..4619) }, Punct { char: '.', spacing: Alone, span: bytes(4640..4641) }, Ident { sym: split, span: bytes(4641..4646) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ',', span: bytes(4647..4650) }], span: bytes(4646..4651) }, Punct { char: '.', spacing: Alone, span: bytes(4672..4673) }, Ident { sym: nth, span: bytes(4673..4676) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4677..4678) }], span: bytes(4676..4679) }, Punct { char: '.', spacing: Alone, span: bytes(4700..4701) }, Ident { sym: and_then, span: bytes(4701..4709) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4710..4711) }, Ident { sym: s, span: bytes(4711..4712) }, Punct { char: '|', spacing: Alone, span: bytes(4712..4713) }, Ident { sym: s, span: bytes(4714..4715) }, Punct { char: '.', spacing: Alone, span: bytes(4715..4716) }, Ident { sym: parse, span: bytes(4716..4721) }, Punct { char: ':', spacing: Joint, span: bytes(4721..4722) }, Punct { char: ':', spacing: Joint, span: bytes(4722..4723) }, Punct { char: '<', spacing: Alone, span: bytes(4723..4724) }, Ident { sym: u32, span: bytes(4724..4727) }, Punct { char: '>', spacing: Alone, span: bytes(4727..4728) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4728..4730) }, Punct { char: '.', spacing: Alone, span: bytes(4730..4731) }, Ident { sym: ok, span: bytes(4731..4733) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4733..4735) }], span: bytes(4709..4736) }, Punct { char: '.', spacing: Alone, span: bytes(4757..4758) }, Ident { sym: unwrap_or, span: bytes(4758..4767) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 1, span: bytes(4768..4769) }], span: bytes(4767..4770) }, Punct { char: ';', spacing: Alone, span: bytes(4770..4771) }, Ident { sym: let, span: bytes(4855..4858) }, Ident { sym: lhs_start, span: bytes(4859..4868) }, Punct { char: '=', spacing: Alone, span: bytes(4869..4870) }, Ident { sym: lhs, span: bytes(4871..4874) }, Punct { char: '.', spacing: Alone, span: bytes(4895..4896) }, Ident { sym: split, span: bytes(4896..4901) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: ',', span: bytes(4902..4905) }], span: bytes(4901..4906) }, Punct { char: '.', spacing: Alone, span: bytes(4927..4928) }, Ident { sym: next, span: bytes(4928..4932) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4932..4934) }, Punct { char: '.', spacing: Alone, span: bytes(4955..4956) }, Ident { sym: and_then, span: bytes(4956..4964) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(4965..4966) }, Ident { sym: s, span: bytes(4966..4967) }, Punct { char: '|', spacing: Alone, span: bytes(4967..4968) }, Ident { sym: s, span: bytes(4969..4970) }, Punct { char: '.', spacing: Alone, span: bytes(4970..4971) }, Ident { sym: parse, span: bytes(4971..4976) }, Punct { char: ':', spacing: Joint, span: bytes(4976..4977) }, Punct { char: ':', spacing: Joint, span: bytes(4977..4978) }, Punct { char: '<', spacing: Alone, span: bytes(4978..4979) }, Ident { sym: u32, span: bytes(4979..4982) }, Punct { char: '>', spacing: Alone, span: bytes(4982..4983) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4983..4985) }, Punct { char: '.', spacing: Alone, span: bytes(4985..4986) }, Ident { sym: ok, span: bytes(4986..4988) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(4988..4990) }], span: bytes(4964..4991) }, Punct { char: '.', spacing: Alone, span: bytes(5012..5013) }, Ident { sym: unwrap_or, span: bytes(5013..5022) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(5023..5024) }], span: bytes(5022..5025) }, Punct { char: ';', spacing: Alone, span: bytes(5025..5026) }, Ident { sym: if, span: bytes(5044..5046) }, Ident { sym: lhs_start, span: bytes(5047..5056) }, Punct { char: '=', spacing: Joint, span: bytes(5057..5058) }, Punct { char: '=', spacing: Alone, span: bytes(5058..5059) }, Literal { lit: 0, span: bytes(5060..5061) }, Punct { char: '&', spacing: Joint, span: bytes(5062..5063) }, Punct { char: '&', spacing: Alone, span: bytes(5063..5064) }, Ident { sym: lhs_count, span: bytes(5065..5074) }, Punct { char: '=', spacing: Joint, span: bytes(5075..5076) }, Punct { char: '=', spacing: Alone, span: bytes(5076..5077) }, Literal { lit: 0, span: bytes(5078..5079) }, Punct { char: '&', spacing: Joint, span: bytes(5080..5081) }, Punct { char: '&', spacing: Alone, span: bytes(5081..5082) }, Ident { sym: rhs_count, span: bytes(5083..5092) }, Punct { char: '>', spacing: Alone, span: bytes(5093..5094) }, Literal { lit: 0, span: bytes(5095..5096) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5119..5125) }, Ident { sym: Color, span: bytes(5126..5131) }, Punct { char: ':', spacing: Joint, span: bytes(5131..5132) }, Punct { char: ':', spacing: Alone, span: bytes(5132..5133) }, Ident { sym: Green, span: bytes(5133..5138) }, Punct { char: ';', spacing: Alone, span: bytes(5138..5139) }], span: bytes(5097..5169) }, Ident { sym: else, span: bytes(5170..5174) }, Ident { sym: if, span: bytes(5175..5177) }, Ident { sym: lhs_count, span: bytes(5178..5187) }, Punct { char: '>', spacing: Alone, span: bytes(5188..5189) }, Literal { lit: 0, span: bytes(5190..5191) }, Punct { char: '&', spacing: Joint, span: bytes(5192..5193) }, Punct { char: '&', spacing: Alone, span: bytes(5193..5194) }, Ident { sym: rhs_count, span: bytes(5195..5204) }, Punct { char: '=', spacing: Joint, span: bytes(5205..5206) }, Punct { char: '=', spacing: Alone, span: bytes(5206..5207) }, Literal { lit: 0, span: bytes(5208..5209) }, Punct { char: '&', spacing: Joint, span: bytes(5210..5211) }, Punct { char: '&', spacing: Alone, span: bytes(5211..5212) }, Ident { sym: rhs, span: bytes(5213..5216) }, Punct { char: '.', spacing: Alone, span: bytes(5216..5217) }, Ident { sym: starts_with, span: bytes(5217..5228) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "0,", span: bytes(5229..5233) }], span: bytes(5228..5234) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5257..5263) }, Ident { sym: Color, span: bytes(5264..5269) }, Punct { char: ':', spacing: Joint, span: bytes(5269..5270) }, Punct { char: ':', spacing: Alone, span: bytes(5270..5271) }, Ident { sym: Red, span: bytes(5271..5274) }, Punct { char: ';', spacing: Alone, span: bytes(5274..5275) }], span: bytes(5235..5305) }, Ident { sym: else, span: bytes(5306..5310) }, Ident { sym: if, span: bytes(5311..5313) }, Ident { sym: lhs_count, span: bytes(5314..5323) }, Punct { char: '=', spacing: Joint, span: bytes(5324..5325) }, Punct { char: '=', spacing: Alone, span: bytes(5325..5326) }, Literal { lit: 0, span: bytes(5327..5328) }, Punct { char: '&', spacing: Joint, span: bytes(5329..5330) }, Punct { char: '&', spacing: Alone, span: bytes(5330..5331) }, Ident { sym: rhs_count, span: bytes(5332..5341) }, Punct { char: '>', spacing: Alone, span: bytes(5342..5343) }, Literal { lit: 0, span: bytes(5344..5345) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5368..5374) }, Ident { sym: Color, span: bytes(5375..5380) }, Punct { char: ':', spacing: Joint, span: bytes(5380..5381) }, Punct { char: ':', spacing: Alone, span: bytes(5381..5382) }, Ident { sym: Green, span: bytes(5382..5387) }, Punct { char: ';', spacing: Alone, span: bytes(5387..5388) }], span: bytes(5346..5423) }, Ident { sym: else, span: bytes(5424..5428) }, Ident { sym: if, span: bytes(5429..5431) }, Ident { sym: lhs_count, span: bytes(5432..5441) }, Punct { char: '>', spacing: Alone, span: bytes(5442..5443) }, Literal { lit: 0, span: bytes(5444..5445) }, Punct { char: '&', spacing: Joint, span: bytes(5446..5447) }, Punct { char: '&', spacing: Alone, span: bytes(5447..5448) }, Ident { sym: rhs_count, span: bytes(5449..5458) }, Punct { char: '=', spacing: Joint, span: bytes(5459..5460) }, Punct { char: '=', spacing: Alone, span: bytes(5460..5461) }, Literal { lit: 0, span: bytes(5462..5463) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(5486..5492) }, Ident { sym: Color, span: bytes(5493..5498) }, Punct { char: ':', spacing: Joint, span: bytes(5498..5499) }, Punct { char: ':', spacing: Alone, span: bytes(5499..5500) }, Ident { sym: Red, span: bytes(5500..5503) }, Punct { char: ';', spacing: Alone, span: bytes(5503..5504) }], span: bytes(5464..5539) }], span: bytes(4273..5553) }], span: bytes(4164..5563) }, Ident { sym: Color, span: bytes(5572..5577) }, Punct { char: ':', spacing: Joint, span: bytes(5577..5578) }, Punct { char: ':', spacing: Alone, span: bytes(5578..5579) }, Ident { sym: LightYellow, span: bytes(5579..5590) }], span: bytes(4035..5612) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: allow, span: bytes(5618..5623) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: clippy, span: bytes(5624..5630) }, Punct { char: ':', spacing: Joint, span: bytes(5630..5631) }, Punct { char: ':', spacing: Alone, span: bytes(5631..5632) }, Ident { sym: too_many_arguments, span: bytes(5632..5650) }], span: bytes(5623..5651) }], span: bytes(5617..5652) }) }, delimiter: Some(Nothing) }])), visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(5653..5655) }, string: "fn" }), name: Ident { sym: create_chunk_section, span: bytes(5656..5676) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: file_path, span: bytes(5682..5691) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(5693..5694) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(5694..5697) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: title, span: bytes(5703..5708) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(5710..5716) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: line_num, span: bytes(5722..5730) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: i64, span: bytes(5732..5735) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: column_start, span: bytes(5741..5753) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: i64, span: bytes(5755..5758) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: column_end, span: bytes(5764..5774) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: i64, span: bytes(5776..5779) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: chunk_type, span: bytes(5785..5795) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: ChunkType, span: bytes(5797..5806) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: lhs_text, span: bytes(5812..5820) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Option, span: bytes(5822..5828) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(5829..5835) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: rhs_text, span: bytes(5842..5850) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Option, span: bytes(5852..5858) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(5859..5865) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Section, span: bytes(5873..5880) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: Section, span: bytes(5887..5894) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: title, span: bytes(5905..5910) }, Punct { char: ',', spacing: Alone, span: bytes(5910..5911) }, Ident { sym: level, span: bytes(5920..5925) }, Punct { char: ':', spacing: Alone, span: bytes(5925..5926) }, Literal { lit: 2, span: bytes(5927..5928) }, Punct { char: ',', spacing: Alone, span: bytes(5928..5929) }, Ident { sym: line_start, span: bytes(5938..5948) }, Punct { char: ':', spacing: Alone, span: bytes(5948..5949) }, Ident { sym: line_num, span: bytes(5950..5958) }, Punct { char: ',', spacing: Alone, span: bytes(5958..5959) }, Ident { sym: line_end, span: bytes(5968..5976) }, Punct { char: ':', spacing: Alone, span: bytes(5976..5977) }, Ident { sym: line_num, span: bytes(5978..5986) }, Punct { char: '+', spacing: Alone, span: bytes(5987..5988) }, Literal { lit: 1, span: bytes(5989..5990) }, Punct { char: ',', spacing: Alone, span: bytes(5990..5991) }, Ident { sym: column_start, span: bytes(6000..6012) }, Punct { char: ',', spacing: Alone, span: bytes(6012..6013) }, Ident { sym: column_end, span: bytes(6022..6032) }, Punct { char: ',', spacing: Alone, span: bytes(6032..6033) }, Ident { sym: byte_start, span: bytes(6042..6052) }, Punct { char: ':', spacing: Alone, span: bytes(6052..6053) }, Literal { lit: 0, span: bytes(6054..6055) }, Punct { char: ',', spacing: Alone, span: bytes(6055..6056) }, Ident { sym: byte_end, span: bytes(6065..6073) }, Punct { char: ':', spacing: Alone, span: bytes(6073..6074) }, Literal { lit: 0, span: bytes(6075..6076) }, Punct { char: ',', spacing: Alone, span: bytes(6076..6077) }, Ident { sym: file_path, span: bytes(6086..6095) }, Punct { char: ':', spacing: Alone, span: bytes(6095..6096) }, Ident { sym: file_path, span: bytes(6097..6106) }, Punct { char: '.', spacing: Alone, span: bytes(6106..6107) }, Ident { sym: to_string, span: bytes(6107..6116) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6116..6118) }, Punct { char: ',', spacing: Alone, span: bytes(6118..6119) }, Ident { sym: parent_index, span: bytes(6128..6140) }, Punct { char: ':', spacing: Alone, span: bytes(6140..6141) }, Ident { sym: None, span: bytes(6142..6146) }, Punct { char: ',', spacing: Alone, span: bytes(6146..6147) }, Ident { sym: children_indices, span: bytes(6156..6172) }, Punct { char: ':', spacing: Alone, span: bytes(6172..6173) }, Ident { sym: Vec, span: bytes(6174..6177) }, Punct { char: ':', spacing: Joint, span: bytes(6177..6178) }, Punct { char: ':', spacing: Alone, span: bytes(6178..6179) }, Ident { sym: new, span: bytes(6179..6182) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6182..6184) }, Punct { char: ',', spacing: Alone, span: bytes(6184..6185) }, Ident { sym: section_content, span: bytes(6194..6209) }, Punct { char: ':', spacing: Alone, span: bytes(6209..6210) }, Ident { sym: None, span: bytes(6211..6215) }, Punct { char: ',', spacing: Alone, span: bytes(6215..6216) }, Ident { sym: chunk_type, span: bytes(6225..6235) }, Punct { char: ':', spacing: Alone, span: bytes(6235..6236) }, Ident { sym: Some, span: bytes(6237..6241) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: chunk_type, span: bytes(6242..6252) }], span: bytes(6241..6253) }, Punct { char: ',', spacing: Alone, span: bytes(6253..6254) }, Ident { sym: lhs_content, span: bytes(6263..6274) }, Punct { char: ':', spacing: Alone, span: bytes(6274..6275) }, Ident { sym: lhs_text, span: bytes(6276..6284) }, Punct { char: ',', spacing: Alone, span: bytes(6284..6285) }, Ident { sym: rhs_content, span: bytes(6294..6305) }, Punct { char: ':', spacing: Alone, span: bytes(6305..6306) }, Ident { sym: rhs_text, span: bytes(6307..6315) }, Punct { char: ',', spacing: Alone, span: bytes(6315..6316) }], span: bytes(5895..6322) }], span: bytes(5881..6324) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(6326..6372) }, Punct { char: '=', spacing: Alone, span: bytes(6326..6372) }, Literal { lit: " Parse difftastic JSON output into sections", span: bytes(6326..6372) }], span: bytes(6326..6372) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(6373..6376) }, Punct { char: '=', spacing: Alone, span: bytes(6373..6376) }, Literal { lit: "", span: bytes(6373..6376) }], span: bytes(6373..6376) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(6377..6452) }, Punct { char: '=', spacing: Alone, span: bytes(6377..6452) }, Literal { lit: " Files become non-navigable containers, hunks become navigable sections.", span: bytes(6377..6452) }], span: bytes(6377..6452) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(6453..6456) }, Punct { char: '=', spacing: Alone, span: bytes(6453..6456) }, Literal { lit: "", span: bytes(6453..6456) }], span: bytes(6453..6456) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(6457..6469) }, Punct { char: '=', spacing: Alone, span: bytes(6457..6469) }, Literal { lit: " # Errors", span: bytes(6457..6469) }], span: bytes(6457..6469) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(6470..6473) }, Punct { char: '=', spacing: Alone, span: bytes(6470..6473) }, Literal { lit: "", span: bytes(6470..6473) }], span: bytes(6470..6473) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(6474..6545) }, Punct { char: '=', spacing: Alone, span: bytes(6474..6545) }, Literal { lit: " Returns an error if JSON parsing fails or if the format is invalid.", span: bytes(6474..6545) }], span: bytes(6474..6545) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(6546..6549) }, string: "pub" }))), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(6550..6552) }, string: "fn" }), name: Ident { sym: parse_difftastic_json, span: bytes(6553..6574) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: json_str, span: bytes(6575..6583) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(6585..6586) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(6586..6589) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: io, span: bytes(6594..6596) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(6596..6597) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(6597..6598) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Result, span: bytes(6598..6604) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(6605..6608) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Section, span: bytes(6609..6616) })) }], third: Operator<'>'> })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(6625..6628) }, Ident { sym: files, span: bytes(6629..6634) }, Punct { char: ':', spacing: Alone, span: bytes(6634..6635) }, Ident { sym: Vec, span: bytes(6636..6639) }, Punct { char: '<', spacing: Alone, span: bytes(6639..6640) }, Ident { sym: DifftFile, span: bytes(6640..6649) }, Punct { char: '>', spacing: Alone, span: bytes(6649..6650) }, Punct { char: '=', spacing: Alone, span: bytes(6651..6652) }, Ident { sym: if, span: bytes(6653..6655) }, Ident { sym: let, span: bytes(6656..6659) }, Ident { sym: Ok, span: bytes(6660..6662) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: files, span: bytes(6663..6668) }], span: bytes(6662..6669) }, Punct { char: '=', spacing: Alone, span: bytes(6670..6671) }, Ident { sym: serde_json, span: bytes(6672..6682) }, Punct { char: ':', spacing: Joint, span: bytes(6682..6683) }, Punct { char: ':', spacing: Alone, span: bytes(6683..6684) }, Ident { sym: from_str, span: bytes(6684..6692) }, Punct { char: ':', spacing: Joint, span: bytes(6692..6693) }, Punct { char: ':', spacing: Joint, span: bytes(6693..6694) }, Punct { char: '<', spacing: Alone, span: bytes(6694..6695) }, Ident { sym: Vec, span: bytes(6695..6698) }, Punct { char: '<', spacing: Alone, span: bytes(6698..6699) }, Ident { sym: DifftFile, span: bytes(6699..6708) }, Punct { char: '>', spacing: Joint, span: bytes(6708..6709) }, Punct { char: '>', spacing: Alone, span: bytes(6709..6710) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: json_str, span: bytes(6711..6719) }], span: bytes(6710..6720) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: files, span: bytes(6779..6784) }], span: bytes(6725..6790) }, Ident { sym: else, span: bytes(6791..6795) }, Ident { sym: if, span: bytes(6796..6798) }, Ident { sym: json_str, span: bytes(6799..6807) }, Punct { char: '.', spacing: Alone, span: bytes(6807..6808) }, Ident { sym: trim, span: bytes(6808..6812) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(6812..6814) }, Punct { char: '.', spacing: Alone, span: bytes(6814..6815) }, Ident { sym: starts_with, span: bytes(6815..6826) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '[', span: bytes(6827..6830) }], span: bytes(6826..6831) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: return, span: bytes(6894..6900) }, Ident { sym: Err, span: bytes(6901..6904) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: io, span: bytes(6905..6907) }, Punct { char: ':', spacing: Joint, span: bytes(6907..6908) }, Punct { char: ':', spacing: Alone, span: bytes(6908..6909) }, Ident { sym: Error, span: bytes(6909..6914) }, Punct { char: ':', spacing: Joint, span: bytes(6914..6915) }, Punct { char: ':', spacing: Alone, span: bytes(6915..6916) }, Ident { sym: new, span: bytes(6916..6919) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: io, span: bytes(6933..6935) }, Punct { char: ':', spacing: Joint, span: bytes(6935..6936) }, Punct { char: ':', spacing: Alone, span: bytes(6936..6937) }, Ident { sym: ErrorKind, span: bytes(6937..6946) }, Punct { char: ':', spacing: Joint, span: bytes(6946..6947) }, Punct { char: ':', spacing: Alone, span: bytes(6947..6948) }, Ident { sym: InvalidData, span: bytes(6948..6959) }, Punct { char: ',', spacing: Alone, span: bytes(6959..6960) }, Literal { lit: "Invalid JSON array format", span: bytes(6973..7000) }, Punct { char: ',', spacing: Alone, span: bytes(7000..7001) }], span: bytes(6919..7011) }], span: bytes(6904..7012) }, Punct { char: ';', spacing: Alone, span: bytes(7012..7013) }], span: bytes(6832..7019) }, Ident { sym: else, span: bytes(7020..7024) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: json_str, span: bytes(7104..7112) }, Punct { char: '.', spacing: Alone, span: bytes(7125..7126) }, Ident { sym: lines, span: bytes(7126..7131) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(7131..7133) }, Punct { char: '.', spacing: Alone, span: bytes(7146..7147) }, Ident { sym: filter, span: bytes(7147..7153) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(7154..7155) }, Ident { sym: line, span: bytes(7155..7159) }, Punct { char: '|', spacing: Alone, span: bytes(7159..7160) }, Punct { char: '!', spacing: Alone, span: bytes(7161..7162) }, Ident { sym: line, span: bytes(7162..7166) }, Punct { char: '.', spacing: Alone, span: bytes(7166..7167) }, Ident { sym: trim, span: bytes(7167..7171) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(7171..7173) }, Punct { char: '.', spacing: Alone, span: bytes(7173..7174) }, Ident { sym: is_empty, span: bytes(7174..7182) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(7182..7184) }], span: bytes(7153..7185) }, Punct { char: '.', spacing: Alone, span: bytes(7198..7199) }, Ident { sym: map, span: bytes(7199..7202) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(7203..7204) }, Ident { sym: line, span: bytes(7204..7208) }, Punct { char: '|', spacing: Alone, span: bytes(7208..7209) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: serde_json, span: bytes(7228..7238) }, Punct { char: ':', spacing: Joint, span: bytes(7238..7239) }, Punct { char: ':', spacing: Alone, span: bytes(7239..7240) }, Ident { sym: from_str, span: bytes(7240..7248) }, Punct { char: ':', spacing: Joint, span: bytes(7248..7249) }, Punct { char: ':', spacing: Joint, span: bytes(7249..7250) }, Punct { char: '<', spacing: Alone, span: bytes(7250..7251) }, Ident { sym: DifftFile, span: bytes(7251..7260) }, Punct { char: '>', spacing: Alone, span: bytes(7260..7261) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line, span: bytes(7262..7266) }], span: bytes(7261..7267) }, Punct { char: '.', spacing: Alone, span: bytes(7267..7268) }, Ident { sym: map_err, span: bytes(7268..7275) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(7276..7277) }, Ident { sym: e, span: bytes(7277..7278) }, Punct { char: '|', spacing: Alone, span: bytes(7278..7279) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: io, span: bytes(7302..7304) }, Punct { char: ':', spacing: Joint, span: bytes(7304..7305) }, Punct { char: ':', spacing: Alone, span: bytes(7305..7306) }, Ident { sym: Error, span: bytes(7306..7311) }, Punct { char: ':', spacing: Joint, span: bytes(7311..7312) }, Punct { char: ':', spacing: Alone, span: bytes(7312..7313) }, Ident { sym: new, span: bytes(7313..7316) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: io, span: bytes(7342..7344) }, Punct { char: ':', spacing: Joint, span: bytes(7344..7345) }, Punct { char: ':', spacing: Alone, span: bytes(7345..7346) }, Ident { sym: ErrorKind, span: bytes(7346..7355) }, Punct { char: ':', spacing: Joint, span: bytes(7355..7356) }, Punct { char: ':', spacing: Alone, span: bytes(7356..7357) }, Ident { sym: InvalidData, span: bytes(7357..7368) }, Punct { char: ',', spacing: Alone, span: bytes(7368..7369) }, Ident { sym: format, span: bytes(7394..7400) }, Punct { char: '!', spacing: Alone, span: bytes(7400..7401) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Failed to parse JSON line: {e}", span: bytes(7402..7434) }], span: bytes(7401..7435) }, Punct { char: ',', spacing: Alone, span: bytes(7435..7436) }], span: bytes(7316..7458) }], span: bytes(7280..7476) }], span: bytes(7275..7477) }], span: bytes(7210..7491) }], span: bytes(7202..7492) }, Punct { char: '.', spacing: Alone, span: bytes(7505..7506) }, Ident { sym: collect, span: bytes(7506..7513) }, Punct { char: ':', spacing: Joint, span: bytes(7513..7514) }, Punct { char: ':', spacing: Joint, span: bytes(7514..7515) }, Punct { char: '<', spacing: Alone, span: bytes(7515..7516) }, Ident { sym: Result, span: bytes(7516..7522) }, Punct { char: '<', spacing: Alone, span: bytes(7522..7523) }, Ident { sym: Vec, span: bytes(7523..7526) }, Punct { char: '<', spacing: Alone, span: bytes(7526..7527) }, Ident { sym: DifftFile, span: bytes(7527..7536) }, Punct { char: '>', spacing: Joint, span: bytes(7536..7537) }, Punct { char: ',', spacing: Alone, span: bytes(7537..7538) }, Ident { sym: io, span: bytes(7539..7541) }, Punct { char: ':', spacing: Joint, span: bytes(7541..7542) }, Punct { char: ':', spacing: Alone, span: bytes(7542..7543) }, Ident { sym: Error, span: bytes(7543..7548) }, Punct { char: '>', spacing: Joint, span: bytes(7548..7549) }, Punct { char: '>', spacing: Alone, span: bytes(7549..7550) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(7550..7552) }, Punct { char: '?', spacing: Alone, span: bytes(7552..7553) }], span: bytes(7025..7559) }, Punct { char: ';', spacing: Alone, span: bytes(7559..7560) }, Ident { sym: let, span: bytes(7566..7569) }, Ident { sym: mut, span: bytes(7570..7573) }, Ident { sym: sections, span: bytes(7574..7582) }, Punct { char: '=', spacing: Alone, span: bytes(7583..7584) }, Ident { sym: Vec, span: bytes(7585..7588) }, Punct { char: ':', spacing: Joint, span: bytes(7588..7589) }, Punct { char: ':', spacing: Alone, span: bytes(7589..7590) }, Ident { sym: new, span: bytes(7590..7593) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(7593..7595) }, Punct { char: ';', spacing: Alone, span: bytes(7595..7596) }, Ident { sym: let, span: bytes(7601..7604) }, Ident { sym: mut, span: bytes(7605..7608) }, Ident { sym: global_line, span: bytes(7609..7620) }, Punct { char: '=', spacing: Alone, span: bytes(7621..7622) }, Literal { lit: 0i64, span: bytes(7623..7627) }, Punct { char: ';', spacing: Alone, span: bytes(7627..7628) }, Ident { sym: for, span: bytes(7634..7637) }, Ident { sym: file, span: bytes(7638..7642) }, Ident { sym: in, span: bytes(7643..7645) }, Punct { char: '&', spacing: Alone, span: bytes(7646..7647) }, Ident { sym: files, span: bytes(7647..7652) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(7695..7697) }, Ident { sym: file, span: bytes(7698..7702) }, Punct { char: '.', spacing: Alone, span: bytes(7702..7703) }, Ident { sym: status, span: bytes(7703..7709) }, Punct { char: '=', spacing: Joint, span: bytes(7710..7711) }, Punct { char: '=', spacing: Alone, span: bytes(7711..7712) }, Literal { lit: "unchanged", span: bytes(7713..7724) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: continue, span: bytes(7739..7747) }, Punct { char: ';', spacing: Alone, span: bytes(7747..7748) }], span: bytes(7725..7758) }, Ident { sym: let, span: bytes(7768..7771) }, Ident { sym: file_path, span: bytes(7772..7781) }, Punct { char: '=', spacing: Alone, span: bytes(7782..7783) }, Punct { char: '&', spacing: Alone, span: bytes(7784..7785) }, Ident { sym: file, span: bytes(7785..7789) }, Punct { char: '.', spacing: Alone, span: bytes(7789..7790) }, Ident { sym: path, span: bytes(7790..7794) }, Punct { char: ';', spacing: Alone, span: bytes(7794..7795) }, Ident { sym: if, span: bytes(7864..7866) }, Ident { sym: let, span: bytes(7867..7870) }, Ident { sym: Some, span: bytes(7871..7875) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: chunks, span: bytes(7876..7882) }], span: bytes(7875..7883) }, Punct { char: '=', spacing: Alone, span: bytes(7884..7885) }, Punct { char: '&', spacing: Alone, span: bytes(7886..7887) }, Ident { sym: file, span: bytes(7887..7891) }, Punct { char: '.', spacing: Alone, span: bytes(7891..7892) }, Ident { sym: chunks, span: bytes(7892..7898) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(7913..7916) }, Ident { sym: mut, span: bytes(7917..7920) }, Ident { sym: hunk_counter, span: bytes(7921..7933) }, Punct { char: '=', spacing: Alone, span: bytes(7934..7935) }, Literal { lit: 0, span: bytes(7936..7937) }, Punct { char: ';', spacing: Alone, span: bytes(7937..7938) }, Ident { sym: for, span: bytes(7951..7954) }, Ident { sym: chunk, span: bytes(7955..7960) }, Ident { sym: in, span: bytes(7961..7963) }, Ident { sym: chunks, span: bytes(7964..7970) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: for, span: bytes(8059..8062) }, Ident { sym: change, span: bytes(8063..8069) }, Ident { sym: in, span: bytes(8070..8072) }, Ident { sym: chunk, span: bytes(8073..8078) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: hunk_counter, span: bytes(8101..8113) }, Punct { char: '+', spacing: Joint, span: bytes(8114..8115) }, Punct { char: '=', spacing: Alone, span: bytes(8115..8116) }, Literal { lit: 1, span: bytes(8117..8118) }, Punct { char: ';', spacing: Alone, span: bytes(8118..8119) }, Ident { sym: let, span: bytes(8220..8223) }, Ident { sym: hunk_title, span: bytes(8224..8234) }, Punct { char: '=', spacing: Alone, span: bytes(8235..8236) }, Ident { sym: format_hunk_header, span: bytes(8237..8255) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: change, span: bytes(8256..8262) }, Punct { char: ',', spacing: Alone, span: bytes(8262..8263) }, Ident { sym: hunk_counter, span: bytes(8264..8276) }], span: bytes(8255..8277) }, Punct { char: ';', spacing: Alone, span: bytes(8277..8278) }, Ident { sym: let, span: bytes(8299..8302) }, Ident { sym: hunk_content, span: bytes(8303..8315) }, Punct { char: '=', spacing: Alone, span: bytes(8316..8317) }, Ident { sym: format_change_content, span: bytes(8318..8339) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: change, span: bytes(8340..8346) }], span: bytes(8339..8347) }, Punct { char: ';', spacing: Alone, span: bytes(8347..8348) }, Ident { sym: let, span: bytes(8370..8373) }, Ident { sym: hunk_start_line, span: bytes(8374..8389) }, Punct { char: '=', spacing: Alone, span: bytes(8390..8391) }, Ident { sym: global_line, span: bytes(8392..8403) }, Punct { char: ';', spacing: Alone, span: bytes(8403..8404) }, Ident { sym: let, span: bytes(8425..8428) }, Ident { sym: hunk_end_line, span: bytes(8429..8442) }, Punct { char: '=', spacing: Alone, span: bytes(8443..8444) }, Ident { sym: global_line, span: bytes(8469..8480) }, Punct { char: '+', spacing: Alone, span: bytes(8481..8482) }, Ident { sym: i64, span: bytes(8483..8486) }, Punct { char: ':', spacing: Joint, span: bytes(8486..8487) }, Punct { char: ':', spacing: Alone, span: bytes(8487..8488) }, Ident { sym: try_from, span: bytes(8488..8496) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: hunk_content, span: bytes(8497..8509) }, Punct { char: '.', spacing: Alone, span: bytes(8509..8510) }, Ident { sym: lines, span: bytes(8510..8515) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(8515..8517) }, Punct { char: '.', spacing: Alone, span: bytes(8517..8518) }, Ident { sym: count, span: bytes(8518..8523) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(8523..8525) }], span: bytes(8496..8526) }, Punct { char: '.', spacing: Alone, span: bytes(8526..8527) }, Ident { sym: unwrap_or, span: bytes(8527..8536) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(8537..8538) }], span: bytes(8536..8539) }, Punct { char: ';', spacing: Alone, span: bytes(8539..8540) }, Ident { sym: sections, span: bytes(8614..8622) }, Punct { char: '.', spacing: Alone, span: bytes(8622..8623) }, Ident { sym: push, span: bytes(8623..8627) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Section, span: bytes(8628..8635) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: title, span: bytes(8662..8667) }, Punct { char: ':', spacing: Alone, span: bytes(8667..8668) }, Ident { sym: hunk_title, span: bytes(8669..8679) }, Punct { char: ',', spacing: Alone, span: bytes(8679..8680) }, Ident { sym: level, span: bytes(8705..8710) }, Punct { char: ':', spacing: Alone, span: bytes(8710..8711) }, Literal { lit: 1, span: bytes(8712..8713) }, Punct { char: ',', spacing: Alone, span: bytes(8713..8714) }, Ident { sym: line_start, span: bytes(8739..8749) }, Punct { char: ':', spacing: Alone, span: bytes(8749..8750) }, Ident { sym: hunk_start_line, span: bytes(8751..8766) }, Punct { char: ',', spacing: Alone, span: bytes(8766..8767) }, Ident { sym: line_end, span: bytes(8792..8800) }, Punct { char: ':', spacing: Alone, span: bytes(8800..8801) }, Ident { sym: hunk_end_line, span: bytes(8802..8815) }, Punct { char: ',', spacing: Alone, span: bytes(8815..8816) }, Ident { sym: column_start, span: bytes(8841..8853) }, Punct { char: ':', spacing: Alone, span: bytes(8853..8854) }, Literal { lit: 0, span: bytes(8855..8856) }, Punct { char: ',', spacing: Alone, span: bytes(8856..8857) }, Ident { sym: column_end, span: bytes(8882..8892) }, Punct { char: ':', spacing: Alone, span: bytes(8892..8893) }, Literal { lit: 0, span: bytes(8894..8895) }, Punct { char: ',', spacing: Alone, span: bytes(8895..8896) }, Ident { sym: byte_start, span: bytes(8921..8931) }, Punct { char: ':', spacing: Alone, span: bytes(8931..8932) }, Literal { lit: 0, span: bytes(8933..8934) }, Punct { char: ',', spacing: Alone, span: bytes(8934..8935) }, Ident { sym: byte_end, span: bytes(8960..8968) }, Punct { char: ':', spacing: Alone, span: bytes(8968..8969) }, Literal { lit: 0, span: bytes(8970..8971) }, Punct { char: ',', spacing: Alone, span: bytes(8971..8972) }, Ident { sym: file_path, span: bytes(8997..9006) }, Punct { char: ':', spacing: Alone, span: bytes(9006..9007) }, Ident { sym: file_path, span: bytes(9008..9017) }, Punct { char: '.', spacing: Alone, span: bytes(9017..9018) }, Ident { sym: clone, span: bytes(9018..9023) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(9023..9025) }, Punct { char: ',', spacing: Alone, span: bytes(9025..9026) }, Ident { sym: parent_index, span: bytes(9051..9063) }, Punct { char: ':', spacing: Alone, span: bytes(9063..9064) }, Ident { sym: None, span: bytes(9065..9069) }, Punct { char: ',', spacing: Alone, span: bytes(9069..9070) }, Ident { sym: children_indices, span: bytes(9095..9111) }, Punct { char: ':', spacing: Alone, span: bytes(9111..9112) }, Ident { sym: Vec, span: bytes(9113..9116) }, Punct { char: ':', spacing: Joint, span: bytes(9116..9117) }, Punct { char: ':', spacing: Alone, span: bytes(9117..9118) }, Ident { sym: new, span: bytes(9118..9121) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(9121..9123) }, Punct { char: ',', spacing: Alone, span: bytes(9123..9124) }, Ident { sym: section_content, span: bytes(9149..9164) }, Punct { char: ':', spacing: Alone, span: bytes(9164..9165) }, Ident { sym: Some, span: bytes(9166..9170) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: vec, span: bytes(9171..9174) }, Punct { char: '!', spacing: Alone, span: bytes(9174..9175) }, Group { delimiter: Bracket, stream: TokenStream [Ident { sym: hunk_content, span: bytes(9176..9188) }], span: bytes(9175..9189) }], span: bytes(9170..9190) }, Punct { char: ',', spacing: Alone, span: bytes(9190..9191) }, Ident { sym: chunk_type, span: bytes(9216..9226) }, Punct { char: ':', spacing: Alone, span: bytes(9226..9227) }, Ident { sym: None, span: bytes(9228..9232) }, Punct { char: ',', spacing: Alone, span: bytes(9232..9233) }, Ident { sym: lhs_content, span: bytes(9258..9269) }, Punct { char: ':', spacing: Alone, span: bytes(9269..9270) }, Ident { sym: None, span: bytes(9271..9275) }, Punct { char: ',', spacing: Alone, span: bytes(9275..9276) }, Ident { sym: rhs_content, span: bytes(9301..9312) }, Punct { char: ':', spacing: Alone, span: bytes(9312..9313) }, Ident { sym: None, span: bytes(9314..9318) }, Punct { char: ',', spacing: Alone, span: bytes(9318..9319) }], span: bytes(8636..9341) }], span: bytes(8627..9342) }, Punct { char: ';', spacing: Alone, span: bytes(9342..9343) }, Ident { sym: global_line, span: bytes(9365..9376) }, Punct { char: '=', spacing: Alone, span: bytes(9377..9378) }, Ident { sym: hunk_end_line, span: bytes(9379..9392) }, Punct { char: '+', spacing: Alone, span: bytes(9393..9394) }, Literal { lit: 1, span: bytes(9395..9396) }, Punct { char: ';', spacing: Alone, span: bytes(9396..9397) }], span: bytes(8079..9415) }], span: bytes(7971..9429) }], span: bytes(7899..9439) }, Ident { sym: else, span: bytes(9440..9444) }, Ident { sym: if, span: bytes(9445..9447) }, Ident { sym: file, span: bytes(9448..9452) }, Punct { char: '.', spacing: Alone, span: bytes(9452..9453) }, Ident { sym: status, span: bytes(9453..9459) }, Punct { char: '=', spacing: Joint, span: bytes(9460..9461) }, Punct { char: '=', spacing: Alone, span: bytes(9461..9462) }, Literal { lit: "created", span: bytes(9463..9472) }, Punct { char: '|', spacing: Joint, span: bytes(9473..9474) }, Punct { char: '|', spacing: Alone, span: bytes(9474..9475) }, Ident { sym: file, span: bytes(9476..9480) }, Punct { char: '.', spacing: Alone, span: bytes(9480..9481) }, Ident { sym: status, span: bytes(9481..9487) }, Punct { char: '=', spacing: Joint, span: bytes(9488..9489) }, Punct { char: '=', spacing: Alone, span: bytes(9489..9490) }, Literal { lit: "deleted", span: bytes(9491..9500) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(9695..9698) }, Ident { sym: line_count, span: bytes(9699..9709) }, Punct { char: '=', spacing: Alone, span: bytes(9710..9711) }, Ident { sym: if, span: bytes(9712..9714) }, Ident { sym: file, span: bytes(9715..9719) }, Punct { char: '.', spacing: Alone, span: bytes(9719..9720) }, Ident { sym: status, span: bytes(9720..9726) }, Punct { char: '=', spacing: Joint, span: bytes(9727..9728) }, Punct { char: '=', spacing: Alone, span: bytes(9728..9729) }, Literal { lit: "created", span: bytes(9730..9739) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: std, span: bytes(9824..9827) }, Punct { char: ':', spacing: Joint, span: bytes(9827..9828) }, Punct { char: ':', spacing: Alone, span: bytes(9828..9829) }, Ident { sym: fs, span: bytes(9829..9831) }, Punct { char: ':', spacing: Joint, span: bytes(9831..9832) }, Punct { char: ':', spacing: Alone, span: bytes(9832..9833) }, Ident { sym: read_to_string, span: bytes(9833..9847) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: file_path, span: bytes(9848..9857) }], span: bytes(9847..9858) }, Punct { char: '.', spacing: Alone, span: bytes(9879..9880) }, Ident { sym: ok, span: bytes(9880..9882) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(9882..9884) }, Punct { char: '.', spacing: Alone, span: bytes(9905..9906) }, Ident { sym: map_or, span: bytes(9906..9912) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(9913..9914) }, Punct { char: ',', spacing: Alone, span: bytes(9914..9915) }, Punct { char: '|', spacing: Alone, span: bytes(9916..9917) }, Ident { sym: content, span: bytes(9917..9924) }, Punct { char: '|', spacing: Alone, span: bytes(9924..9925) }, Ident { sym: content, span: bytes(9926..9933) }, Punct { char: '.', spacing: Alone, span: bytes(9933..9934) }, Ident { sym: lines, span: bytes(9934..9939) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(9939..9941) }, Punct { char: '.', spacing: Alone, span: bytes(9941..9942) }, Ident { sym: count, span: bytes(9942..9947) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(9947..9949) }], span: bytes(9912..9950) }], span: bytes(9740..9964) }, Ident { sym: else, span: bytes(9965..9969) }, Group { delimiter: Brace, stream: TokenStream [Literal { lit: 0, span: bytes(9988..9989) }], span: bytes(9970..10020) }, Punct { char: ';', spacing: Alone, span: bytes(10020..10021) }, Ident { sym: let, span: bytes(10035..10038) }, Ident { sym: hunk_title, span: bytes(10039..10049) }, Punct { char: '=', spacing: Alone, span: bytes(10050..10051) }, Ident { sym: if, span: bytes(10052..10054) }, Ident { sym: file, span: bytes(10055..10059) }, Punct { char: '.', spacing: Alone, span: bytes(10059..10060) }, Ident { sym: status, span: bytes(10060..10066) }, Punct { char: '=', spacing: Joint, span: bytes(10067..10068) }, Punct { char: '=', spacing: Alone, span: bytes(10068..10069) }, Literal { lit: "created", span: bytes(10070..10079) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: format, span: bytes(10098..10104) }, Punct { char: '!', spacing: Alone, span: bytes(10104..10105) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "(1) @@ -0,0 +1,{line_count} @@", span: bytes(10106..10138) }], span: bytes(10105..10139) }], span: bytes(10080..10153) }, Ident { sym: else, span: bytes(10154..10158) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: format, span: bytes(10177..10183) }, Punct { char: '!', spacing: Alone, span: bytes(10183..10184) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "(1) @@ -1,{line_count} +0,0 @@", span: bytes(10185..10217) }], span: bytes(10184..10218) }], span: bytes(10159..10232) }, Punct { char: ';', spacing: Alone, span: bytes(10232..10233) }, Ident { sym: let, span: bytes(10247..10250) }, Ident { sym: hunk_content, span: bytes(10251..10263) }, Punct { char: '=', spacing: Alone, span: bytes(10264..10265) }, Ident { sym: if, span: bytes(10266..10268) }, Ident { sym: file, span: bytes(10269..10273) }, Punct { char: '.', spacing: Alone, span: bytes(10273..10274) }, Ident { sym: status, span: bytes(10274..10280) }, Punct { char: '=', spacing: Joint, span: bytes(10281..10282) }, Punct { char: '=', spacing: Alone, span: bytes(10282..10283) }, Literal { lit: "created", span: bytes(10284..10293) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: std, span: bytes(10312..10315) }, Punct { char: ':', spacing: Joint, span: bytes(10315..10316) }, Punct { char: ':', spacing: Alone, span: bytes(10316..10317) }, Ident { sym: fs, span: bytes(10317..10319) }, Punct { char: ':', spacing: Joint, span: bytes(10319..10320) }, Punct { char: ':', spacing: Alone, span: bytes(10320..10321) }, Ident { sym: read_to_string, span: bytes(10321..10335) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: file_path, span: bytes(10336..10345) }], span: bytes(10335..10346) }, Punct { char: '.', spacing: Alone, span: bytes(10367..10368) }, Ident { sym: ok, span: bytes(10368..10370) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(10370..10372) }, Punct { char: '.', spacing: Alone, span: bytes(10393..10394) }, Ident { sym: unwrap_or_else, span: bytes(10394..10408) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Joint, span: bytes(10409..10410) }, Punct { char: '|', spacing: Alone, span: bytes(10410..10411) }, Ident { sym: format, span: bytes(10412..10418) }, Punct { char: '!', spacing: Alone, span: bytes(10418..10419) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "File was {}", span: bytes(10420..10433) }, Punct { char: ',', spacing: Alone, span: bytes(10433..10434) }, Ident { sym: file, span: bytes(10435..10439) }, Punct { char: '.', spacing: Alone, span: bytes(10439..10440) }, Ident { sym: status, span: bytes(10440..10446) }], span: bytes(10419..10447) }], span: bytes(10408..10448) }], span: bytes(10294..10462) }, Ident { sym: else, span: bytes(10463..10467) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: format, span: bytes(10486..10492) }, Punct { char: '!', spacing: Alone, span: bytes(10492..10493) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "File was {}", span: bytes(10494..10507) }, Punct { char: ',', spacing: Alone, span: bytes(10507..10508) }, Ident { sym: file, span: bytes(10509..10513) }, Punct { char: '.', spacing: Alone, span: bytes(10513..10514) }, Ident { sym: status, span: bytes(10514..10520) }], span: bytes(10493..10521) }], span: bytes(10468..10535) }, Punct { char: ';', spacing: Alone, span: bytes(10535..10536) }, Ident { sym: sections, span: bytes(10550..10558) }, Punct { char: '.', spacing: Alone, span: bytes(10558..10559) }, Ident { sym: push, span: bytes(10559..10563) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Section, span: bytes(10564..10571) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: title, span: bytes(10590..10595) }, Punct { char: ':', spacing: Alone, span: bytes(10595..10596) }, Ident { sym: hunk_title, span: bytes(10597..10607) }, Punct { char: ',', spacing: Alone, span: bytes(10607..10608) }, Ident { sym: level, span: bytes(10625..10630) }, Punct { char: ':', spacing: Alone, span: bytes(10630..10631) }, Literal { lit: 1, span: bytes(10632..10633) }, Punct { char: ',', spacing: Alone, span: bytes(10633..10634) }, Ident { sym: line_start, span: bytes(10651..10661) }, Punct { char: ':', spacing: Alone, span: bytes(10661..10662) }, Ident { sym: global_line, span: bytes(10663..10674) }, Punct { char: ',', spacing: Alone, span: bytes(10674..10675) }, Ident { sym: line_end, span: bytes(10692..10700) }, Punct { char: ':', spacing: Alone, span: bytes(10700..10701) }, Ident { sym: global_line, span: bytes(10702..10713) }, Punct { char: '+', spacing: Alone, span: bytes(10714..10715) }, Ident { sym: i64, span: bytes(10716..10719) }, Punct { char: ':', spacing: Joint, span: bytes(10719..10720) }, Punct { char: ':', spacing: Alone, span: bytes(10720..10721) }, Ident { sym: try_from, span: bytes(10721..10729) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line_count, span: bytes(10730..10740) }], span: bytes(10729..10741) }, Punct { char: '.', spacing: Alone, span: bytes(10741..10742) }, Ident { sym: unwrap_or, span: bytes(10742..10751) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(10752..10753) }], span: bytes(10751..10754) }, Punct { char: ',', spacing: Alone, span: bytes(10754..10755) }, Ident { sym: column_start, span: bytes(10772..10784) }, Punct { char: ':', spacing: Alone, span: bytes(10784..10785) }, Literal { lit: 0, span: bytes(10786..10787) }, Punct { char: ',', spacing: Alone, span: bytes(10787..10788) }, Ident { sym: column_end, span: bytes(10805..10815) }, Punct { char: ':', spacing: Alone, span: bytes(10815..10816) }, Literal { lit: 0, span: bytes(10817..10818) }, Punct { char: ',', spacing: Alone, span: bytes(10818..10819) }, Ident { sym: byte_start, span: bytes(10836..10846) }, Punct { char: ':', spacing: Alone, span: bytes(10846..10847) }, Literal { lit: 0, span: bytes(10848..10849) }, Punct { char: ',', spacing: Alone, span: bytes(10849..10850) }, Ident { sym: byte_end, span: bytes(10867..10875) }, Punct { char: ':', spacing: Alone, span: bytes(10875..10876) }, Literal { lit: 0, span: bytes(10877..10878) }, Punct { char: ',', spacing: Alone, span: bytes(10878..10879) }, Ident { sym: file_path, span: bytes(10896..10905) }, Punct { char: ':', spacing: Alone, span: bytes(10905..10906) }, Ident { sym: file_path, span: bytes(10907..10916) }, Punct { char: '.', spacing: Alone, span: bytes(10916..10917) }, Ident { sym: clone, span: bytes(10917..10922) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(10922..10924) }, Punct { char: ',', spacing: Alone, span: bytes(10924..10925) }, Ident { sym: parent_index, span: bytes(10942..10954) }, Punct { char: ':', spacing: Alone, span: bytes(10954..10955) }, Ident { sym: None, span: bytes(10956..10960) }, Punct { char: ',', spacing: Alone, span: bytes(10960..10961) }, Ident { sym: children_indices, span: bytes(10978..10994) }, Punct { char: ':', spacing: Alone, span: bytes(10994..10995) }, Ident { sym: Vec, span: bytes(10996..10999) }, Punct { char: ':', spacing: Joint, span: bytes(10999..11000) }, Punct { char: ':', spacing: Alone, span: bytes(11000..11001) }, Ident { sym: new, span: bytes(11001..11004) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(11004..11006) }, Punct { char: ',', spacing: Alone, span: bytes(11006..11007) }, Ident { sym: section_content, span: bytes(11024..11039) }, Punct { char: ':', spacing: Alone, span: bytes(11039..11040) }, Ident { sym: Some, span: bytes(11041..11045) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: hunk_content, span: bytes(11046..11058) }, Punct { char: '.', spacing: Alone, span: bytes(11058..11059) }, Ident { sym: lines, span: bytes(11059..11064) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(11064..11066) }, Punct { char: '.', spacing: Alone, span: bytes(11066..11067) }, Ident { sym: map, span: bytes(11067..11070) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: String, span: bytes(11071..11077) }, Punct { char: ':', spacing: Joint, span: bytes(11077..11078) }, Punct { char: ':', spacing: Alone, span: bytes(11078..11079) }, Ident { sym: from, span: bytes(11079..11083) }], span: bytes(11070..11084) }, Punct { char: '.', spacing: Alone, span: bytes(11084..11085) }, Ident { sym: collect, span: bytes(11085..11092) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(11092..11094) }], span: bytes(11045..11095) }, Punct { char: ',', spacing: Alone, span: bytes(11095..11096) }, Ident { sym: chunk_type, span: bytes(11113..11123) }, Punct { char: ':', spacing: Alone, span: bytes(11123..11124) }, Ident { sym: None, span: bytes(11125..11129) }, Punct { char: ',', spacing: Alone, span: bytes(11129..11130) }, Ident { sym: lhs_content, span: bytes(11147..11158) }, Punct { char: ':', spacing: Alone, span: bytes(11158..11159) }, Ident { sym: None, span: bytes(11160..11164) }, Punct { char: ',', spacing: Alone, span: bytes(11164..11165) }, Ident { sym: rhs_content, span: bytes(11182..11193) }, Punct { char: ':', spacing: Alone, span: bytes(11193..11194) }, Ident { sym: None, span: bytes(11195..11199) }, Punct { char: ',', spacing: Alone, span: bytes(11199..11200) }], span: bytes(10572..11214) }], span: bytes(10563..11215) }, Punct { char: ';', spacing: Alone, span: bytes(11215..11216) }, Ident { sym: global_line, span: bytes(11230..11241) }, Punct { char: '+', spacing: Joint, span: bytes(11242..11243) }, Punct { char: '=', spacing: Alone, span: bytes(11243..11244) }, Ident { sym: i64, span: bytes(11245..11248) }, Punct { char: ':', spacing: Joint, span: bytes(11248..11249) }, Punct { char: ':', spacing: Alone, span: bytes(11249..11250) }, Ident { sym: try_from, span: bytes(11250..11258) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line_count, span: bytes(11259..11269) }], span: bytes(11258..11270) }, Punct { char: '.', spacing: Alone, span: bytes(11270..11271) }, Ident { sym: unwrap_or, span: bytes(11271..11280) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(11281..11282) }], span: bytes(11280..11283) }, Punct { char: '+', spacing: Alone, span: bytes(11284..11285) }, Literal { lit: 1, span: bytes(11286..11287) }, Punct { char: ';', spacing: Alone, span: bytes(11287..11288) }], span: bytes(9501..11298) }], span: bytes(7653..11304) }, Ident { sym: Ok, span: bytes(11310..11312) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: sections, span: bytes(11313..11321) }], span: bytes(11312..11322) }], span: bytes(6619..11324) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(11326..11378) }, Punct { char: '=', spacing: Alone, span: bytes(11326..11378) }, Literal { lit: " Format a change as a proper git diff hunk header", span: bytes(11326..11378) }], span: bytes(11326..11378) }) }, delimiter: Some(Nothing) }])), visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(11379..11381) }, string: "fn" }), name: Ident { sym: format_hunk_header, span: bytes(11382..11400) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: change, span: bytes(11401..11407) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(11409..11410) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: DifftLine, span: bytes(11410..11419) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: hunk_num, span: bytes(11421..11429) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: usize, span: bytes(11431..11436) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(11441..11447) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(11454..11457) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs_line, span: bytes(11459..11467) }, Punct { char: ',', spacing: Alone, span: bytes(11467..11468) }, Ident { sym: rhs_line, span: bytes(11469..11477) }], span: bytes(11458..11478) }, Punct { char: '=', spacing: Alone, span: bytes(11479..11480) }, Ident { sym: match, span: bytes(11481..11486) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(11488..11489) }, Ident { sym: change, span: bytes(11489..11495) }, Punct { char: '.', spacing: Alone, span: bytes(11495..11496) }, Ident { sym: lhs, span: bytes(11496..11499) }, Punct { char: ',', spacing: Alone, span: bytes(11499..11500) }, Punct { char: '&', spacing: Alone, span: bytes(11501..11502) }, Ident { sym: change, span: bytes(11502..11508) }, Punct { char: '.', spacing: Alone, span: bytes(11508..11509) }, Ident { sym: rhs, span: bytes(11509..11512) }], span: bytes(11487..11513) }, Group { delimiter: Brace, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Some, span: bytes(11525..11529) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs, span: bytes(11530..11533) }], span: bytes(11529..11534) }, Punct { char: ',', spacing: Alone, span: bytes(11534..11535) }, Ident { sym: Some, span: bytes(11536..11540) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rhs, span: bytes(11541..11544) }], span: bytes(11540..11545) }], span: bytes(11524..11546) }, Punct { char: '=', spacing: Joint, span: bytes(11547..11548) }, Punct { char: '>', spacing: Alone, span: bytes(11548..11549) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs, span: bytes(11551..11554) }, Punct { char: '.', spacing: Alone, span: bytes(11554..11555) }, Ident { sym: line_number, span: bytes(11555..11566) }, Punct { char: ',', spacing: Alone, span: bytes(11566..11567) }, Ident { sym: rhs, span: bytes(11568..11571) }, Punct { char: '.', spacing: Alone, span: bytes(11571..11572) }, Ident { sym: line_number, span: bytes(11572..11583) }], span: bytes(11550..11584) }, Punct { char: ',', spacing: Alone, span: bytes(11584..11585) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Some, span: bytes(11595..11599) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs, span: bytes(11600..11603) }], span: bytes(11599..11604) }, Punct { char: ',', spacing: Alone, span: bytes(11604..11605) }, Ident { sym: None, span: bytes(11606..11610) }], span: bytes(11594..11611) }, Punct { char: '=', spacing: Joint, span: bytes(11612..11613) }, Punct { char: '>', spacing: Alone, span: bytes(11613..11614) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs, span: bytes(11616..11619) }, Punct { char: '.', spacing: Alone, span: bytes(11619..11620) }, Ident { sym: line_number, span: bytes(11620..11631) }, Punct { char: ',', spacing: Alone, span: bytes(11631..11632) }, Literal { lit: 0, span: bytes(11633..11634) }], span: bytes(11615..11635) }, Punct { char: ',', spacing: Alone, span: bytes(11635..11636) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: None, span: bytes(11646..11650) }, Punct { char: ',', spacing: Alone, span: bytes(11650..11651) }, Ident { sym: Some, span: bytes(11652..11656) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rhs, span: bytes(11657..11660) }], span: bytes(11656..11661) }], span: bytes(11645..11662) }, Punct { char: '=', spacing: Joint, span: bytes(11663..11664) }, Punct { char: '>', spacing: Alone, span: bytes(11664..11665) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(11667..11668) }, Punct { char: ',', spacing: Alone, span: bytes(11668..11669) }, Ident { sym: rhs, span: bytes(11670..11673) }, Punct { char: '.', spacing: Alone, span: bytes(11673..11674) }, Ident { sym: line_number, span: bytes(11674..11685) }], span: bytes(11666..11686) }, Punct { char: ',', spacing: Alone, span: bytes(11686..11687) }, Ident { sym: _, span: bytes(11696..11697) }, Punct { char: '=', spacing: Joint, span: bytes(11698..11699) }, Punct { char: '>', spacing: Alone, span: bytes(11699..11700) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(11702..11703) }, Punct { char: ',', spacing: Alone, span: bytes(11703..11704) }, Literal { lit: 0, span: bytes(11705..11706) }], span: bytes(11701..11707) }, Punct { char: ',', spacing: Alone, span: bytes(11707..11708) }], span: bytes(11514..11714) }, Punct { char: ';', spacing: Alone, span: bytes(11714..11715) }, Ident { sym: let, span: bytes(11780..11783) }, Ident { sym: lhs_count, span: bytes(11784..11793) }, Punct { char: '=', spacing: Alone, span: bytes(11794..11795) }, Ident { sym: i32, span: bytes(11796..11799) }, Punct { char: ':', spacing: Joint, span: bytes(11799..11800) }, Punct { char: ':', spacing: Alone, span: bytes(11800..11801) }, Ident { sym: from, span: bytes(11801..11805) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: change, span: bytes(11806..11812) }, Punct { char: '.', spacing: Alone, span: bytes(11812..11813) }, Ident { sym: lhs, span: bytes(11813..11816) }, Punct { char: '.', spacing: Alone, span: bytes(11816..11817) }, Ident { sym: is_some, span: bytes(11817..11824) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(11824..11826) }], span: bytes(11805..11827) }, Punct { char: ';', spacing: Alone, span: bytes(11827..11828) }, Ident { sym: let, span: bytes(11833..11836) }, Ident { sym: rhs_count, span: bytes(11837..11846) }, Punct { char: '=', spacing: Alone, span: bytes(11847..11848) }, Ident { sym: i32, span: bytes(11849..11852) }, Punct { char: ':', spacing: Joint, span: bytes(11852..11853) }, Punct { char: ':', spacing: Alone, span: bytes(11853..11854) }, Ident { sym: from, span: bytes(11854..11858) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: change, span: bytes(11859..11865) }, Punct { char: '.', spacing: Alone, span: bytes(11865..11866) }, Ident { sym: rhs, span: bytes(11866..11869) }, Punct { char: '.', spacing: Alone, span: bytes(11869..11870) }, Ident { sym: is_some, span: bytes(11870..11877) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(11877..11879) }], span: bytes(11858..11880) }, Punct { char: ';', spacing: Alone, span: bytes(11880..11881) }, Ident { sym: format, span: bytes(11887..11893) }, Punct { char: '!', spacing: Alone, span: bytes(11893..11894) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "({hunk_num}) @@ -{lhs_line},{lhs_count} +{rhs_line},{rhs_count} @@", span: bytes(11895..11963) }], span: bytes(11894..11964) }], span: bytes(11448..11966) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(11968..12006) }, Punct { char: '=', spacing: Alone, span: bytes(11968..12006) }, Literal { lit: " Format a single change for display", span: bytes(11968..12006) }], span: bytes(11968..12006) }) }, delimiter: Some(Nothing) }])), visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(12007..12009) }, string: "fn" }), name: Ident { sym: format_change_content, span: bytes(12010..12031) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: change, span: bytes(12032..12038) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(12040..12041) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: DifftLine, span: bytes(12041..12050) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(12055..12061) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(12068..12071) }, Ident { sym: mut, span: bytes(12072..12075) }, Ident { sym: output, span: bytes(12076..12082) }, Punct { char: '=', spacing: Alone, span: bytes(12083..12084) }, Ident { sym: String, span: bytes(12085..12091) }, Punct { char: ':', spacing: Joint, span: bytes(12091..12092) }, Punct { char: ':', spacing: Alone, span: bytes(12092..12093) }, Ident { sym: new, span: bytes(12093..12096) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(12096..12098) }, Punct { char: ';', spacing: Alone, span: bytes(12098..12099) }, Ident { sym: match, span: bytes(12105..12110) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(12112..12113) }, Ident { sym: change, span: bytes(12113..12119) }, Punct { char: '.', spacing: Alone, span: bytes(12119..12120) }, Ident { sym: lhs, span: bytes(12120..12123) }, Punct { char: ',', spacing: Alone, span: bytes(12123..12124) }, Punct { char: '&', spacing: Alone, span: bytes(12125..12126) }, Ident { sym: change, span: bytes(12126..12132) }, Punct { char: '.', spacing: Alone, span: bytes(12132..12133) }, Ident { sym: rhs, span: bytes(12133..12136) }], span: bytes(12111..12137) }, Group { delimiter: Brace, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Some, span: bytes(12149..12153) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs, span: bytes(12154..12157) }], span: bytes(12153..12158) }, Punct { char: ',', spacing: Alone, span: bytes(12158..12159) }, Ident { sym: Some, span: bytes(12160..12164) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rhs, span: bytes(12165..12168) }], span: bytes(12164..12169) }], span: bytes(12148..12170) }, Punct { char: '=', spacing: Joint, span: bytes(12171..12172) }, Punct { char: '>', spacing: Alone, span: bytes(12172..12173) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: write, span: bytes(12235..12240) }, Punct { char: '!', spacing: Alone, span: bytes(12240..12241) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: output, span: bytes(12242..12248) }, Punct { char: ',', spacing: Alone, span: bytes(12248..12249) }, Literal { lit: "-{}: ", span: bytes(12250..12257) }, Punct { char: ',', spacing: Alone, span: bytes(12257..12258) }, Ident { sym: lhs, span: bytes(12259..12262) }, Punct { char: '.', spacing: Alone, span: bytes(12262..12263) }, Ident { sym: line_number, span: bytes(12263..12274) }], span: bytes(12241..12275) }, Punct { char: '.', spacing: Alone, span: bytes(12275..12276) }, Ident { sym: unwrap, span: bytes(12276..12282) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(12282..12284) }, Punct { char: ';', spacing: Alone, span: bytes(12284..12285) }, Ident { sym: for, span: bytes(12298..12301) }, Ident { sym: ch, span: bytes(12302..12304) }, Ident { sym: in, span: bytes(12305..12307) }, Punct { char: '&', spacing: Alone, span: bytes(12308..12309) }, Ident { sym: lhs, span: bytes(12309..12312) }, Punct { char: '.', spacing: Alone, span: bytes(12312..12313) }, Ident { sym: changes, span: bytes(12313..12320) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: output, span: bytes(12339..12345) }, Punct { char: '.', spacing: Alone, span: bytes(12345..12346) }, Ident { sym: push_str, span: bytes(12346..12354) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(12355..12356) }, Ident { sym: ch, span: bytes(12356..12358) }, Punct { char: '.', spacing: Alone, span: bytes(12358..12359) }, Ident { sym: content, span: bytes(12359..12366) }], span: bytes(12354..12367) }, Punct { char: ';', spacing: Alone, span: bytes(12367..12368) }], span: bytes(12321..12382) }, Ident { sym: output, span: bytes(12395..12401) }, Punct { char: '.', spacing: Alone, span: bytes(12401..12402) }, Ident { sym: push, span: bytes(12402..12406) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '\n', span: bytes(12407..12411) }], span: bytes(12406..12412) }, Punct { char: ';', spacing: Alone, span: bytes(12412..12413) }, Ident { sym: write, span: bytes(12427..12432) }, Punct { char: '!', spacing: Alone, span: bytes(12432..12433) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: output, span: bytes(12434..12440) }, Punct { char: ',', spacing: Alone, span: bytes(12440..12441) }, Literal { lit: "+{}: ", span: bytes(12442..12449) }, Punct { char: ',', spacing: Alone, span: bytes(12449..12450) }, Ident { sym: rhs, span: bytes(12451..12454) }, Punct { char: '.', spacing: Alone, span: bytes(12454..12455) }, Ident { sym: line_number, span: bytes(12455..12466) }], span: bytes(12433..12467) }, Punct { char: '.', spacing: Alone, span: bytes(12467..12468) }, Ident { sym: unwrap, span: bytes(12468..12474) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(12474..12476) }, Punct { char: ';', spacing: Alone, span: bytes(12476..12477) }, Ident { sym: for, span: bytes(12490..12493) }, Ident { sym: ch, span: bytes(12494..12496) }, Ident { sym: in, span: bytes(12497..12499) }, Punct { char: '&', spacing: Alone, span: bytes(12500..12501) }, Ident { sym: rhs, span: bytes(12501..12504) }, Punct { char: '.', spacing: Alone, span: bytes(12504..12505) }, Ident { sym: changes, span: bytes(12505..12512) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: output, span: bytes(12531..12537) }, Punct { char: '.', spacing: Alone, span: bytes(12537..12538) }, Ident { sym: push_str, span: bytes(12538..12546) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(12547..12548) }, Ident { sym: ch, span: bytes(12548..12550) }, Punct { char: '.', spacing: Alone, span: bytes(12550..12551) }, Ident { sym: content, span: bytes(12551..12558) }], span: bytes(12546..12559) }, Punct { char: ';', spacing: Alone, span: bytes(12559..12560) }], span: bytes(12513..12574) }, Ident { sym: output, span: bytes(12587..12593) }, Punct { char: '.', spacing: Alone, span: bytes(12593..12594) }, Ident { sym: push, span: bytes(12594..12598) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '\n', span: bytes(12599..12603) }], span: bytes(12598..12604) }, Punct { char: ';', spacing: Alone, span: bytes(12604..12605) }], span: bytes(12174..12615) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Some, span: bytes(12625..12629) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs, span: bytes(12630..12633) }], span: bytes(12629..12634) }, Punct { char: ',', spacing: Alone, span: bytes(12634..12635) }, Ident { sym: None, span: bytes(12636..12640) }], span: bytes(12624..12641) }, Punct { char: '=', spacing: Joint, span: bytes(12642..12643) }, Punct { char: '>', spacing: Alone, span: bytes(12643..12644) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: write, span: bytes(12687..12692) }, Punct { char: '!', spacing: Alone, span: bytes(12692..12693) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: output, span: bytes(12694..12700) }, Punct { char: ',', spacing: Alone, span: bytes(12700..12701) }, Literal { lit: "-{}: ", span: bytes(12702..12709) }, Punct { char: ',', spacing: Alone, span: bytes(12709..12710) }, Ident { sym: lhs, span: bytes(12711..12714) }, Punct { char: '.', spacing: Alone, span: bytes(12714..12715) }, Ident { sym: line_number, span: bytes(12715..12726) }], span: bytes(12693..12727) }, Punct { char: '.', spacing: Alone, span: bytes(12727..12728) }, Ident { sym: unwrap, span: bytes(12728..12734) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(12734..12736) }, Punct { char: ';', spacing: Alone, span: bytes(12736..12737) }, Ident { sym: for, span: bytes(12750..12753) }, Ident { sym: ch, span: bytes(12754..12756) }, Ident { sym: in, span: bytes(12757..12759) }, Punct { char: '&', spacing: Alone, span: bytes(12760..12761) }, Ident { sym: lhs, span: bytes(12761..12764) }, Punct { char: '.', spacing: Alone, span: bytes(12764..12765) }, Ident { sym: changes, span: bytes(12765..12772) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: output, span: bytes(12791..12797) }, Punct { char: '.', spacing: Alone, span: bytes(12797..12798) }, Ident { sym: push_str, span: bytes(12798..12806) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(12807..12808) }, Ident { sym: ch, span: bytes(12808..12810) }, Punct { char: '.', spacing: Alone, span: bytes(12810..12811) }, Ident { sym: content, span: bytes(12811..12818) }], span: bytes(12806..12819) }, Punct { char: ';', spacing: Alone, span: bytes(12819..12820) }], span: bytes(12773..12834) }, Ident { sym: output, span: bytes(12847..12853) }, Punct { char: '.', spacing: Alone, span: bytes(12853..12854) }, Ident { sym: push, span: bytes(12854..12858) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '\n', span: bytes(12859..12863) }], span: bytes(12858..12864) }, Punct { char: ';', spacing: Alone, span: bytes(12864..12865) }], span: bytes(12645..12875) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: None, span: bytes(12885..12889) }, Punct { char: ',', spacing: Alone, span: bytes(12889..12890) }, Ident { sym: Some, span: bytes(12891..12895) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rhs, span: bytes(12896..12899) }], span: bytes(12895..12900) }], span: bytes(12884..12901) }, Punct { char: '=', spacing: Joint, span: bytes(12902..12903) }, Punct { char: '>', spacing: Alone, span: bytes(12903..12904) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: write, span: bytes(12945..12950) }, Punct { char: '!', spacing: Alone, span: bytes(12950..12951) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: output, span: bytes(12952..12958) }, Punct { char: ',', spacing: Alone, span: bytes(12958..12959) }, Literal { lit: "+{}: ", span: bytes(12960..12967) }, Punct { char: ',', spacing: Alone, span: bytes(12967..12968) }, Ident { sym: rhs, span: bytes(12969..12972) }, Punct { char: '.', spacing: Alone, span: bytes(12972..12973) }, Ident { sym: line_number, span: bytes(12973..12984) }], span: bytes(12951..12985) }, Punct { char: '.', spacing: Alone, span: bytes(12985..12986) }, Ident { sym: unwrap, span: bytes(12986..12992) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(12992..12994) }, Punct { char: ';', spacing: Alone, span: bytes(12994..12995) }, Ident { sym: for, span: bytes(13008..13011) }, Ident { sym: ch, span: bytes(13012..13014) }, Ident { sym: in, span: bytes(13015..13017) }, Punct { char: '&', spacing: Alone, span: bytes(13018..13019) }, Ident { sym: rhs, span: bytes(13019..13022) }, Punct { char: '.', spacing: Alone, span: bytes(13022..13023) }, Ident { sym: changes, span: bytes(13023..13030) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: output, span: bytes(13049..13055) }, Punct { char: '.', spacing: Alone, span: bytes(13055..13056) }, Ident { sym: push_str, span: bytes(13056..13064) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '&', spacing: Alone, span: bytes(13065..13066) }, Ident { sym: ch, span: bytes(13066..13068) }, Punct { char: '.', spacing: Alone, span: bytes(13068..13069) }, Ident { sym: content, span: bytes(13069..13076) }], span: bytes(13064..13077) }, Punct { char: ';', spacing: Alone, span: bytes(13077..13078) }], span: bytes(13031..13092) }, Ident { sym: output, span: bytes(13105..13111) }, Punct { char: '.', spacing: Alone, span: bytes(13111..13112) }, Ident { sym: push, span: bytes(13112..13116) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: '\n', span: bytes(13117..13121) }], span: bytes(13116..13122) }, Punct { char: ';', spacing: Alone, span: bytes(13122..13123) }], span: bytes(12905..13133) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: None, span: bytes(13143..13147) }, Punct { char: ',', spacing: Alone, span: bytes(13147..13148) }, Ident { sym: None, span: bytes(13149..13153) }], span: bytes(13142..13154) }, Punct { char: '=', spacing: Joint, span: bytes(13155..13156) }, Punct { char: '>', spacing: Alone, span: bytes(13156..13157) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: output, span: bytes(13172..13178) }, Punct { char: '.', spacing: Alone, span: bytes(13178..13179) }, Ident { sym: push_str, span: bytes(13179..13187) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: " \n", span: bytes(13188..13193) }], span: bytes(13187..13194) }, Punct { char: ';', spacing: Alone, span: bytes(13194..13195) }], span: bytes(13158..13205) }], span: bytes(12138..13211) }, Ident { sym: output, span: bytes(13217..13223) }], span: bytes(12062..13225) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(13227..13229) }, string: "fn" }), name: Ident { sym: extract_chunk_text, span: bytes(13230..13248) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: side, span: bytes(13249..13253) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(13255..13256) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Value, span: bytes(13256..13261) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Option, span: bytes(13266..13272) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: String, span: bytes(13273..13279) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: side, span: bytes(13287..13291) }, Punct { char: '.', spacing: Alone, span: bytes(13291..13292) }, Ident { sym: get, span: bytes(13292..13295) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "changes", span: bytes(13296..13305) }], span: bytes(13295..13306) }, Punct { char: '.', spacing: Alone, span: bytes(13315..13316) }, Ident { sym: and_then, span: bytes(13316..13324) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13325..13326) }, Ident { sym: c, span: bytes(13326..13327) }, Punct { char: '|', spacing: Alone, span: bytes(13327..13328) }, Ident { sym: c, span: bytes(13329..13330) }, Punct { char: '.', spacing: Alone, span: bytes(13330..13331) }, Ident { sym: as_array, span: bytes(13331..13339) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(13339..13341) }], span: bytes(13324..13342) }, Punct { char: '.', spacing: Alone, span: bytes(13351..13352) }, Ident { sym: map, span: bytes(13352..13355) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13356..13357) }, Ident { sym: changes, span: bytes(13357..13364) }, Punct { char: '|', spacing: Alone, span: bytes(13364..13365) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: changes, span: bytes(13380..13387) }, Punct { char: '.', spacing: Alone, span: bytes(13404..13405) }, Ident { sym: iter, span: bytes(13405..13409) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(13409..13411) }, Punct { char: '.', spacing: Alone, span: bytes(13428..13429) }, Ident { sym: filter_map, span: bytes(13429..13439) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13440..13441) }, Ident { sym: change, span: bytes(13441..13447) }, Punct { char: '|', spacing: Alone, span: bytes(13447..13448) }, Ident { sym: change, span: bytes(13449..13455) }, Punct { char: '.', spacing: Alone, span: bytes(13455..13456) }, Ident { sym: get, span: bytes(13456..13459) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "content", span: bytes(13460..13469) }], span: bytes(13459..13470) }, Punct { char: '.', spacing: Alone, span: bytes(13470..13471) }, Ident { sym: and_then, span: bytes(13471..13479) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13480..13481) }, Ident { sym: c, span: bytes(13481..13482) }, Punct { char: '|', spacing: Alone, span: bytes(13482..13483) }, Ident { sym: c, span: bytes(13484..13485) }, Punct { char: '.', spacing: Alone, span: bytes(13485..13486) }, Ident { sym: as_str, span: bytes(13486..13492) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(13492..13494) }], span: bytes(13479..13495) }], span: bytes(13439..13496) }, Punct { char: '.', spacing: Alone, span: bytes(13513..13514) }, Ident { sym: collect, span: bytes(13514..13521) }, Punct { char: ':', spacing: Joint, span: bytes(13521..13522) }, Punct { char: ':', spacing: Joint, span: bytes(13522..13523) }, Punct { char: '<', spacing: Alone, span: bytes(13523..13524) }, Ident { sym: String, span: bytes(13524..13530) }, Punct { char: '>', spacing: Alone, span: bytes(13530..13531) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(13531..13533) }], span: bytes(13366..13543) }], span: bytes(13355..13544) }], span: bytes(13281..13546) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: None, visibility: None, const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(13548..13550) }, string: "fn" }), name: Ident { sym: extract_column_range, span: bytes(13551..13571) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: side, span: bytes(13572..13576) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(13578..13579) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Value, span: bytes(13579..13584) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: i64, span: bytes(13590..13593) }, Punct { char: ',', spacing: Alone, span: bytes(13593..13594) }, Ident { sym: i64, span: bytes(13595..13598) }], span: bytes(13589..13599) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(13606..13609) }, Ident { sym: changes, span: bytes(13610..13617) }, Punct { char: '=', spacing: Alone, span: bytes(13618..13619) }, Ident { sym: side, span: bytes(13620..13624) }, Punct { char: '.', spacing: Alone, span: bytes(13624..13625) }, Ident { sym: get, span: bytes(13625..13628) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "changes", span: bytes(13629..13638) }], span: bytes(13628..13639) }, Punct { char: '.', spacing: Alone, span: bytes(13639..13640) }, Ident { sym: and_then, span: bytes(13640..13648) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13649..13650) }, Ident { sym: c, span: bytes(13650..13651) }, Punct { char: '|', spacing: Alone, span: bytes(13651..13652) }, Ident { sym: c, span: bytes(13653..13654) }, Punct { char: '.', spacing: Alone, span: bytes(13654..13655) }, Ident { sym: as_array, span: bytes(13655..13663) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(13663..13665) }], span: bytes(13648..13666) }, Punct { char: ';', spacing: Alone, span: bytes(13666..13667) }, Ident { sym: let, span: bytes(13673..13676) }, Ident { sym: start, span: bytes(13677..13682) }, Punct { char: '=', spacing: Alone, span: bytes(13683..13684) }, Ident { sym: changes, span: bytes(13685..13692) }, Punct { char: '.', spacing: Alone, span: bytes(13701..13702) }, Ident { sym: and_then, span: bytes(13702..13710) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13711..13712) }, Ident { sym: arr, span: bytes(13712..13715) }, Punct { char: '|', spacing: Alone, span: bytes(13715..13716) }, Ident { sym: arr, span: bytes(13717..13720) }, Punct { char: '.', spacing: Alone, span: bytes(13720..13721) }, Ident { sym: first, span: bytes(13721..13726) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(13726..13728) }], span: bytes(13710..13729) }, Punct { char: '.', spacing: Alone, span: bytes(13738..13739) }, Ident { sym: and_then, span: bytes(13739..13747) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13748..13749) }, Ident { sym: first, span: bytes(13749..13754) }, Punct { char: '|', spacing: Alone, span: bytes(13754..13755) }, Ident { sym: first, span: bytes(13756..13761) }, Punct { char: '.', spacing: Alone, span: bytes(13761..13762) }, Ident { sym: get, span: bytes(13762..13765) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "start", span: bytes(13766..13773) }], span: bytes(13765..13774) }], span: bytes(13747..13775) }, Punct { char: '.', spacing: Alone, span: bytes(13784..13785) }, Ident { sym: and_then, span: bytes(13785..13793) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: serde_json, span: bytes(13794..13804) }, Punct { char: ':', spacing: Joint, span: bytes(13804..13805) }, Punct { char: ':', spacing: Alone, span: bytes(13805..13806) }, Ident { sym: Value, span: bytes(13806..13811) }, Punct { char: ':', spacing: Joint, span: bytes(13811..13812) }, Punct { char: ':', spacing: Alone, span: bytes(13812..13813) }, Ident { sym: as_i64, span: bytes(13813..13819) }], span: bytes(13793..13820) }, Punct { char: '.', spacing: Alone, span: bytes(13829..13830) }, Ident { sym: unwrap_or, span: bytes(13830..13839) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(13840..13841) }], span: bytes(13839..13842) }, Punct { char: ';', spacing: Alone, span: bytes(13842..13843) }, Ident { sym: let, span: bytes(13849..13852) }, Ident { sym: end, span: bytes(13853..13856) }, Punct { char: '=', spacing: Alone, span: bytes(13857..13858) }, Ident { sym: changes, span: bytes(13859..13866) }, Punct { char: '.', spacing: Alone, span: bytes(13875..13876) }, Ident { sym: and_then, span: bytes(13876..13884) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13885..13886) }, Ident { sym: arr, span: bytes(13886..13889) }, Punct { char: '|', spacing: Alone, span: bytes(13889..13890) }, Ident { sym: arr, span: bytes(13891..13894) }, Punct { char: '.', spacing: Alone, span: bytes(13894..13895) }, Ident { sym: last, span: bytes(13895..13899) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(13899..13901) }], span: bytes(13884..13902) }, Punct { char: '.', spacing: Alone, span: bytes(13911..13912) }, Ident { sym: and_then, span: bytes(13912..13920) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(13921..13922) }, Ident { sym: last, span: bytes(13922..13926) }, Punct { char: '|', spacing: Alone, span: bytes(13926..13927) }, Ident { sym: last, span: bytes(13928..13932) }, Punct { char: '.', spacing: Alone, span: bytes(13932..13933) }, Ident { sym: get, span: bytes(13933..13936) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "end", span: bytes(13937..13942) }], span: bytes(13936..13943) }], span: bytes(13920..13944) }, Punct { char: '.', spacing: Alone, span: bytes(13953..13954) }, Ident { sym: and_then, span: bytes(13954..13962) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: serde_json, span: bytes(13963..13973) }, Punct { char: ':', spacing: Joint, span: bytes(13973..13974) }, Punct { char: ':', spacing: Alone, span: bytes(13974..13975) }, Ident { sym: Value, span: bytes(13975..13980) }, Punct { char: ':', spacing: Joint, span: bytes(13980..13981) }, Punct { char: ':', spacing: Alone, span: bytes(13981..13982) }, Ident { sym: as_i64, span: bytes(13982..13988) }], span: bytes(13962..13989) }, Punct { char: '.', spacing: Alone, span: bytes(13998..13999) }, Ident { sym: unwrap_or, span: bytes(13999..14008) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(14009..14010) }], span: bytes(14008..14011) }, Punct { char: ';', spacing: Alone, span: bytes(14011..14012) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: start, span: bytes(14019..14024) }, Punct { char: ',', spacing: Alone, span: bytes(14024..14025) }, Ident { sym: end, span: bytes(14026..14029) }], span: bytes(14018..14030) }], span: bytes(13600..14032) }) })
[SYNCDOC DEBUG] Processing item type: Function
[SYNCDOC DEBUG] Processing item: Function(FnSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(14034..14115) }, Punct { char: '=', spacing: Alone, span: bytes(14034..14115) }, Literal { lit: " Extract the difftastic hunks as sections (same as sections in a markdown etc)", span: bytes(14034..14115) }], span: bytes(14034..14115) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(14116..14119) }, Punct { char: '=', spacing: Alone, span: bytes(14116..14119) }, Literal { lit: "", span: bytes(14116..14119) }], span: bytes(14116..14119) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(14120..14132) }, Punct { char: '=', spacing: Alone, span: bytes(14120..14132) }, Literal { lit: " # Errors", span: bytes(14120..14132) }], span: bytes(14120..14132) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(14133..14136) }, Punct { char: '=', spacing: Alone, span: bytes(14133..14136) }, Literal { lit: "", span: bytes(14133..14136) }], span: bytes(14133..14136) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(14137..14200) }, Punct { char: '=', spacing: Alone, span: bytes(14137..14200) }, Literal { lit: " Returns an error if the JSON file cannot be read from disk.", span: bytes(14137..14200) }], span: bytes(14137..14200) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(14201..14204) }, string: "pub" }))), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(14205..14207) }, string: "fn" }), name: Ident { sym: extract_difftastic_sections, span: bytes(14208..14235) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: json_path, span: bytes(14236..14245) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(14247..14248) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Path, span: bytes(14248..14252) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeFn { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: io, span: bytes(14257..14259) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(14259..14260) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(14260..14261) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Result, span: bytes(14261..14267) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::group::BraceGroup>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::group::BraceGroup>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Vec, span: bytes(14268..14271) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Section, span: bytes(14272..14279) })) }], third: Operator<'>'> })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, body: BraceGroup(Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(14288..14291) }, Ident { sym: content, span: bytes(14292..14299) }, Punct { char: '=', spacing: Alone, span: bytes(14300..14301) }, Ident { sym: fs, span: bytes(14302..14304) }, Punct { char: ':', spacing: Joint, span: bytes(14304..14305) }, Punct { char: ':', spacing: Alone, span: bytes(14305..14306) }, Ident { sym: read_to_string, span: bytes(14306..14320) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: json_path, span: bytes(14321..14330) }], span: bytes(14320..14331) }, Punct { char: '?', spacing: Joint, span: bytes(14331..14332) }, Punct { char: ';', spacing: Alone, span: bytes(14332..14333) }, Ident { sym: let, span: bytes(14338..14341) }, Ident { sym: lines, span: bytes(14342..14347) }, Punct { char: ':', spacing: Alone, span: bytes(14347..14348) }, Ident { sym: Vec, span: bytes(14349..14352) }, Punct { char: '<', spacing: Alone, span: bytes(14352..14353) }, Ident { sym: Value, span: bytes(14353..14358) }, Punct { char: '>', spacing: Alone, span: bytes(14358..14359) }, Punct { char: '=', spacing: Alone, span: bytes(14360..14361) }, Ident { sym: content, span: bytes(14362..14369) }, Punct { char: '.', spacing: Alone, span: bytes(14378..14379) }, Ident { sym: lines, span: bytes(14379..14384) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(14384..14386) }, Punct { char: '.', spacing: Alone, span: bytes(14395..14396) }, Ident { sym: filter_map, span: bytes(14396..14406) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(14407..14408) }, Ident { sym: line, span: bytes(14408..14412) }, Punct { char: '|', spacing: Alone, span: bytes(14412..14413) }, Ident { sym: serde_json, span: bytes(14414..14424) }, Punct { char: ':', spacing: Joint, span: bytes(14424..14425) }, Punct { char: ':', spacing: Alone, span: bytes(14425..14426) }, Ident { sym: from_str, span: bytes(14426..14434) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: line, span: bytes(14435..14439) }], span: bytes(14434..14440) }, Punct { char: '.', spacing: Alone, span: bytes(14440..14441) }, Ident { sym: ok, span: bytes(14441..14443) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(14443..14445) }], span: bytes(14406..14446) }, Punct { char: '.', spacing: Alone, span: bytes(14455..14456) }, Ident { sym: collect, span: bytes(14456..14463) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(14463..14465) }, Punct { char: ';', spacing: Alone, span: bytes(14465..14466) }, Ident { sym: let, span: bytes(14472..14475) }, Ident { sym: mut, span: bytes(14476..14479) }, Ident { sym: sections, span: bytes(14480..14488) }, Punct { char: '=', spacing: Alone, span: bytes(14489..14490) }, Ident { sym: Vec, span: bytes(14491..14494) }, Punct { char: ':', spacing: Joint, span: bytes(14494..14495) }, Punct { char: ':', spacing: Alone, span: bytes(14495..14496) }, Ident { sym: new, span: bytes(14496..14499) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(14499..14501) }, Punct { char: ';', spacing: Alone, span: bytes(14501..14502) }, Ident { sym: for, span: bytes(14508..14511) }, Ident { sym: value, span: bytes(14512..14517) }, Ident { sym: in, span: bytes(14518..14520) }, Ident { sym: lines, span: bytes(14521..14526) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(14537..14540) }, Ident { sym: file_path, span: bytes(14541..14550) }, Punct { char: '=', spacing: Alone, span: bytes(14551..14552) }, Ident { sym: value, span: bytes(14553..14558) }, Punct { char: '.', spacing: Alone, span: bytes(14571..14572) }, Ident { sym: get, span: bytes(14572..14575) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "path", span: bytes(14576..14582) }], span: bytes(14575..14583) }, Punct { char: '.', spacing: Alone, span: bytes(14596..14597) }, Ident { sym: and_then, span: bytes(14597..14605) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(14606..14607) }, Ident { sym: p, span: bytes(14607..14608) }, Punct { char: '|', spacing: Alone, span: bytes(14608..14609) }, Ident { sym: p, span: bytes(14610..14611) }, Punct { char: '.', spacing: Alone, span: bytes(14611..14612) }, Ident { sym: as_str, span: bytes(14612..14618) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(14618..14620) }], span: bytes(14605..14621) }, Punct { char: '.', spacing: Alone, span: bytes(14634..14635) }, Ident { sym: unwrap_or, span: bytes(14635..14644) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "unknown", span: bytes(14645..14654) }], span: bytes(14644..14655) }, Punct { char: ';', spacing: Alone, span: bytes(14655..14656) }, Ident { sym: if, span: bytes(14666..14668) }, Ident { sym: let, span: bytes(14669..14672) }, Ident { sym: Some, span: bytes(14673..14677) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: chunks, span: bytes(14678..14684) }], span: bytes(14677..14685) }, Punct { char: '=', spacing: Alone, span: bytes(14686..14687) }, Ident { sym: value, span: bytes(14688..14693) }, Punct { char: '.', spacing: Alone, span: bytes(14693..14694) }, Ident { sym: get, span: bytes(14694..14697) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "chunks", span: bytes(14698..14706) }], span: bytes(14697..14707) }, Punct { char: '.', spacing: Alone, span: bytes(14707..14708) }, Ident { sym: and_then, span: bytes(14708..14716) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(14717..14718) }, Ident { sym: c, span: bytes(14718..14719) }, Punct { char: '|', spacing: Alone, span: bytes(14719..14720) }, Ident { sym: c, span: bytes(14721..14722) }, Punct { char: '.', spacing: Alone, span: bytes(14722..14723) }, Ident { sym: as_array, span: bytes(14723..14731) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(14731..14733) }], span: bytes(14716..14734) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: for, span: bytes(14749..14752) }, Ident { sym: chunk_array, span: bytes(14753..14764) }, Ident { sym: in, span: bytes(14765..14767) }, Ident { sym: chunks, span: bytes(14768..14774) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: if, span: bytes(14793..14795) }, Ident { sym: let, span: bytes(14796..14799) }, Ident { sym: Some, span: bytes(14800..14804) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: chunk_list, span: bytes(14805..14815) }], span: bytes(14804..14816) }, Punct { char: '=', spacing: Alone, span: bytes(14817..14818) }, Ident { sym: chunk_array, span: bytes(14819..14830) }, Punct { char: '.', spacing: Alone, span: bytes(14830..14831) }, Ident { sym: as_array, span: bytes(14831..14839) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: bytes(14839..14841) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: for, span: bytes(14864..14867) }, Ident { sym: chunk, span: bytes(14868..14873) }, Ident { sym: in, span: bytes(14874..14876) }, Ident { sym: chunk_list, span: bytes(14877..14887) }, Group { delimiter: Brace, stream: TokenStream [Ident { sym: let, span: bytes(14914..14917) }, Ident { sym: lhs, span: bytes(14918..14921) }, Punct { char: '=', spacing: Alone, span: bytes(14922..14923) }, Ident { sym: chunk, span: bytes(14924..14929) }, Punct { char: '.', spacing: Alone, span: bytes(14929..14930) }, Ident { sym: get, span: bytes(14930..14933) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "lhs", span: bytes(14934..14939) }], span: bytes(14933..14940) }, Punct { char: ';', spacing: Alone, span: bytes(14940..14941) }, Ident { sym: let, span: bytes(14966..14969) }, Ident { sym: rhs, span: bytes(14970..14973) }, Punct { char: '=', spacing: Alone, span: bytes(14974..14975) }, Ident { sym: chunk, span: bytes(14976..14981) }, Punct { char: '.', spacing: Alone, span: bytes(14981..14982) }, Ident { sym: get, span: bytes(14982..14985) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "rhs", span: bytes(14986..14991) }], span: bytes(14985..14992) }, Punct { char: ';', spacing: Alone, span: bytes(14992..14993) }, Ident { sym: let, span: bytes(15019..15022) }, Ident { sym: chunk_type, span: bytes(15023..15033) }, Punct { char: '=', spacing: Alone, span: bytes(15034..15035) }, Ident { sym: match, span: bytes(15036..15041) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: lhs, span: bytes(15043..15046) }, Punct { char: ',', spacing: Alone, span: bytes(15046..15047) }, Ident { sym: rhs, span: bytes(15048..15051) }], span: bytes(15042..15052) }, Group { delimiter: Brace, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Some, span: bytes(15084..15088) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: _, span: bytes(15089..15090) }], span: bytes(15088..15091) }, Punct { char: ',', spacing: Alone, span: bytes(15091..15092) }, Ident { sym: None, span: bytes(15093..15097) }], span: bytes(15083..15098) }, Punct { char: '=', spacing: Joint, span: bytes(15099..15100) }, Punct { char: '>', spacing: Alone, span: bytes(15100..15101) }, Ident { sym: ChunkType, span: bytes(15102..15111) }, Punct { char: ':', spacing: Joint, span: bytes(15111..15112) }, Punct { char: ':', spacing: Alone, span: bytes(15112..15113) }, Ident { sym: Deleted, span: bytes(15113..15120) }, Punct { char: ',', spacing: Alone, span: bytes(15120..15121) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: None, span: bytes(15151..15155) }, Punct { char: ',', spacing: Alone, span: bytes(15155..15156) }, Ident { sym: Some, span: bytes(15157..15161) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: _, span: bytes(15162..15163) }], span: bytes(15161..15164) }], span: bytes(15150..15165) }, Punct { char: '=', spacing: Joint, span: bytes(15166..15167) }, Punct { char: '>', spacing: Alone, span: bytes(15167..15168) }, Ident { sym: ChunkType, span: bytes(15169..15178) }, Punct { char: ':', spacing: Joint, span: bytes(15178..15179) }, Punct { char: ':', spacing: Alone, span: bytes(15179..15180) }, Ident { sym: Added, span: bytes(15180..15185) }, Punct { char: ',', spacing: Alone, span: bytes(15185..15186) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Some, span: bytes(15216..15220) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: l, span: bytes(15221..15222) }], span: bytes(15220..15223) }, Punct { char: ',', spacing: Alone, span: bytes(15223..15224) }, Ident { sym: Some, span: bytes(15225..15229) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: r, span: bytes(15230..15231) }], span: bytes(15229..15232) }], span: bytes(15215..15233) }, Ident { sym: if, span: bytes(15234..15236) }, Ident { sym: l, span: bytes(15237..15238) }, Punct { char: '!', spacing: Joint, span: bytes(15239..15240) }, Punct { char: '=', spacing: Alone, span: bytes(15240..15241) }, Ident { sym: r, span: bytes(15242..15243) }, Punct { char: '=', spacing: Joint, span: bytes(15244..15245) }, Punct { char: '>', spacing: Alone, span: bytes(15245..15246) }, Ident { sym: ChunkType, span: bytes(15247..15256) }, Punct { char: ':', spacing: Joint, span: bytes(15256..15257) }, Punct { char: ':', spacing: Alone, span: bytes(15257..15258) }, Ident { sym: Modified, span: bytes(15258..15266) }, Punct { char: ',', spacing: Alone, span: bytes(15266..15267) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: Some, span: bytes(15297..15301) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: _, span: bytes(15302..15303) }], span: bytes(15301..15304) }, Punct { char: ',', spacing: Alone, span: bytes(15304..15305) }, Ident { sym: Some, span: bytes(15306..15310) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: _, span: bytes(15311..15312) }], span: bytes(15310..15313) }], span: bytes(15296..15314) }, Punct { char: '=', spacing: Joint, span: bytes(15315..15316) }, Punct { char: '>', spacing: Alone, span: bytes(15316..15317) }, Ident { sym: ChunkType, span: bytes(15318..15327) }, Punct { char: ':', spacing: Joint, span: bytes(15327..15328) }, Punct { char: ':', spacing: Alone, span: bytes(15328..15329) }, Ident { sym: Unchanged, span: bytes(15329..15338) }, Punct { char: ',', spacing: Alone, span: bytes(15338..15339) }, Ident { sym: _, span: bytes(15368..15369) }, Punct { char: '=', spacing: Joint, span: bytes(15370..15371) }, Punct { char: '>', spacing: Alone, span: bytes(15371..15372) }, Ident { sym: continue, span: bytes(15373..15381) }, Punct { char: ',', spacing: Alone, span: bytes(15381..15382) }], span: bytes(15053..15408) }, Punct { char: ';', spacing: Alone, span: bytes(15408..15409) }, Ident { sym: let, span: bytes(15435..15438) }, Ident { sym: line_num, span: bytes(15439..15447) }, Punct { char: '=', spacing: Alone, span: bytes(15448..15449) }, Ident { sym: lhs, span: bytes(15450..15453) }, Punct { char: '.', spacing: Alone, span: bytes(15482..15483) }, Ident { sym: or, span: bytes(15483..15485) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rhs, span: bytes(15486..15489) }], span: bytes(15485..15490) }, Punct { char: '.', spacing: Alone, span: bytes(15519..15520) }, Ident { sym: and_then, span: bytes(15520..15528) }, Group { delimiter: Parenthesis, stream: TokenStream [Punct { char: '|', spacing: Alone, span: bytes(15529..15530) }, Ident { sym: v, span: bytes(15530..15531) }, Punct { char: '|', spacing: Alone, span: bytes(15531..15532) }, Ident { sym: v, span: bytes(15533..15534) }, Punct { char: '.', spacing: Alone, span: bytes(15534..15535) }, Ident { sym: get, span: bytes(15535..15538) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "line_number", span: bytes(15539..15552) }], span: bytes(15538..15553) }], span: bytes(15528..15554) }, Punct { char: '.', spacing: Alone, span: bytes(15583..15584) }, Ident { sym: and_then, span: bytes(15584..15592) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: serde_json, span: bytes(15593..15603) }, Punct { char: ':', spacing: Joint, span: bytes(15603..15604) }, Punct { char: ':', spacing: Alone, span: bytes(15604..15605) }, Ident { sym: Value, span: bytes(15605..15610) }, Punct { char: ':', spacing: Joint, span: bytes(15610..15611) }, Punct { char: ':', spacing: Alone, span: bytes(15611..15612) }, Ident { sym: as_i64, span: bytes(15612..15618) }], span: bytes(15592..15619) }, Punct { char: '.', spacing: Alone, span: bytes(15648..15649) }, Ident { sym: unwrap_or, span: bytes(15649..15658) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(15659..15660) }], span: bytes(15658..15661) }, Punct { char: ';', spacing: Alone, span: bytes(15661..15662) }, Ident { sym: let, span: bytes(15688..15691) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: column_start, span: bytes(15693..15705) }, Punct { char: ',', spacing: Alone, span: bytes(15705..15706) }, Ident { sym: column_end, span: bytes(15707..15717) }], span: bytes(15692..15718) }, Punct { char: '=', spacing: Alone, span: bytes(15719..15720) }, Ident { sym: lhs, span: bytes(15749..15752) }, Punct { char: '.', spacing: Alone, span: bytes(15752..15753) }, Ident { sym: or, span: bytes(15753..15755) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: rhs, span: bytes(15756..15759) }], span: bytes(15755..15760) }, Punct { char: '.', spacing: Alone, span: bytes(15760..15761) }, Ident { sym: map_or, span: bytes(15761..15767) }, Group { delimiter: Parenthesis, stream: TokenStream [Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: 0, span: bytes(15769..15770) }, Punct { char: ',', spacing: Alone, span: bytes(15770..15771) }, Literal { lit: 0, span: bytes(15772..15773) }], span: bytes(15768..15774) }, Punct { char: ',', spacing: Alone, span: bytes(15774..15775) }, Ident { sym: extract_column_range, span: bytes(15776..15796) }], span: bytes(15767..15797) }, Punct { char: ';', spacing: Alone, span: bytes(15797..15798) }, Ident { sym: let, span: bytes(15824..15827) }, Ident { sym: title, span: bytes(15828..15833) }, Punct { char: '=', spacing: Alone, span: bytes(15834..15835) }, Ident { sym: format, span: bytes(15836..15842) }, Punct { char: '!', spacing: Alone, span: bytes(15842..15843) }, Group { delimiter: Parenthesis, stream: TokenStream [Literal { lit: "Chunk @@ {file_path}:{line_num} @@", span: bytes(15844..15880) }], span: bytes(15843..15881) }, Punct { char: ';', spacing: Alone, span: bytes(15881..15882) }, Ident { sym: let, span: bytes(15907..15910) }, Ident { sym: lhs_text, span: bytes(15911..15919) }, Punct { char: '=', spacing: Alone, span: bytes(15920..15921) }, Ident { sym: lhs, span: bytes(15922..15925) }, Punct { char: '.', spacing: Alone, span: bytes(15925..15926) }, Ident { sym: and_then, span: bytes(15926..15934) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: extract_chunk_text, span: bytes(15935..15953) }], span: bytes(15934..15954) }, Punct { char: ';', spacing: Alone, span: bytes(15954..15955) }, Ident { sym: let, span: bytes(15980..15983) }, Ident { sym: rhs_text, span: bytes(15984..15992) }, Punct { char: '=', spacing: Alone, span: bytes(15993..15994) }, Ident { sym: rhs, span: bytes(15995..15998) }, Punct { char: '.', spacing: Alone, span: bytes(15998..15999) }, Ident { sym: and_then, span: bytes(15999..16007) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: extract_chunk_text, span: bytes(16008..16026) }], span: bytes(16007..16027) }, Punct { char: ';', spacing: Alone, span: bytes(16027..16028) }, Ident { sym: sections, span: bytes(16054..16062) }, Punct { char: '.', spacing: Alone, span: bytes(16062..16063) }, Ident { sym: push, span: bytes(16063..16067) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: create_chunk_section, span: bytes(16068..16088) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: file_path, span: bytes(16118..16127) }, Punct { char: ',', spacing: Alone, span: bytes(16127..16128) }, Ident { sym: title, span: bytes(16157..16162) }, Punct { char: ',', spacing: Alone, span: bytes(16162..16163) }, Ident { sym: line_num, span: bytes(16192..16200) }, Punct { char: ',', spacing: Alone, span: bytes(16200..16201) }, Ident { sym: column_start, span: bytes(16230..16242) }, Punct { char: ',', spacing: Alone, span: bytes(16242..16243) }, Ident { sym: column_end, span: bytes(16272..16282) }, Punct { char: ',', spacing: Alone, span: bytes(16282..16283) }, Ident { sym: chunk_type, span: bytes(16312..16322) }, Punct { char: ',', spacing: Alone, span: bytes(16322..16323) }, Ident { sym: lhs_text, span: bytes(16352..16360) }, Punct { char: ',', spacing: Alone, span: bytes(16360..16361) }, Ident { sym: rhs_text, span: bytes(16390..16398) }, Punct { char: ',', spacing: Alone, span: bytes(16398..16399) }], span: bytes(16088..16425) }], span: bytes(16067..16426) }, Punct { char: ';', spacing: Alone, span: bytes(16426..16427) }], span: bytes(14888..16449) }], span: bytes(14842..16467) }], span: bytes(14775..16481) }], span: bytes(14735..16491) }], span: bytes(14527..16497) }, Ident { sym: Ok, span: bytes(16503..16505) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: sections, span: bytes(16506..16514) }], span: bytes(16505..16515) }], span: bytes(14282..16517) }) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: '#', spacing: Alone, span: bytes(16519..16520) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: cfg, span: bytes(16521..16524) }, Group { delimiter: Parenthesis, stream: TokenStream [Ident { sym: test, span: bytes(16525..16529) }], span: bytes(16524..16530) }], span: bytes(16520..16531) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: '#', spacing: Alone, span: bytes(16532..16533) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: path, span: bytes(16534..16538) }, Punct { char: '=', spacing: Alone, span: bytes(16539..16540) }, Literal { lit: "../tests/difftastic.rs", span: bytes(16541..16565) }], span: bytes(16533..16566) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(16567..16570) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: tests, span: bytes(16571..16576) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(16576..16577) })
[SYNCDOC DEBUG] 
=== REFORMAT START ===
[SYNCDOC DEBUG] Original length: 16579
[SYNCDOC DEBUG] Transformed length: 10675
[SYNCDOC DEBUG] Formatted original length: 16579
[SYNCDOC DEBUG] Formatted transformed length: 13691
[SYNCDOC DEBUG] 
--- Formatted Original ---
[SYNCDOC DEBUG] //! Difftastic format implementation for displaying structural diffs.
//!
//! This module provides support for parsing difftastic JSON output and
//! converting it into sections that can be navigated and edited in asterism.

use crate::formats::Format;
use crate::section::{ChunkType, Section};
use ratatui::{
    style::{Color, Style},
    text::{Line, Span},
};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::fmt::Write;
use std::path::Path;
use std::{fs, io};

/// Represents a file in difftastic output
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftFile {
    /// Programming language identified by difftastic for syntax highlighting.
    pub language: String,
    /// File path relative to the comparison root.
    pub path: String,
    /// Grouped diff hunks, each containing lines that changed together.
    #[serde(default)]
    pub chunks: Option<Vec<Vec<DifftLine>>>,
    /// Change classification: "unchanged", "changed", "created", or "deleted".
    pub status: String,
}

/// Represents a line in a diff chunk
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftLine {
    /// Left-hand (original) side of the comparison, absent for pure additions.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub lhs: Option<DifftSide>,
    /// Right-hand (modified) side of the comparison, absent for pure deletions.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub rhs: Option<DifftSide>,
}

/// Represents one side (left or right) of a diff line
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftSide {
    /// Original line position in the source file (1-indexed).
    pub line_number: u32,
    /// Structural changes within this line, ordered by column position.
    pub changes: Vec<DifftChange>,
}

/// Represents a change within a line
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftChange {
    /// Column offset where this change begins (0-indexed).
    pub start: u32,
    /// Column offset where this change ends (exclusive).
    pub end: u32,
    /// Text content of this change segment.
    pub content: String,
    /// Syntax category for rendering: "delimiter", "string", "keyword", "comment", "type", "normal"
    /// or "`tree_sitter_error`".
    pub highlight: String,
}

/// Difftastic format handler
pub struct DifftasticFormat;

impl Format for DifftasticFormat {
    fn file_extension(&self) -> &'static str {
        "diff"
    }

    fn language(&self) -> tree_sitter::Language {
        // Difftastic doesn't use tree-sitter parsing
        tree_sitter_md::LANGUAGE.into()
    }

    fn section_query(&self) -> &'static str {
        ""
    }

    fn title_query(&self) -> &'static str {
        ""
    }

    fn format_section_display(&self, level: usize, title: &str) -> Line<'static> {
        // Check if this is a hunk header with format: (N) @@ -X,Y +A,B @@
        if title.contains("@@") && title.starts_with('(') {
            if let Some(close_paren) = title.find(')') {
                let hunk_num = &title[..=close_paren];
                let rest = &title[close_paren + 1..].trim();

                // Determine color based on the diff header
                let color = Self::determine_hunk_color_from_header(rest);

                let spans = vec![
                    Span::styled(hunk_num.to_string(), Style::default().fg(color)),
                    Span::raw(" "),
                    Span::raw((*rest).to_string()),
                ];

                return Line::from(spans);
            }
        }

        // For file nodes or other sections
        let color = if level == 0 {
            Color::Cyan // Files
        } else {
            Color::LightYellow // Hunks
        };

        let spans = vec![
            Span::styled(" ", Style::default().fg(color)),
            Span::raw(title.to_string()),
        ];

        Line::from(spans)
    }
}

impl DifftasticFormat {
    /// Determine hunk color from the header string itself
    fn determine_hunk_color_from_header(header: &str) -> Color {
        // Parse @@ -X,Y +A,B @@
        if let Some(hunk_part) = header.strip_prefix("@@").and_then(|s| s.split("@@").next()) {
            let parts: Vec<&str> = hunk_part.split_whitespace().collect();
            if parts.len() >= 2 {
                let lhs = parts[0].trim_start_matches('-');
                let rhs = parts[1].trim_start_matches('+');

                let lhs_count = lhs
                    .split(',')
                    .nth(1)
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(1);
                let rhs_count = rhs
                    .split(',')
                    .nth(1)
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(1);

                // Parse the line numbers too to detect -0,0 +1,N
                let lhs_start = lhs
                    .split(',')
                    .next()
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(0);

                if lhs_start == 0 && lhs_count == 0 && rhs_count > 0 {
                    return Color::Green; // Addition
                } else if lhs_count > 0 && rhs_count == 0 && rhs.starts_with("0,") {
                    return Color::Red; // Deletion
                } else if lhs_count == 0 && rhs_count > 0 {
                    return Color::Green; // Pure addition
                } else if lhs_count > 0 && rhs_count == 0 {
                    return Color::Red; // Pure deletion
                }
            }
        }
        Color::LightYellow // Modification
    }
}

#[allow(clippy::too_many_arguments)]
fn create_chunk_section(
    file_path: &str,
    title: String,
    line_num: i64,
    column_start: i64,
    column_end: i64,
    chunk_type: ChunkType,
    lhs_text: Option<String>,
    rhs_text: Option<String>,
) -> Section {
    Section {
        title,
        level: 2,
        line_start: line_num,
        line_end: line_num + 1,
        column_start,
        column_end,
        byte_start: 0,
        byte_end: 0,
        file_path: file_path.to_string(),
        parent_index: None,
        children_indices: Vec::new(),
        section_content: None,
        chunk_type: Some(chunk_type),
        lhs_content: lhs_text,
        rhs_content: rhs_text,
    }
}

/// Parse difftastic JSON output into sections
///
/// Files become non-navigable containers, hunks become navigable sections.
///
/// # Errors
///
/// Returns an error if JSON parsing fails or if the format is invalid.
pub fn parse_difftastic_json(json_str: &str) -> io::Result<Vec<Section>> {
    let files: Vec<DifftFile> = if let Ok(files) = serde_json::from_str::<Vec<DifftFile>>(json_str)
    {
        // Array format: [{file1}, {file2}]
        files
    } else if json_str.trim().starts_with('[') {
        // Failed to parse as array, invalid format
        return Err(io::Error::new(
            io::ErrorKind::InvalidData,
            "Invalid JSON array format",
        ));
    } else {
        // Try parsing as newline-delimited JSON (NDJSON/JSON Lines)
        json_str
            .lines()
            .filter(|line| !line.trim().is_empty())
            .map(|line| {
                serde_json::from_str::<DifftFile>(line).map_err(|e| {
                    io::Error::new(
                        io::ErrorKind::InvalidData,
                        format!("Failed to parse JSON line: {e}"),
                    )
                })
            })
            .collect::<Result<Vec<DifftFile>, io::Error>>()?
    };

    let mut sections = Vec::new();
    let mut global_line = 0i64;

    for file in &files {
        // Skip unchanged files
        if file.status == "unchanged" {
            continue;
        }

        let file_path = &file.path;

        // Create hunk sections directly (no file section)
        if let Some(chunks) = &file.chunks {
            let mut hunk_counter = 0;
            for chunk in chunks {
                // Each element in the chunk array is a separate hunk
                for change in chunk {
                    hunk_counter += 1;

                    // Format this individual change as a proper git diff hunk
                    let hunk_title = format_hunk_header(change, hunk_counter);
                    let hunk_content = format_change_content(change);

                    let hunk_start_line = global_line;
                    let hunk_end_line =
                        global_line + i64::try_from(hunk_content.lines().count()).unwrap_or(0);

                    // Create section for this hunk
                    sections.push(Section {
                        title: hunk_title,
                        level: 1,
                        line_start: hunk_start_line,
                        line_end: hunk_end_line,
                        column_start: 0,
                        column_end: 0,
                        byte_start: 0,
                        byte_end: 0,
                        file_path: file_path.clone(),
                        parent_index: None,
                        children_indices: Vec::new(),
                        section_content: Some(vec![hunk_content]),
                        chunk_type: None,
                        lhs_content: None,
                        rhs_content: None,
                    });

                    global_line = hunk_end_line + 1;
                }
            }
        } else if file.status == "created" || file.status == "deleted" {
            // For files with no chunks (created/deleted without detailed hunks),
            // create a proper hunk header

            // Try to read the file to get line count
            let line_count = if file.status == "created" {
                // For created files, try to read from filesystem
                std::fs::read_to_string(file_path)
                    .ok()
                    .map_or(0, |content| content.lines().count())
            } else {
                0 // Deleted files
            };

            let hunk_title = if file.status == "created" {
                format!("(1) @@ -0,0 +1,{line_count} @@")
            } else {
                format!("(1) @@ -1,{line_count} +0,0 @@")
            };

            let hunk_content = if file.status == "created" {
                std::fs::read_to_string(file_path)
                    .ok()
                    .unwrap_or_else(|| format!("File was {}", file.status))
            } else {
                format!("File was {}", file.status)
            };

            sections.push(Section {
                title: hunk_title,
                level: 1,
                line_start: global_line,
                line_end: global_line + i64::try_from(line_count).unwrap_or(0),
                column_start: 0,
                column_end: 0,
                byte_start: 0,
                byte_end: 0,
                file_path: file_path.clone(),
                parent_index: None,
                children_indices: Vec::new(),
                section_content: Some(hunk_content.lines().map(String::from).collect()),
                chunk_type: None,
                lhs_content: None,
                rhs_content: None,
            });

            global_line += i64::try_from(line_count).unwrap_or(0) + 1;
        }
    }

    Ok(sections)
}

/// Format a change as a proper git diff hunk header
fn format_hunk_header(change: &DifftLine, hunk_num: usize) -> String {
    let (lhs_line, rhs_line) = match (&change.lhs, &change.rhs) {
        (Some(lhs), Some(rhs)) => (lhs.line_number, rhs.line_number),
        (Some(lhs), None) => (lhs.line_number, 0),
        (None, Some(rhs)) => (0, rhs.line_number),
        _ => (0, 0),
    };

    // Determine chunk size (for now, single line changes)
    let lhs_count = i32::from(change.lhs.is_some());
    let rhs_count = i32::from(change.rhs.is_some());

    format!("({hunk_num}) @@ -{lhs_line},{lhs_count} +{rhs_line},{rhs_count} @@")
}

/// Format a single change for display
fn format_change_content(change: &DifftLine) -> String {
    let mut output = String::new();

    match (&change.lhs, &change.rhs) {
        (Some(lhs), Some(rhs)) => {
            // Modified line - show both sides
            write!(output, "-{}: ", lhs.line_number).unwrap();
            for ch in &lhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');

            write!(output, "+{}: ", rhs.line_number).unwrap();
            for ch in &rhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (Some(lhs), None) => {
            // Deleted line
            write!(output, "-{}: ", lhs.line_number).unwrap();
            for ch in &lhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (None, Some(rhs)) => {
            // Added line
            write!(output, "+{}: ", rhs.line_number).unwrap();
            for ch in &rhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (None, None) => {
            output.push_str(" \n");
        }
    }

    output
}

fn extract_chunk_text(side: &Value) -> Option<String> {
    side.get("changes")
        .and_then(|c| c.as_array())
        .map(|changes| {
            changes
                .iter()
                .filter_map(|change| change.get("content").and_then(|c| c.as_str()))
                .collect::<String>()
        })
}

fn extract_column_range(side: &Value) -> (i64, i64) {
    let changes = side.get("changes").and_then(|c| c.as_array());

    let start = changes
        .and_then(|arr| arr.first())
        .and_then(|first| first.get("start"))
        .and_then(serde_json::Value::as_i64)
        .unwrap_or(0);

    let end = changes
        .and_then(|arr| arr.last())
        .and_then(|last| last.get("end"))
        .and_then(serde_json::Value::as_i64)
        .unwrap_or(0);

    (start, end)
}

/// Extract the difftastic hunks as sections (same as sections in a markdown etc)
///
/// # Errors
///
/// Returns an error if the JSON file cannot be read from disk.
pub fn extract_difftastic_sections(json_path: &Path) -> io::Result<Vec<Section>> {
    let content = fs::read_to_string(json_path)?;
    let lines: Vec<Value> = content
        .lines()
        .filter_map(|line| serde_json::from_str(line).ok())
        .collect();

    let mut sections = Vec::new();

    for value in lines {
        let file_path = value
            .get("path")
            .and_then(|p| p.as_str())
            .unwrap_or("unknown");

        if let Some(chunks) = value.get("chunks").and_then(|c| c.as_array()) {
            for chunk_array in chunks {
                if let Some(chunk_list) = chunk_array.as_array() {
                    for chunk in chunk_list {
                        let lhs = chunk.get("lhs");
                        let rhs = chunk.get("rhs");

                        let chunk_type = match (lhs, rhs) {
                            (Some(_), None) => ChunkType::Deleted,
                            (None, Some(_)) => ChunkType::Added,
                            (Some(l), Some(r)) if l != r => ChunkType::Modified,
                            (Some(_), Some(_)) => ChunkType::Unchanged,
                            _ => continue,
                        };

                        let line_num = lhs
                            .or(rhs)
                            .and_then(|v| v.get("line_number"))
                            .and_then(serde_json::Value::as_i64)
                            .unwrap_or(0);

                        let (column_start, column_end) =
                            lhs.or(rhs).map_or((0, 0), extract_column_range);

                        let title = format!("Chunk @@ {file_path}:{line_num} @@");
                        let lhs_text = lhs.and_then(extract_chunk_text);
                        let rhs_text = rhs.and_then(extract_chunk_text);

                        sections.push(create_chunk_section(
                            file_path,
                            title,
                            line_num,
                            column_start,
                            column_end,
                            chunk_type,
                            lhs_text,
                            rhs_text,
                        ));
                    }
                }
            }
        }
    }

    Ok(sections)
}

#[cfg(test)]
#[path = "../tests/difftastic.rs"]
mod tests;

[SYNCDOC DEBUG] 
--- Formatted Transformed ---
[SYNCDOC DEBUG] # ! [doc = syncdoc :: module_doc ! ()]
use crate::formats::Format;
use crate::section::{ChunkType, Section};
use ratatui::{
    style::{Color, Style},
    text::{Line, Span},
};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::fmt::Write;
use std::path::Path;
use std::{fs, io};
#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftFile {
    pub language: String,
    pub path: String,
    #[serde(default)]
    pub chunks: Option<Vec<Vec<DifftLine>>>,
    pub status: String,
}
#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftLine {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub lhs: Option<DifftSide>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub rhs: Option<DifftSide>,
}
#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftSide {
    pub line_number: u32,
    pub changes: Vec<DifftChange>,
}
#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftChange {
    pub start: u32,
    pub end: u32,
    pub content: String,
    pub highlight: String,
}
#[syncdoc::omnidoc]
pub struct DifftasticFormat;
#[syncdoc::omnidoc]
impl Format for DifftasticFormat {
    fn file_extension(&self) -> &'static str {
        "diff"
    }
    fn language(&self) -> tree_sitter::Language {
        tree_sitter_md::LANGUAGE.into()
    }
    fn section_query(&self) -> &'static str {
        ""
    }
    fn title_query(&self) -> &'static str {
        ""
    }
    fn format_section_display(&self, level: usize, title: &str) -> Line<'static> {
        if title.contains("@@") && title.starts_with('(') {
            if let Some(close_paren) = title.find(')') {
                let hunk_num = &title[..=close_paren];
                let rest = &title[close_paren + 1..].trim();
                let color = Self::determine_hunk_color_from_header(rest);
                let spans = vec![
                    Span::styled(hunk_num.to_string(), Style::default().fg(color)),
                    Span::raw(" "),
                    Span::raw((*rest).to_string()),
                ];
                return Line::from(spans);
            }
        }
        let color = if level == 0 {
            Color::Cyan
        } else {
            Color::LightYellow
        };
        let spans = vec![
            Span::styled(" ", Style::default().fg(color)),
            Span::raw(title.to_string()),
        ];
        Line::from(spans)
    }
}
#[syncdoc::omnidoc]
impl DifftasticFormat {
    fn determine_hunk_color_from_header(header: &str) -> Color {
        if let Some(hunk_part) = header.strip_prefix("@@").and_then(|s| s.split("@@").next()) {
            let parts: Vec<&str> = hunk_part.split_whitespace().collect();
            if parts.len() >= 2 {
                let lhs = parts[0].trim_start_matches('-');
                let rhs = parts[1].trim_start_matches('+');
                let lhs_count = lhs
                    .split(',')
                    .nth(1)
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(1);
                let rhs_count = rhs
                    .split(',')
                    .nth(1)
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(1);
                let lhs_start = lhs
                    .split(',')
                    .next()
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(0);
                if lhs_start == 0 && lhs_count == 0 && rhs_count > 0 {
                    return Color::Green;
                } else if lhs_count > 0 && rhs_count == 0 && rhs.starts_with("0,") {
                    return Color::Red;
                } else if lhs_count == 0 && rhs_count > 0 {
                    return Color::Green;
                } else if lhs_count > 0 && rhs_count == 0 {
                    return Color::Red;
                }
            }
        }
        Color::LightYellow
    }
}
#[syncdoc::omnidoc]
#[allow(clippy::too_many_arguments)]
fn create_chunk_section(
    file_path: &str,
    title: String,
    line_num: i64,
    column_start: i64,
    column_end: i64,
    chunk_type: ChunkType,
    lhs_text: Option<String>,
    rhs_text: Option<String>,
) -> Section {
    Section {
        title,
        level: 2,
        line_start: line_num,
        line_end: line_num + 1,
        column_start,
        column_end,
        byte_start: 0,
        byte_end: 0,
        file_path: file_path.to_string(),
        parent_index: None,
        children_indices: Vec::new(),
        section_content: None,
        chunk_type: Some(chunk_type),
        lhs_content: lhs_text,
        rhs_content: rhs_text,
    }
}
#[syncdoc::omnidoc]
pub fn parse_difftastic_json(json_str: &str) -> io::Result<Vec<Section>> {
    let files: Vec<DifftFile> = if let Ok(files) = serde_json::from_str::<Vec<DifftFile>>(json_str)
    {
        files
    } else if json_str.trim().starts_with('[') {
        return Err(io::Error::new(
            io::ErrorKind::InvalidData,
            "Invalid JSON array format",
        ));
    } else {
        json_str
            .lines()
            .filter(|line| !line.trim().is_empty())
            .map(|line| {
                serde_json::from_str::<DifftFile>(line).map_err(|e| {
                    io::Error::new(
                        io::ErrorKind::InvalidData,
                        format!("Failed to parse JSON line: {e}"),
                    )
                })
            })
            .collect::<Result<Vec<DifftFile>, io::Error>>()?
    };
    let mut sections = Vec::new();
    let mut global_line = 0i64;
    for file in &files {
        if file.status == "unchanged" {
            continue;
        }
        let file_path = &file.path;
        if let Some(chunks) = &file.chunks {
            let mut hunk_counter = 0;
            for chunk in chunks {
                for change in chunk {
                    hunk_counter += 1;
                    let hunk_title = format_hunk_header(change, hunk_counter);
                    let hunk_content = format_change_content(change);
                    let hunk_start_line = global_line;
                    let hunk_end_line =
                        global_line + i64::try_from(hunk_content.lines().count()).unwrap_or(0);
                    sections.push(Section {
                        title: hunk_title,
                        level: 1,
                        line_start: hunk_start_line,
                        line_end: hunk_end_line,
                        column_start: 0,
                        column_end: 0,
                        byte_start: 0,
                        byte_end: 0,
                        file_path: file_path.clone(),
                        parent_index: None,
                        children_indices: Vec::new(),
                        section_content: Some(vec![hunk_content]),
                        chunk_type: None,
                        lhs_content: None,
                        rhs_content: None,
                    });
                    global_line = hunk_end_line + 1;
                }
            }
        } else if file.status == "created" || file.status == "deleted" {
            let line_count = if file.status == "created" {
                std::fs::read_to_string(file_path)
                    .ok()
                    .map_or(0, |content| content.lines().count())
            } else {
                0
            };
            let hunk_title = if file.status == "created" {
                format!("(1) @@ -0,0 +1,{line_count} @@")
            } else {
                format!("(1) @@ -1,{line_count} +0,0 @@")
            };
            let hunk_content = if file.status == "created" {
                std::fs::read_to_string(file_path)
                    .ok()
                    .unwrap_or_else(|| format!("File was {}", file.status))
            } else {
                format!("File was {}", file.status)
            };
            sections.push(Section {
                title: hunk_title,
                level: 1,
                line_start: global_line,
                line_end: global_line + i64::try_from(line_count).unwrap_or(0),
                column_start: 0,
                column_end: 0,
                byte_start: 0,
                byte_end: 0,
                file_path: file_path.clone(),
                parent_index: None,
                children_indices: Vec::new(),
                section_content: Some(hunk_content.lines().map(String::from).collect()),
                chunk_type: None,
                lhs_content: None,
                rhs_content: None,
            });
            global_line += i64::try_from(line_count).unwrap_or(0) + 1;
        }
    }
    Ok(sections)
}
#[syncdoc::omnidoc]
fn format_hunk_header(change: &DifftLine, hunk_num: usize) -> String {
    let (lhs_line, rhs_line) = match (&change.lhs, &change.rhs) {
        (Some(lhs), Some(rhs)) => (lhs.line_number, rhs.line_number),
        (Some(lhs), None) => (lhs.line_number, 0),
        (None, Some(rhs)) => (0, rhs.line_number),
        _ => (0, 0),
    };
    let lhs_count = i32::from(change.lhs.is_some());
    let rhs_count = i32::from(change.rhs.is_some());
    format!("({hunk_num}) @@ -{lhs_line},{lhs_count} +{rhs_line},{rhs_count} @@")
}
#[syncdoc::omnidoc]
fn format_change_content(change: &DifftLine) -> String {
    let mut output = String::new();
    match (&change.lhs, &change.rhs) {
        (Some(lhs), Some(rhs)) => {
            write!(output, "-{}: ", lhs.line_number).unwrap();
            for ch in &lhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
            write!(output, "+{}: ", rhs.line_number).unwrap();
            for ch in &rhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (Some(lhs), None) => {
            write!(output, "-{}: ", lhs.line_number).unwrap();
            for ch in &lhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (None, Some(rhs)) => {
            write!(output, "+{}: ", rhs.line_number).unwrap();
            for ch in &rhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (None, None) => {
            output.push_str(" \n");
        }
    }
    output
}
#[syncdoc::omnidoc]
fn extract_chunk_text(side: &Value) -> Option<String> {
    side.get("changes")
        .and_then(|c| c.as_array())
        .map(|changes| {
            changes
                .iter()
                .filter_map(|change| change.get("content").and_then(|c| c.as_str()))
                .collect::<String>()
        })
}
#[syncdoc::omnidoc]
fn extract_column_range(side: &Value) -> (i64, i64) {
    let changes = side.get("changes").and_then(|c| c.as_array());
    let start = changes
        .and_then(|arr| arr.first())
        .and_then(|first| first.get("start"))
        .and_then(serde_json::Value::as_i64)
        .unwrap_or(0);
    let end = changes
        .and_then(|arr| arr.last())
        .and_then(|last| last.get("end"))
        .and_then(serde_json::Value::as_i64)
        .unwrap_or(0);
    (start, end)
}
#[syncdoc::omnidoc]
pub fn extract_difftastic_sections(json_path: &Path) -> io::Result<Vec<Section>> {
    let content = fs::read_to_string(json_path)?;
    let lines: Vec<Value> = content
        .lines()
        .filter_map(|line| serde_json::from_str(line).ok())
        .collect();
    let mut sections = Vec::new();
    for value in lines {
        let file_path = value
            .get("path")
            .and_then(|p| p.as_str())
            .unwrap_or("unknown");
        if let Some(chunks) = value.get("chunks").and_then(|c| c.as_array()) {
            for chunk_array in chunks {
                if let Some(chunk_list) = chunk_array.as_array() {
                    for chunk in chunk_list {
                        let lhs = chunk.get("lhs");
                        let rhs = chunk.get("rhs");
                        let chunk_type = match (lhs, rhs) {
                            (Some(_), None) => ChunkType::Deleted,
                            (None, Some(_)) => ChunkType::Added,
                            (Some(l), Some(r)) if l != r => ChunkType::Modified,
                            (Some(_), Some(_)) => ChunkType::Unchanged,
                            _ => continue,
                        };
                        let line_num = lhs
                            .or(rhs)
                            .and_then(|v| v.get("line_number"))
                            .and_then(serde_json::Value::as_i64)
                            .unwrap_or(0);
                        let (column_start, column_end) =
                            lhs.or(rhs).map_or((0, 0), extract_column_range);
                        let title = format!("Chunk @@ {file_path}:{line_num} @@");
                        let lhs_text = lhs.and_then(extract_chunk_text);
                        let rhs_text = rhs.and_then(extract_chunk_text);
                        sections.push(create_chunk_section(
                            file_path,
                            title,
                            line_num,
                            column_start,
                            column_end,
                            chunk_type,
                            lhs_text,
                            rhs_text,
                        ));
                    }
                }
            }
        }
    }
    Ok(sections)
}
#[cfg(test)]
#[path = "../tests/difftastic.rs"]
mod tests;

[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 489
[SYNCDOC DEBUG] After lines: 385
[SYNCDOC DEBUG] Hunks: 93
[SYNCDOC DEBUG] Hunk 0: before[0..5] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! Difftastic format implementation for displaying structural diffs."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module provides support for parsing difftastic JSON output and"
[SYNCDOC DEBUG]     [3]: "//! converting it into sections that can be navigated and edited in asterism."
[SYNCDOC DEBUG]     [4]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[16..18] -> after[12..13]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [16]: ""
[SYNCDOC DEBUG]     [17]: "/// Represents a file in difftastic output"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [12]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[20..21] -> after[15..15]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [20]: "    /// Programming language identified by difftastic for syntax highlighting."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 3: before[22..23] -> after[16..16]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [22]: "    /// File path relative to the comparison root."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 4: before[24..25] -> after[17..17]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [24]: "    /// Grouped diff hunks, each containing lines that changed together."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[27..28] -> after[19..19]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [27]: "    /// Change classification: \"unchanged\", \"changed\", \"created\", or \"deleted\"."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[30..32] -> after[21..22]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [30]: ""
[SYNCDOC DEBUG]     [31]: "/// Represents a line in a diff chunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [21]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 7: before[34..35] -> after[24..24]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [34]: "    /// Left-hand (original) side of the comparison, absent for pure additions."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 8: before[37..38] -> after[26..26]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [37]: "    /// Right-hand (modified) side of the comparison, absent for pure deletions."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 9: before[41..43] -> after[29..30]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [41]: ""
[SYNCDOC DEBUG]     [42]: "/// Represents one side (left or right) of a diff line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [29]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 10: before[45..46] -> after[32..32]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [45]: "    /// Original line position in the source file (1-indexed)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 11: before[47..48] -> after[33..33]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [47]: "    /// Structural changes within this line, ordered by column position."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 12: before[50..52] -> after[35..36]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [50]: ""
[SYNCDOC DEBUG]     [51]: "/// Represents a change within a line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [35]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 13: before[54..55] -> after[38..38]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [54]: "    /// Column offset where this change begins (0-indexed)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 14: before[56..57] -> after[39..39]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [56]: "    /// Column offset where this change ends (exclusive)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 15: before[58..59] -> after[40..40]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [58]: "    /// Text content of this change segment."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 16: before[60..62] -> after[41..41]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [60]: "    /// Syntax category for rendering: \"delimiter\", \"string\", \"keyword\", \"comment\", \"type\", \"normal\""
[SYNCDOC DEBUG]     [61]: "    /// or \"`tree_sitter_error`\"."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 17: before[64..66] -> after[43..44]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [64]: ""
[SYNCDOC DEBUG]     [65]: "/// Difftastic format handler"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [43]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 18: before[67..68] -> after[45..46]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [67]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [45]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 19: before[72..73] -> after[50..50]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [72]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 20: before[74..75] -> after[51..51]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [74]: "        // Difftastic doesn't use tree-sitter parsing"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 21: before[77..78] -> after[53..53]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [77]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 22: before[81..82] -> after[56..56]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [81]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 23: before[85..86] -> after[59..59]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [85]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 24: before[87..88] -> after[60..60]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [87]: "        // Check if this is a hunk header with format: (N) @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 25: before[92..94] -> after[64..64]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [92]: ""
[SYNCDOC DEBUG]     [93]: "                // Determine color based on the diff header"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 26: before[95..96] -> after[65..65]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [95]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 27: before[101..102] -> after[70..70]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [101]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 28: before[105..107] -> after[73..73]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [105]: ""
[SYNCDOC DEBUG]     [106]: "        // For file nodes or other sections"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 29: before[108..109] -> after[74..75]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [108]: "            Color::Cyan // Files"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [74]: "            Color::Cyan"
[SYNCDOC DEBUG] Hunk 30: before[110..111] -> after[76..77]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [110]: "            Color::LightYellow // Hunks"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [76]: "            Color::LightYellow"
[SYNCDOC DEBUG] Hunk 31: before[112..113] -> after[78..78]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [112]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 32: before[117..118] -> after[82..82]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [117]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 33: before[121..122] -> after[85..86]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [121]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [85]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 34: before[123..124] -> after[87..87]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [123]: "    /// Determine hunk color from the header string itself"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 35: before[125..126] -> after[88..88]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [125]: "        // Parse @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 36: before[131..132] -> after[93..93]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [131]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 37: before[142..144] -> after[103..103]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [142]: ""
[SYNCDOC DEBUG]     [143]: "                // Parse the line numbers too to detect -0,0 +1,N"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 38: before[149..150] -> after[108..108]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [149]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 39: before[151..152] -> after[109..110]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [151]: "                    return Color::Green; // Addition"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [109]: "                    return Color::Green;"
[SYNCDOC DEBUG] Hunk 40: before[153..154] -> after[111..112]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [153]: "                    return Color::Red; // Deletion"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [111]: "                    return Color::Red;"
[SYNCDOC DEBUG] Hunk 41: before[155..156] -> after[113..114]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [155]: "                    return Color::Green; // Pure addition"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [113]: "                    return Color::Green;"
[SYNCDOC DEBUG] Hunk 42: before[157..158] -> after[115..116]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [157]: "                    return Color::Red; // Pure deletion"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [115]: "                    return Color::Red;"
[SYNCDOC DEBUG] Hunk 43: before[161..162] -> after[119..120]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [161]: "        Color::LightYellow // Modification"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [119]: "        Color::LightYellow"
[SYNCDOC DEBUG] Hunk 44: before[164..165] -> after[122..123]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [164]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [122]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 45: before[194..202] -> after[152..153]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [194]: ""
[SYNCDOC DEBUG]     [195]: "/// Parse difftastic JSON output into sections"
[SYNCDOC DEBUG]     [196]: "///"
[SYNCDOC DEBUG]     [197]: "/// Files become non-navigable containers, hunks become navigable sections."
[SYNCDOC DEBUG]     [198]: "///"
[SYNCDOC DEBUG]     [199]: "/// # Errors"
[SYNCDOC DEBUG]     [200]: "///"
[SYNCDOC DEBUG]     [201]: "/// Returns an error if JSON parsing fails or if the format is invalid."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [152]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 46: before[205..206] -> after[156..156]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [205]: "        // Array format: [{file1}, {file2}]"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 47: before[208..209] -> after[158..158]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [208]: "        // Failed to parse as array, invalid format"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 48: before[214..215] -> after[163..163]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [214]: "        // Try parsing as newline-delimited JSON (NDJSON/JSON Lines)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 49: before[228..229] -> after[176..176]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [228]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 50: before[231..232] -> after[178..178]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [231]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 51: before[233..234] -> after[179..179]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [233]: "        // Skip unchanged files"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 52: before[237..238] -> after[182..182]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [237]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 53: before[239..241] -> after[183..183]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [239]: ""
[SYNCDOC DEBUG]     [240]: "        // Create hunk sections directly (no file section)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 54: before[244..245] -> after[186..186]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [244]: "                // Each element in the chunk array is a separate hunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 55: before[247..249] -> after[188..188]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [247]: ""
[SYNCDOC DEBUG]     [248]: "                    // Format this individual change as a proper git diff hunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 56: before[251..252] -> after[190..190]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [251]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 57: before[255..257] -> after[193..193]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [255]: ""
[SYNCDOC DEBUG]     [256]: "                    // Create section for this hunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 58: before[274..275] -> after[210..210]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [274]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 59: before[279..283] -> after[214..214]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [279]: "            // For files with no chunks (created/deleted without detailed hunks),"
[SYNCDOC DEBUG]     [280]: "            // create a proper hunk header"
[SYNCDOC DEBUG]     [281]: ""
[SYNCDOC DEBUG]     [282]: "            // Try to read the file to get line count"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 60: before[284..285] -> after[215..215]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [284]: "                // For created files, try to read from filesystem"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 61: before[289..290] -> after[219..220]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [289]: "                0 // Deleted files"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [219]: "                0"
[SYNCDOC DEBUG] Hunk 62: before[291..292] -> after[221..221]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [291]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 63: before[297..298] -> after[226..226]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [297]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 64: before[305..306] -> after[233..233]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [305]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 65: before[323..324] -> after[250..250]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [323]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 66: before[327..328] -> after[253..253]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [327]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 67: before[330..332] -> after[255..256]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [330]: ""
[SYNCDOC DEBUG]     [331]: "/// Format a change as a proper git diff hunk header"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [255]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 68: before[339..341] -> after[263..263]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [339]: ""
[SYNCDOC DEBUG]     [340]: "    // Determine chunk size (for now, single line changes)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 69: before[343..344] -> after[265..265]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [343]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 70: before[346..348] -> after[267..268]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [346]: ""
[SYNCDOC DEBUG]     [347]: "/// Format a single change for display"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [267]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 71: before[350..351] -> after[270..270]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [350]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 72: before[353..354] -> after[272..272]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [353]: "            // Modified line - show both sides"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 73: before[359..360] -> after[277..277]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [359]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 74: before[367..368] -> after[284..284]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [367]: "            // Deleted line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 75: before[375..376] -> after[291..291]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [375]: "            // Added line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 76: before[386..387] -> after[301..301]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [386]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 77: before[389..390] -> after[303..304]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [389]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [303]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 78: before[400..401] -> after[314..315]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [400]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [314]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 79: before[403..404] -> after[317..317]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [403]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 80: before[409..410] -> after[322..322]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [409]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 81: before[415..416] -> after[327..327]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [415]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 82: before[418..424] -> after[329..330]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [418]: ""
[SYNCDOC DEBUG]     [419]: "/// Extract the difftastic hunks as sections (same as sections in a markdown etc)"
[SYNCDOC DEBUG]     [420]: "///"
[SYNCDOC DEBUG]     [421]: "/// # Errors"
[SYNCDOC DEBUG]     [422]: "///"
[SYNCDOC DEBUG]     [423]: "/// Returns an error if the JSON file cannot be read from disk."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [329]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 83: before[430..431] -> after[336..336]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [430]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 84: before[432..433] -> after[337..337]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [432]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 85: before[438..439] -> after[342..342]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [438]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 86: before[445..446] -> after[348..348]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [445]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 87: before[453..454] -> after[355..355]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [453]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 88: before[459..460] -> after[360..360]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [459]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 89: before[462..463] -> after[362..362]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [462]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 90: before[466..467] -> after[365..365]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [466]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 91: before[482..483] -> after[380..380]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [482]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 92: before[485..486] -> after[382..382]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [485]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] DEBUG restore: Found 93 hunks
[SYNCDOC DEBUG]   Hunk 0: before[0..5] after[0..1]
[SYNCDOC DEBUG]   Hunk 1: before[16..18] after[12..13]
[SYNCDOC DEBUG]   Hunk 2: before[20..21] after[15..15]
[SYNCDOC DEBUG]   Hunk 3: before[22..23] after[16..16]
[SYNCDOC DEBUG]   Hunk 4: before[24..25] after[17..17]
[SYNCDOC DEBUG]   Hunk 5: before[27..28] after[19..19]
[SYNCDOC DEBUG]   Hunk 6: before[30..32] after[21..22]
[SYNCDOC DEBUG]   Hunk 7: before[34..35] after[24..24]
[SYNCDOC DEBUG]   Hunk 8: before[37..38] after[26..26]
[SYNCDOC DEBUG]   Hunk 9: before[41..43] after[29..30]
[SYNCDOC DEBUG]   Hunk 10: before[45..46] after[32..32]
[SYNCDOC DEBUG]   Hunk 11: before[47..48] after[33..33]
[SYNCDOC DEBUG]   Hunk 12: before[50..52] after[35..36]
[SYNCDOC DEBUG]   Hunk 13: before[54..55] after[38..38]
[SYNCDOC DEBUG]   Hunk 14: before[56..57] after[39..39]
[SYNCDOC DEBUG]   Hunk 15: before[58..59] after[40..40]
[SYNCDOC DEBUG]   Hunk 16: before[60..62] after[41..41]
[SYNCDOC DEBUG]   Hunk 17: before[64..66] after[43..44]
[SYNCDOC DEBUG]   Hunk 18: before[67..68] after[45..46]
[SYNCDOC DEBUG]   Hunk 19: before[72..73] after[50..50]
[SYNCDOC DEBUG]   Hunk 20: before[74..75] after[51..51]
[SYNCDOC DEBUG]   Hunk 21: before[77..78] after[53..53]
[SYNCDOC DEBUG]   Hunk 22: before[81..82] after[56..56]
[SYNCDOC DEBUG]   Hunk 23: before[85..86] after[59..59]
[SYNCDOC DEBUG]   Hunk 24: before[87..88] after[60..60]
[SYNCDOC DEBUG]   Hunk 25: before[92..94] after[64..64]
[SYNCDOC DEBUG]   Hunk 26: before[95..96] after[65..65]
[SYNCDOC DEBUG]   Hunk 27: before[101..102] after[70..70]
[SYNCDOC DEBUG]   Hunk 28: before[105..107] after[73..73]
[SYNCDOC DEBUG]   Hunk 29: before[108..109] after[74..75]
[SYNCDOC DEBUG]   Hunk 30: before[110..111] after[76..77]
[SYNCDOC DEBUG]   Hunk 31: before[112..113] after[78..78]
[SYNCDOC DEBUG]   Hunk 32: before[117..118] after[82..82]
[SYNCDOC DEBUG]   Hunk 33: before[121..122] after[85..86]
[SYNCDOC DEBUG]   Hunk 34: before[123..124] after[87..87]
[SYNCDOC DEBUG]   Hunk 35: before[125..126] after[88..88]
[SYNCDOC DEBUG]   Hunk 36: before[131..132] after[93..93]
[SYNCDOC DEBUG]   Hunk 37: before[142..144] after[103..103]
[SYNCDOC DEBUG]   Hunk 38: before[149..150] after[108..108]
[SYNCDOC DEBUG]   Hunk 39: before[151..152] after[109..110]
[SYNCDOC DEBUG]   Hunk 40: before[153..154] after[111..112]
[SYNCDOC DEBUG]   Hunk 41: before[155..156] after[113..114]
[SYNCDOC DEBUG]   Hunk 42: before[157..158] after[115..116]
[SYNCDOC DEBUG]   Hunk 43: before[161..162] after[119..120]
[SYNCDOC DEBUG]   Hunk 44: before[164..165] after[122..123]
[SYNCDOC DEBUG]   Hunk 45: before[194..202] after[152..153]
[SYNCDOC DEBUG]   Hunk 46: before[205..206] after[156..156]
[SYNCDOC DEBUG]   Hunk 47: before[208..209] after[158..158]
[SYNCDOC DEBUG]   Hunk 48: before[214..215] after[163..163]
[SYNCDOC DEBUG]   Hunk 49: before[228..229] after[176..176]
[SYNCDOC DEBUG]   Hunk 50: before[231..232] after[178..178]
[SYNCDOC DEBUG]   Hunk 51: before[233..234] after[179..179]
[SYNCDOC DEBUG]   Hunk 52: before[237..238] after[182..182]
[SYNCDOC DEBUG]   Hunk 53: before[239..241] after[183..183]
[SYNCDOC DEBUG]   Hunk 54: before[244..245] after[186..186]
[SYNCDOC DEBUG]   Hunk 55: before[247..249] after[188..188]
[SYNCDOC DEBUG]   Hunk 56: before[251..252] after[190..190]
[SYNCDOC DEBUG]   Hunk 57: before[255..257] after[193..193]
[SYNCDOC DEBUG]   Hunk 58: before[274..275] after[210..210]
[SYNCDOC DEBUG]   Hunk 59: before[279..283] after[214..214]
[SYNCDOC DEBUG]   Hunk 60: before[284..285] after[215..215]
[SYNCDOC DEBUG]   Hunk 61: before[289..290] after[219..220]
[SYNCDOC DEBUG]   Hunk 62: before[291..292] after[221..221]
[SYNCDOC DEBUG]   Hunk 63: before[297..298] after[226..226]
[SYNCDOC DEBUG]   Hunk 64: before[305..306] after[233..233]
[SYNCDOC DEBUG]   Hunk 65: before[323..324] after[250..250]
[SYNCDOC DEBUG]   Hunk 66: before[327..328] after[253..253]
[SYNCDOC DEBUG]   Hunk 67: before[330..332] after[255..256]
[SYNCDOC DEBUG]   Hunk 68: before[339..341] after[263..263]
[SYNCDOC DEBUG]   Hunk 69: before[343..344] after[265..265]
[SYNCDOC DEBUG]   Hunk 70: before[346..348] after[267..268]
[SYNCDOC DEBUG]   Hunk 71: before[350..351] after[270..270]
[SYNCDOC DEBUG]   Hunk 72: before[353..354] after[272..272]
[SYNCDOC DEBUG]   Hunk 73: before[359..360] after[277..277]
[SYNCDOC DEBUG]   Hunk 74: before[367..368] after[284..284]
[SYNCDOC DEBUG]   Hunk 75: before[375..376] after[291..291]
[SYNCDOC DEBUG]   Hunk 76: before[386..387] after[301..301]
[SYNCDOC DEBUG]   Hunk 77: before[389..390] after[303..304]
[SYNCDOC DEBUG]   Hunk 78: before[400..401] after[314..315]
[SYNCDOC DEBUG]   Hunk 79: before[403..404] after[317..317]
[SYNCDOC DEBUG]   Hunk 80: before[409..410] after[322..322]
[SYNCDOC DEBUG]   Hunk 81: before[415..416] after[327..327]
[SYNCDOC DEBUG]   Hunk 82: before[418..424] after[329..330]
[SYNCDOC DEBUG]   Hunk 83: before[430..431] after[336..336]
[SYNCDOC DEBUG]   Hunk 84: before[432..433] after[337..337]
[SYNCDOC DEBUG]   Hunk 85: before[438..439] after[342..342]
[SYNCDOC DEBUG]   Hunk 86: before[445..446] after[348..348]
[SYNCDOC DEBUG]   Hunk 87: before[453..454] after[355..355]
[SYNCDOC DEBUG]   Hunk 88: before[459..460] after[360..360]
[SYNCDOC DEBUG]   Hunk 89: before[462..463] after[362..362]
[SYNCDOC DEBUG]   Hunk 90: before[466..467] after[365..365]
[SYNCDOC DEBUG]   Hunk 91: before[482..483] after[380..380]
[SYNCDOC DEBUG]   Hunk 92: before[485..486] after[382..382]
[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 489
[SYNCDOC DEBUG] After lines: 385
[SYNCDOC DEBUG] Hunks: 93
[SYNCDOC DEBUG] Hunk 0: before[0..5] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! Difftastic format implementation for displaying structural diffs."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module provides support for parsing difftastic JSON output and"
[SYNCDOC DEBUG]     [3]: "//! converting it into sections that can be navigated and edited in asterism."
[SYNCDOC DEBUG]     [4]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[16..18] -> after[12..13]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [16]: ""
[SYNCDOC DEBUG]     [17]: "/// Represents a file in difftastic output"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [12]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[20..21] -> after[15..15]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [20]: "    /// Programming language identified by difftastic for syntax highlighting."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 3: before[22..23] -> after[16..16]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [22]: "    /// File path relative to the comparison root."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 4: before[24..25] -> after[17..17]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [24]: "    /// Grouped diff hunks, each containing lines that changed together."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[27..28] -> after[19..19]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [27]: "    /// Change classification: \"unchanged\", \"changed\", \"created\", or \"deleted\"."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[30..32] -> after[21..22]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [30]: ""
[SYNCDOC DEBUG]     [31]: "/// Represents a line in a diff chunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [21]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 7: before[34..35] -> after[24..24]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [34]: "    /// Left-hand (original) side of the comparison, absent for pure additions."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 8: before[37..38] -> after[26..26]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [37]: "    /// Right-hand (modified) side of the comparison, absent for pure deletions."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 9: before[41..43] -> after[29..30]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [41]: ""
[SYNCDOC DEBUG]     [42]: "/// Represents one side (left or right) of a diff line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [29]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 10: before[45..46] -> after[32..32]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [45]: "    /// Original line position in the source file (1-indexed)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 11: before[47..48] -> after[33..33]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [47]: "    /// Structural changes within this line, ordered by column position."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 12: before[50..52] -> after[35..36]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [50]: ""
[SYNCDOC DEBUG]     [51]: "/// Represents a change within a line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [35]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 13: before[54..55] -> after[38..38]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [54]: "    /// Column offset where this change begins (0-indexed)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 14: before[56..57] -> after[39..39]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [56]: "    /// Column offset where this change ends (exclusive)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 15: before[58..59] -> after[40..40]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [58]: "    /// Text content of this change segment."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 16: before[60..62] -> after[41..41]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [60]: "    /// Syntax category for rendering: \"delimiter\", \"string\", \"keyword\", \"comment\", \"type\", \"normal\""
[SYNCDOC DEBUG]     [61]: "    /// or \"`tree_sitter_error`\"."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 17: before[64..66] -> after[43..44]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [64]: ""
[SYNCDOC DEBUG]     [65]: "/// Difftastic format handler"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [43]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 18: before[67..68] -> after[45..46]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [67]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [45]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 19: before[72..73] -> after[50..50]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [72]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 20: before[74..75] -> after[51..51]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [74]: "        // Difftastic doesn't use tree-sitter parsing"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 21: before[77..78] -> after[53..53]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [77]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 22: before[81..82] -> after[56..56]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [81]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 23: before[85..86] -> after[59..59]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [85]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 24: before[87..88] -> after[60..60]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [87]: "        // Check if this is a hunk header with format: (N) @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 25: before[92..94] -> after[64..64]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [92]: ""
[SYNCDOC DEBUG]     [93]: "                // Determine color based on the diff header"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 26: before[95..96] -> after[65..65]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [95]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 27: before[101..102] -> after[70..70]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [101]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 28: before[105..107] -> after[73..73]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [105]: ""
[SYNCDOC DEBUG]     [106]: "        // For file nodes or other sections"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 29: before[108..109] -> after[74..75]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [108]: "            Color::Cyan // Files"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [74]: "            Color::Cyan"
[SYNCDOC DEBUG] Hunk 30: before[110..111] -> after[76..77]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [110]: "            Color::LightYellow // Hunks"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [76]: "            Color::LightYellow"
[SYNCDOC DEBUG] Hunk 31: before[112..113] -> after[78..78]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [112]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 32: before[117..118] -> after[82..82]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [117]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 33: before[121..122] -> after[85..86]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [121]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [85]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 34: before[123..124] -> after[87..87]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [123]: "    /// Determine hunk color from the header string itself"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 35: before[125..126] -> after[88..88]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [125]: "        // Parse @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 36: before[131..132] -> after[93..93]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [131]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 37: before[142..144] -> after[103..103]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [142]: ""
[SYNCDOC DEBUG]     [143]: "                // Parse the line numbers too to detect -0,0 +1,N"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 38: before[149..150] -> after[108..108]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [149]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 39: before[151..152] -> after[109..110]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [151]: "                    return Color::Green; // Addition"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [109]: "                    return Color::Green;"
[SYNCDOC DEBUG] Hunk 40: before[153..154] -> after[111..112]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [153]: "                    return Color::Red; // Deletion"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [111]: "                    return Color::Red;"
[SYNCDOC DEBUG] Hunk 41: before[155..156] -> after[113..114]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [155]: "                    return Color::Green; // Pure addition"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [113]: "                    return Color::Green;"
[SYNCDOC DEBUG] Hunk 42: before[157..158] -> after[115..116]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [157]: "                    return Color::Red; // Pure deletion"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [115]: "                    return Color::Red;"
[SYNCDOC DEBUG] Hunk 43: before[161..162] -> after[119..120]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [161]: "        Color::LightYellow // Modification"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [119]: "        Color::LightYellow"
[SYNCDOC DEBUG] Hunk 44: before[164..165] -> after[122..123]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [164]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [122]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 45: before[194..202] -> after[152..153]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [194]: ""
[SYNCDOC DEBUG]     [195]: "/// Parse difftastic JSON output into sections"
[SYNCDOC DEBUG]     [196]: "///"
[SYNCDOC DEBUG]     [197]: "/// Files become non-navigable containers, hunks become navigable sections."
[SYNCDOC DEBUG]     [198]: "///"
[SYNCDOC DEBUG]     [199]: "/// # Errors"
[SYNCDOC DEBUG]     [200]: "///"
[SYNCDOC DEBUG]     [201]: "/// Returns an error if JSON parsing fails or if the format is invalid."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [152]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 46: before[205..206] -> after[156..156]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [205]: "        // Array format: [{file1}, {file2}]"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 47: before[208..209] -> after[158..158]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [208]: "        // Failed to parse as array, invalid format"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 48: before[214..215] -> after[163..163]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [214]: "        // Try parsing as newline-delimited JSON (NDJSON/JSON Lines)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 49: before[228..229] -> after[176..176]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [228]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 50: before[231..232] -> after[178..178]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [231]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 51: before[233..234] -> after[179..179]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [233]: "        // Skip unchanged files"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 52: before[237..238] -> after[182..182]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [237]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 53: before[239..241] -> after[183..183]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [239]: ""
[SYNCDOC DEBUG]     [240]: "        // Create hunk sections directly (no file section)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 54: before[244..245] -> after[186..186]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [244]: "                // Each element in the chunk array is a separate hunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 55: before[247..249] -> after[188..188]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [247]: ""
[SYNCDOC DEBUG]     [248]: "                    // Format this individual change as a proper git diff hunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 56: before[251..252] -> after[190..190]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [251]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 57: before[255..257] -> after[193..193]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [255]: ""
[SYNCDOC DEBUG]     [256]: "                    // Create section for this hunk"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 58: before[274..275] -> after[210..210]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [274]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 59: before[279..283] -> after[214..214]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [279]: "            // For files with no chunks (created/deleted without detailed hunks),"
[SYNCDOC DEBUG]     [280]: "            // create a proper hunk header"
[SYNCDOC DEBUG]     [281]: ""
[SYNCDOC DEBUG]     [282]: "            // Try to read the file to get line count"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 60: before[284..285] -> after[215..215]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [284]: "                // For created files, try to read from filesystem"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 61: before[289..290] -> after[219..220]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [289]: "                0 // Deleted files"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [219]: "                0"
[SYNCDOC DEBUG] Hunk 62: before[291..292] -> after[221..221]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [291]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 63: before[297..298] -> after[226..226]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [297]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 64: before[305..306] -> after[233..233]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [305]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 65: before[323..324] -> after[250..250]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [323]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 66: before[327..328] -> after[253..253]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [327]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 67: before[330..332] -> after[255..256]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [330]: ""
[SYNCDOC DEBUG]     [331]: "/// Format a change as a proper git diff hunk header"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [255]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 68: before[339..341] -> after[263..263]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [339]: ""
[SYNCDOC DEBUG]     [340]: "    // Determine chunk size (for now, single line changes)"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 69: before[343..344] -> after[265..265]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [343]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 70: before[346..348] -> after[267..268]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [346]: ""
[SYNCDOC DEBUG]     [347]: "/// Format a single change for display"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [267]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 71: before[350..351] -> after[270..270]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [350]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 72: before[353..354] -> after[272..272]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [353]: "            // Modified line - show both sides"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 73: before[359..360] -> after[277..277]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [359]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 74: before[367..368] -> after[284..284]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [367]: "            // Deleted line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 75: before[375..376] -> after[291..291]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [375]: "            // Added line"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 76: before[386..387] -> after[301..301]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [386]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 77: before[389..390] -> after[303..304]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [389]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [303]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 78: before[400..401] -> after[314..315]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [400]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [314]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 79: before[403..404] -> after[317..317]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [403]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 80: before[409..410] -> after[322..322]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [409]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 81: before[415..416] -> after[327..327]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [415]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 82: before[418..424] -> after[329..330]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [418]: ""
[SYNCDOC DEBUG]     [419]: "/// Extract the difftastic hunks as sections (same as sections in a markdown etc)"
[SYNCDOC DEBUG]     [420]: "///"
[SYNCDOC DEBUG]     [421]: "/// # Errors"
[SYNCDOC DEBUG]     [422]: "///"
[SYNCDOC DEBUG]     [423]: "/// Returns an error if the JSON file cannot be read from disk."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [329]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 83: before[430..431] -> after[336..336]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [430]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 84: before[432..433] -> after[337..337]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [432]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 85: before[438..439] -> after[342..342]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [438]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 86: before[445..446] -> after[348..348]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [445]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 87: before[453..454] -> after[355..355]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [453]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 88: before[459..460] -> after[360..360]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [459]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 89: before[462..463] -> after[362..362]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [462]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 90: before[466..467] -> after[365..365]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [466]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 91: before[482..483] -> after[380..380]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [482]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 92: before[485..486] -> after[382..382]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [485]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 0..5 (adds 1 lines, removes 5 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 16..18 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 20..21 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 22..23 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 24..25 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 27..28 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 30..32 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 34..35 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 37..38 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 41..43 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 45..46 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 47..48 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 50..52 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 54..55 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 56..57 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 58..59 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 60..62 (adds 0 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 64..66 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 67..68 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 72..73
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 74..75
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 77..78
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 81..82
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 85..86
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 87..88
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 92..94
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 95..96
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 101..102
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 105..107
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 108..109
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 110..111
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 112..113
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 117..118
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 121..122 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 123..124 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 125..126
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 131..132
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 142..144
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 149..150
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 151..152
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 153..154
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 155..156
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 157..158
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 161..162
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 164..165 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 194..202 (adds 1 lines, removes 8 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 205..206
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 208..209
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 214..215
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 228..229
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 231..232
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 233..234
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 237..238
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 239..241
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 244..245
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 247..249
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 251..252
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 255..257
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 274..275
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 279..283
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 284..285
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 289..290
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 291..292
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 297..298
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 305..306
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 323..324
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 327..328
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 330..332 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 339..341
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 343..344
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 346..348 (adds 1 lines, removes 2 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 350..351
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 353..354
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 359..360
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 367..368
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 375..376
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 386..387
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 389..390 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 400..401 (adds 1 lines, removes 1 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 403..404
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 409..410
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 415..416
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 418..424 (adds 1 lines, removes 6 lines)
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 430..431
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 432..433
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 438..439
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 445..446
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 453..454
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 459..460
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 462..463
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 466..467
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 482..483
[SYNCDOC DEBUG] Skipping irrelevant hunk at lines 485..486
[SYNCDOC DEBUG] Original != Result: true
[SYNCDOC DEBUG] 
=== BOOKEND DEBUG START ===
[SYNCDOC DEBUG] Input code length: 15053
[SYNCDOC DEBUG] 
Line 0: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       -> Starts with #!
[SYNCDOC DEBUG]       -> Checking trigger "syncdoc::module_doc!": true
[SYNCDOC DEBUG]       -> Has trigger: true
[SYNCDOC DEBUG]   -> NEEDS BOOKENDING
[SYNCDOC DEBUG]     reformat_line for: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     extract_bookend_content:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       Found #![ at position: 0
[SYNCDOC DEBUG]       Found ] at position: 29
[SYNCDOC DEBUG]       Extracted content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Got content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Created bookended expr: "const _: i32 = { doc=syncdoc::module_doc!() };"
[SYNCDOC DEBUG]     Rustfmt output: "const _: i32 = { doc = syncdoc::module_doc!() };\n"
[SYNCDOC DEBUG]     Stripped bookends: "doc = syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Final result: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG]   -> Reformatted to: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG] 
Line 1: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 2: "use crate::formats::Format;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use crate::formats::Format;"
[SYNCDOC DEBUG]       no_spaces: "usecrate::formats::Format;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 3: "use crate::section::{ChunkType, Section};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use crate::section::{ChunkType, Section};"
[SYNCDOC DEBUG]       no_spaces: "usecrate::section::{ChunkType,Section};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 4: "use ratatui::{"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use ratatui::{"
[SYNCDOC DEBUG]       no_spaces: "useratatui::{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 5: "    style::{Color, Style},"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "style::{Color, Style},"
[SYNCDOC DEBUG]       no_spaces: "style::{Color,Style},"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 6: "    text::{Line, Span},"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "text::{Line, Span},"
[SYNCDOC DEBUG]       no_spaces: "text::{Line,Span},"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 7: "};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 8: "use serde::{Deserialize, Serialize};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use serde::{Deserialize, Serialize};"
[SYNCDOC DEBUG]       no_spaces: "useserde::{Deserialize,Serialize};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 9: "use serde_json::Value;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use serde_json::Value;"
[SYNCDOC DEBUG]       no_spaces: "useserde_json::Value;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 10: "use std::fmt::Write;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::fmt::Write;"
[SYNCDOC DEBUG]       no_spaces: "usestd::fmt::Write;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 11: "use std::path::Path;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::path::Path;"
[SYNCDOC DEBUG]       no_spaces: "usestd::path::Path;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 12: "use std::{fs, io};"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "use std::{fs, io};"
[SYNCDOC DEBUG]       no_spaces: "usestd::{fs,io};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 13: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 14: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 15: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]       no_spaces: "#[derive(Debug,Serialize,Deserialize)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 16: "pub struct DifftFile {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub struct DifftFile {"
[SYNCDOC DEBUG]       no_spaces: "pubstructDifftFile{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 17: "    pub language: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub language: String,"
[SYNCDOC DEBUG]       no_spaces: "publanguage:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 18: "    pub path: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub path: String,"
[SYNCDOC DEBUG]       no_spaces: "pubpath:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 19: "    #[serde(default)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[serde(default)]"
[SYNCDOC DEBUG]       no_spaces: "#[serde(default)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 20: "    pub chunks: Option<Vec<Vec<DifftLine>>>,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub chunks: Option<Vec<Vec<DifftLine>>>,"
[SYNCDOC DEBUG]       no_spaces: "pubchunks:Option<Vec<Vec<DifftLine>>>,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 21: "    pub status: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub status: String,"
[SYNCDOC DEBUG]       no_spaces: "pubstatus:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 22: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 23: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 24: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 25: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]       no_spaces: "#[derive(Debug,Serialize,Deserialize)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 26: "pub struct DifftLine {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub struct DifftLine {"
[SYNCDOC DEBUG]       no_spaces: "pubstructDifftLine{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 27: "    #[serde(skip_serializing_if = \"Option::is_none\")]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[serde(skip_serializing_if = \"Option::is_none\")]"
[SYNCDOC DEBUG]       no_spaces: "#[serde(skip_serializing_if=\"Option::is_none\")]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 28: "    pub lhs: Option<DifftSide>,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub lhs: Option<DifftSide>,"
[SYNCDOC DEBUG]       no_spaces: "publhs:Option<DifftSide>,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 29: "    #[serde(skip_serializing_if = \"Option::is_none\")]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[serde(skip_serializing_if = \"Option::is_none\")]"
[SYNCDOC DEBUG]       no_spaces: "#[serde(skip_serializing_if=\"Option::is_none\")]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 30: "    pub rhs: Option<DifftSide>,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub rhs: Option<DifftSide>,"
[SYNCDOC DEBUG]       no_spaces: "pubrhs:Option<DifftSide>,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 31: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 32: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 33: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 34: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]       no_spaces: "#[derive(Debug,Serialize,Deserialize)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 35: "pub struct DifftSide {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub struct DifftSide {"
[SYNCDOC DEBUG]       no_spaces: "pubstructDifftSide{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 36: "    pub line_number: u32,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub line_number: u32,"
[SYNCDOC DEBUG]       no_spaces: "publine_number:u32,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 37: "    pub changes: Vec<DifftChange>,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub changes: Vec<DifftChange>,"
[SYNCDOC DEBUG]       no_spaces: "pubchanges:Vec<DifftChange>,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 38: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 39: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 40: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 41: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[derive(Debug, Serialize, Deserialize)]"
[SYNCDOC DEBUG]       no_spaces: "#[derive(Debug,Serialize,Deserialize)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 42: "pub struct DifftChange {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub struct DifftChange {"
[SYNCDOC DEBUG]       no_spaces: "pubstructDifftChange{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 43: "    pub start: u32,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub start: u32,"
[SYNCDOC DEBUG]       no_spaces: "pubstart:u32,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 44: "    pub end: u32,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub end: u32,"
[SYNCDOC DEBUG]       no_spaces: "pubend:u32,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 45: "    pub content: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub content: String,"
[SYNCDOC DEBUG]       no_spaces: "pubcontent:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 46: "    pub highlight: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub highlight: String,"
[SYNCDOC DEBUG]       no_spaces: "pubhighlight:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 47: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 48: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 49: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 50: "pub struct DifftasticFormat;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub struct DifftasticFormat;"
[SYNCDOC DEBUG]       no_spaces: "pubstructDifftasticFormat;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 51: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 52: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 53: "impl Format for DifftasticFormat {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "impl Format for DifftasticFormat {"
[SYNCDOC DEBUG]       no_spaces: "implFormatforDifftasticFormat{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 54: "    fn file_extension(&self) -> &'static str {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn file_extension(&self) -> &'static str {"
[SYNCDOC DEBUG]       no_spaces: "fnfile_extension(&self)->&'staticstr{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 55: "        \"diff\""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "\"diff\""
[SYNCDOC DEBUG]       no_spaces: "\"diff\""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 56: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 57: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 58: "    fn language(&self) -> tree_sitter::Language {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn language(&self) -> tree_sitter::Language {"
[SYNCDOC DEBUG]       no_spaces: "fnlanguage(&self)->tree_sitter::Language{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 59: "        // Difftastic doesn't use tree-sitter parsing"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Difftastic doesn't use tree-sitter parsing"
[SYNCDOC DEBUG]       no_spaces: "//Difftasticdoesn'tusetree-sitterparsing"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 60: "        tree_sitter_md::LANGUAGE.into()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "tree_sitter_md::LANGUAGE.into()"
[SYNCDOC DEBUG]       no_spaces: "tree_sitter_md::LANGUAGE.into()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 61: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 62: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 63: "    fn section_query(&self) -> &'static str {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn section_query(&self) -> &'static str {"
[SYNCDOC DEBUG]       no_spaces: "fnsection_query(&self)->&'staticstr{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 64: "        \"\""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "\"\""
[SYNCDOC DEBUG]       no_spaces: "\"\""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 65: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 66: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 67: "    fn title_query(&self) -> &'static str {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn title_query(&self) -> &'static str {"
[SYNCDOC DEBUG]       no_spaces: "fntitle_query(&self)->&'staticstr{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 68: "        \"\""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "\"\""
[SYNCDOC DEBUG]       no_spaces: "\"\""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 69: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 70: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 71: "    fn format_section_display(&self, level: usize, title: &str) -> Line<'static> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn format_section_display(&self, level: usize, title: &str) -> Line<'static> {"
[SYNCDOC DEBUG]       no_spaces: "fnformat_section_display(&self,level:usize,title:&str)->Line<'static>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 72: "        // Check if this is a hunk header with format: (N) @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Check if this is a hunk header with format: (N) @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]       no_spaces: "//Checkifthisisahunkheaderwithformat:(N)@@-X,Y+A,B@@"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 73: "        if title.contains(\"@@\") && title.starts_with('(') {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if title.contains(\"@@\") && title.starts_with('(') {"
[SYNCDOC DEBUG]       no_spaces: "iftitle.contains(\"@@\")&&title.starts_with('('){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 74: "            if let Some(close_paren) = title.find(')') {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(close_paren) = title.find(')') {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(close_paren)=title.find(')'){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 75: "                let hunk_num = &title[..=close_paren];"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let hunk_num = &title[..=close_paren];"
[SYNCDOC DEBUG]       no_spaces: "lethunk_num=&title[..=close_paren];"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 76: "                let rest = &title[close_paren + 1..].trim();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let rest = &title[close_paren + 1..].trim();"
[SYNCDOC DEBUG]       no_spaces: "letrest=&title[close_paren+1..].trim();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 77: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 78: "                // Determine color based on the diff header"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Determine color based on the diff header"
[SYNCDOC DEBUG]       no_spaces: "//Determinecolorbasedonthediffheader"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 79: "                let color = Self::determine_hunk_color_from_header(rest);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let color = Self::determine_hunk_color_from_header(rest);"
[SYNCDOC DEBUG]       no_spaces: "letcolor=Self::determine_hunk_color_from_header(rest);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 80: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 81: "                let spans = vec!["
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let spans = vec!["
[SYNCDOC DEBUG]       no_spaces: "letspans=vec!["
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 82: "                    Span::styled(hunk_num.to_string(), Style::default().fg(color)),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Span::styled(hunk_num.to_string(), Style::default().fg(color)),"
[SYNCDOC DEBUG]       no_spaces: "Span::styled(hunk_num.to_string(),Style::default().fg(color)),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 83: "                    Span::raw(\" \"),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Span::raw(\" \"),"
[SYNCDOC DEBUG]       no_spaces: "Span::raw(\"\"),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 84: "                    Span::raw((*rest).to_string()),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Span::raw((*rest).to_string()),"
[SYNCDOC DEBUG]       no_spaces: "Span::raw((*rest).to_string()),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 85: "                ];"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "];"
[SYNCDOC DEBUG]       no_spaces: "];"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 86: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 87: "                return Line::from(spans);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "return Line::from(spans);"
[SYNCDOC DEBUG]       no_spaces: "returnLine::from(spans);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 88: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 89: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 90: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 91: "        // For file nodes or other sections"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// For file nodes or other sections"
[SYNCDOC DEBUG]       no_spaces: "//Forfilenodesorothersections"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 92: "        let color = if level == 0 {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let color = if level == 0 {"
[SYNCDOC DEBUG]       no_spaces: "letcolor=iflevel==0{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 93: "            Color::Cyan // Files"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Color::Cyan // Files"
[SYNCDOC DEBUG]       no_spaces: "Color::Cyan//Files"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 94: "        } else {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else {"
[SYNCDOC DEBUG]       no_spaces: "}else{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 95: "            Color::LightYellow // Hunks"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Color::LightYellow // Hunks"
[SYNCDOC DEBUG]       no_spaces: "Color::LightYellow//Hunks"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 96: "        };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 97: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 98: "        let spans = vec!["
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let spans = vec!["
[SYNCDOC DEBUG]       no_spaces: "letspans=vec!["
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 99: "            Span::styled(\" \", Style::default().fg(color)),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Span::styled(\" \", Style::default().fg(color)),"
[SYNCDOC DEBUG]       no_spaces: "Span::styled(\"\",Style::default().fg(color)),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 100: "            Span::raw(title.to_string()),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Span::raw(title.to_string()),"
[SYNCDOC DEBUG]       no_spaces: "Span::raw(title.to_string()),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 101: "        ];"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "];"
[SYNCDOC DEBUG]       no_spaces: "];"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 102: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 103: "        Line::from(spans)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Line::from(spans)"
[SYNCDOC DEBUG]       no_spaces: "Line::from(spans)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 104: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 105: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 106: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 107: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 108: "impl DifftasticFormat {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "impl DifftasticFormat {"
[SYNCDOC DEBUG]       no_spaces: "implDifftasticFormat{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 109: "    fn determine_hunk_color_from_header(header: &str) -> Color {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn determine_hunk_color_from_header(header: &str) -> Color {"
[SYNCDOC DEBUG]       no_spaces: "fndetermine_hunk_color_from_header(header:&str)->Color{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 110: "        // Parse @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Parse @@ -X,Y +A,B @@"
[SYNCDOC DEBUG]       no_spaces: "//Parse@@-X,Y+A,B@@"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 111: "        if let Some(hunk_part) = header.strip_prefix(\"@@\").and_then(|s| s.split(\"@@\").next()) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(hunk_part) = header.strip_prefix(\"@@\").and_then(|s| s.split(\"@@\").next()) {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(hunk_part)=header.strip_prefix(\"@@\").and_then(|s|s.split(\"@@\").next()){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 112: "            let parts: Vec<&str> = hunk_part.split_whitespace().collect();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let parts: Vec<&str> = hunk_part.split_whitespace().collect();"
[SYNCDOC DEBUG]       no_spaces: "letparts:Vec<&str>=hunk_part.split_whitespace().collect();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 113: "            if parts.len() >= 2 {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if parts.len() >= 2 {"
[SYNCDOC DEBUG]       no_spaces: "ifparts.len()>=2{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 114: "                let lhs = parts[0].trim_start_matches('-');"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let lhs = parts[0].trim_start_matches('-');"
[SYNCDOC DEBUG]       no_spaces: "letlhs=parts[0].trim_start_matches('-');"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 115: "                let rhs = parts[1].trim_start_matches('+');"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let rhs = parts[1].trim_start_matches('+');"
[SYNCDOC DEBUG]       no_spaces: "letrhs=parts[1].trim_start_matches('+');"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 116: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 117: "                let lhs_count = lhs"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let lhs_count = lhs"
[SYNCDOC DEBUG]       no_spaces: "letlhs_count=lhs"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 118: "                    .split(',')"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".split(',')"
[SYNCDOC DEBUG]       no_spaces: ".split(',')"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 119: "                    .nth(1)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".nth(1)"
[SYNCDOC DEBUG]       no_spaces: ".nth(1)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 120: "                    .and_then(|s| s.parse::<u32>().ok())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|s| s.parse::<u32>().ok())"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|s|s.parse::<u32>().ok())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 121: "                    .unwrap_or(1);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or(1);"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or(1);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 122: "                let rhs_count = rhs"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let rhs_count = rhs"
[SYNCDOC DEBUG]       no_spaces: "letrhs_count=rhs"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 123: "                    .split(',')"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".split(',')"
[SYNCDOC DEBUG]       no_spaces: ".split(',')"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 124: "                    .nth(1)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".nth(1)"
[SYNCDOC DEBUG]       no_spaces: ".nth(1)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 125: "                    .and_then(|s| s.parse::<u32>().ok())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|s| s.parse::<u32>().ok())"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|s|s.parse::<u32>().ok())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 126: "                    .unwrap_or(1);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or(1);"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or(1);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 127: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 128: "                // Parse the line numbers too to detect -0,0 +1,N"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Parse the line numbers too to detect -0,0 +1,N"
[SYNCDOC DEBUG]       no_spaces: "//Parsethelinenumberstootodetect-0,0+1,N"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 129: "                let lhs_start = lhs"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let lhs_start = lhs"
[SYNCDOC DEBUG]       no_spaces: "letlhs_start=lhs"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 130: "                    .split(',')"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".split(',')"
[SYNCDOC DEBUG]       no_spaces: ".split(',')"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 131: "                    .next()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".next()"
[SYNCDOC DEBUG]       no_spaces: ".next()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 132: "                    .and_then(|s| s.parse::<u32>().ok())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|s| s.parse::<u32>().ok())"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|s|s.parse::<u32>().ok())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 133: "                    .unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 134: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 135: "                if lhs_start == 0 && lhs_count == 0 && rhs_count > 0 {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if lhs_start == 0 && lhs_count == 0 && rhs_count > 0 {"
[SYNCDOC DEBUG]       no_spaces: "iflhs_start==0&&lhs_count==0&&rhs_count>0{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 136: "                    return Color::Green; // Addition"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "return Color::Green; // Addition"
[SYNCDOC DEBUG]       no_spaces: "returnColor::Green;//Addition"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 137: "                } else if lhs_count > 0 && rhs_count == 0 && rhs.starts_with(\"0,\") {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else if lhs_count > 0 && rhs_count == 0 && rhs.starts_with(\"0,\") {"
[SYNCDOC DEBUG]       no_spaces: "}elseiflhs_count>0&&rhs_count==0&&rhs.starts_with(\"0,\"){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 138: "                    return Color::Red; // Deletion"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "return Color::Red; // Deletion"
[SYNCDOC DEBUG]       no_spaces: "returnColor::Red;//Deletion"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 139: "                } else if lhs_count == 0 && rhs_count > 0 {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else if lhs_count == 0 && rhs_count > 0 {"
[SYNCDOC DEBUG]       no_spaces: "}elseiflhs_count==0&&rhs_count>0{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 140: "                    return Color::Green; // Pure addition"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "return Color::Green; // Pure addition"
[SYNCDOC DEBUG]       no_spaces: "returnColor::Green;//Pureaddition"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 141: "                } else if lhs_count > 0 && rhs_count == 0 {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else if lhs_count > 0 && rhs_count == 0 {"
[SYNCDOC DEBUG]       no_spaces: "}elseiflhs_count>0&&rhs_count==0{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 142: "                    return Color::Red; // Pure deletion"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "return Color::Red; // Pure deletion"
[SYNCDOC DEBUG]       no_spaces: "returnColor::Red;//Puredeletion"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 143: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 144: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 145: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 146: "        Color::LightYellow // Modification"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Color::LightYellow // Modification"
[SYNCDOC DEBUG]       no_spaces: "Color::LightYellow//Modification"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 147: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 148: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 149: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 150: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 151: "#[allow(clippy::too_many_arguments)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[allow(clippy::too_many_arguments)]"
[SYNCDOC DEBUG]       no_spaces: "#[allow(clippy::too_many_arguments)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 152: "fn create_chunk_section("
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn create_chunk_section("
[SYNCDOC DEBUG]       no_spaces: "fncreate_chunk_section("
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 153: "    file_path: &str,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file_path: &str,"
[SYNCDOC DEBUG]       no_spaces: "file_path:&str,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 154: "    title: String,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "title: String,"
[SYNCDOC DEBUG]       no_spaces: "title:String,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 155: "    line_num: i64,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_num: i64,"
[SYNCDOC DEBUG]       no_spaces: "line_num:i64,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 156: "    column_start: i64,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_start: i64,"
[SYNCDOC DEBUG]       no_spaces: "column_start:i64,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 157: "    column_end: i64,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_end: i64,"
[SYNCDOC DEBUG]       no_spaces: "column_end:i64,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 158: "    chunk_type: ChunkType,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "chunk_type: ChunkType,"
[SYNCDOC DEBUG]       no_spaces: "chunk_type:ChunkType,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 159: "    lhs_text: Option<String>,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "lhs_text: Option<String>,"
[SYNCDOC DEBUG]       no_spaces: "lhs_text:Option<String>,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 160: "    rhs_text: Option<String>,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "rhs_text: Option<String>,"
[SYNCDOC DEBUG]       no_spaces: "rhs_text:Option<String>,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 161: ") -> Section {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ") -> Section {"
[SYNCDOC DEBUG]       no_spaces: ")->Section{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 162: "    Section {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Section {"
[SYNCDOC DEBUG]       no_spaces: "Section{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 163: "        title,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "title,"
[SYNCDOC DEBUG]       no_spaces: "title,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 164: "        level: 2,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "level: 2,"
[SYNCDOC DEBUG]       no_spaces: "level:2,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 165: "        line_start: line_num,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_start: line_num,"
[SYNCDOC DEBUG]       no_spaces: "line_start:line_num,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 166: "        line_end: line_num + 1,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_end: line_num + 1,"
[SYNCDOC DEBUG]       no_spaces: "line_end:line_num+1,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 167: "        column_start,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_start,"
[SYNCDOC DEBUG]       no_spaces: "column_start,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 168: "        column_end,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_end,"
[SYNCDOC DEBUG]       no_spaces: "column_end,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 169: "        byte_start: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_start: 0,"
[SYNCDOC DEBUG]       no_spaces: "byte_start:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 170: "        byte_end: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_end: 0,"
[SYNCDOC DEBUG]       no_spaces: "byte_end:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 171: "        file_path: file_path.to_string(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file_path: file_path.to_string(),"
[SYNCDOC DEBUG]       no_spaces: "file_path:file_path.to_string(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 172: "        parent_index: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "parent_index: None,"
[SYNCDOC DEBUG]       no_spaces: "parent_index:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 173: "        children_indices: Vec::new(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "children_indices: Vec::new(),"
[SYNCDOC DEBUG]       no_spaces: "children_indices:Vec::new(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 174: "        section_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "section_content: None,"
[SYNCDOC DEBUG]       no_spaces: "section_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 175: "        chunk_type: Some(chunk_type),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "chunk_type: Some(chunk_type),"
[SYNCDOC DEBUG]       no_spaces: "chunk_type:Some(chunk_type),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 176: "        lhs_content: lhs_text,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "lhs_content: lhs_text,"
[SYNCDOC DEBUG]       no_spaces: "lhs_content:lhs_text,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 177: "        rhs_content: rhs_text,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "rhs_content: rhs_text,"
[SYNCDOC DEBUG]       no_spaces: "rhs_content:rhs_text,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 178: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 179: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 180: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 181: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 182: "pub fn parse_difftastic_json(json_str: &str) -> io::Result<Vec<Section>> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub fn parse_difftastic_json(json_str: &str) -> io::Result<Vec<Section>> {"
[SYNCDOC DEBUG]       no_spaces: "pubfnparse_difftastic_json(json_str:&str)->io::Result<Vec<Section>>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 183: "    let files: Vec<DifftFile> = if let Ok(files) = serde_json::from_str::<Vec<DifftFile>>(json_str)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let files: Vec<DifftFile> = if let Ok(files) = serde_json::from_str::<Vec<DifftFile>>(json_str)"
[SYNCDOC DEBUG]       no_spaces: "letfiles:Vec<DifftFile>=ifletOk(files)=serde_json::from_str::<Vec<DifftFile>>(json_str)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 184: "    {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "{"
[SYNCDOC DEBUG]       no_spaces: "{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 185: "        // Array format: [{file1}, {file2}]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Array format: [{file1}, {file2}]"
[SYNCDOC DEBUG]       no_spaces: "//Arrayformat:[{file1},{file2}]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 186: "        files"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "files"
[SYNCDOC DEBUG]       no_spaces: "files"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 187: "    } else if json_str.trim().starts_with('[') {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else if json_str.trim().starts_with('[') {"
[SYNCDOC DEBUG]       no_spaces: "}elseifjson_str.trim().starts_with('['){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 188: "        // Failed to parse as array, invalid format"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Failed to parse as array, invalid format"
[SYNCDOC DEBUG]       no_spaces: "//Failedtoparseasarray,invalidformat"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 189: "        return Err(io::Error::new("
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "return Err(io::Error::new("
[SYNCDOC DEBUG]       no_spaces: "returnErr(io::Error::new("
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 190: "            io::ErrorKind::InvalidData,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "io::ErrorKind::InvalidData,"
[SYNCDOC DEBUG]       no_spaces: "io::ErrorKind::InvalidData,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 191: "            \"Invalid JSON array format\","
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "\"Invalid JSON array format\","
[SYNCDOC DEBUG]       no_spaces: "\"InvalidJSONarrayformat\","
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 192: "        ));"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "));"
[SYNCDOC DEBUG]       no_spaces: "));"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 193: "    } else {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else {"
[SYNCDOC DEBUG]       no_spaces: "}else{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 194: "        // Try parsing as newline-delimited JSON (NDJSON/JSON Lines)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Try parsing as newline-delimited JSON (NDJSON/JSON Lines)"
[SYNCDOC DEBUG]       no_spaces: "//Tryparsingasnewline-delimitedJSON(NDJSON/JSONLines)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 195: "        json_str"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "json_str"
[SYNCDOC DEBUG]       no_spaces: "json_str"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 196: "            .lines()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".lines()"
[SYNCDOC DEBUG]       no_spaces: ".lines()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 197: "            .filter(|line| !line.trim().is_empty())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".filter(|line| !line.trim().is_empty())"
[SYNCDOC DEBUG]       no_spaces: ".filter(|line|!line.trim().is_empty())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 198: "            .map(|line| {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map(|line| {"
[SYNCDOC DEBUG]       no_spaces: ".map(|line|{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 199: "                serde_json::from_str::<DifftFile>(line).map_err(|e| {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "serde_json::from_str::<DifftFile>(line).map_err(|e| {"
[SYNCDOC DEBUG]       no_spaces: "serde_json::from_str::<DifftFile>(line).map_err(|e|{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 200: "                    io::Error::new("
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "io::Error::new("
[SYNCDOC DEBUG]       no_spaces: "io::Error::new("
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 201: "                        io::ErrorKind::InvalidData,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "io::ErrorKind::InvalidData,"
[SYNCDOC DEBUG]       no_spaces: "io::ErrorKind::InvalidData,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 202: "                        format!(\"Failed to parse JSON line: {e}\"),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "format!(\"Failed to parse JSON line: {e}\"),"
[SYNCDOC DEBUG]       no_spaces: "format!(\"FailedtoparseJSONline:{e}\"),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 203: "                    )"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ")"
[SYNCDOC DEBUG]       no_spaces: ")"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 204: "                })"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "})"
[SYNCDOC DEBUG]       no_spaces: "})"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 205: "            })"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "})"
[SYNCDOC DEBUG]       no_spaces: "})"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 206: "            .collect::<Result<Vec<DifftFile>, io::Error>>()?"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".collect::<Result<Vec<DifftFile>, io::Error>>()?"
[SYNCDOC DEBUG]       no_spaces: ".collect::<Result<Vec<DifftFile>,io::Error>>()?"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 207: "    };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 208: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 209: "    let mut sections = Vec::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut sections = Vec::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutsections=Vec::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 210: "    let mut global_line = 0i64;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut global_line = 0i64;"
[SYNCDOC DEBUG]       no_spaces: "letmutglobal_line=0i64;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 211: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 212: "    for file in &files {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for file in &files {"
[SYNCDOC DEBUG]       no_spaces: "forfilein&files{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 213: "        // Skip unchanged files"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Skip unchanged files"
[SYNCDOC DEBUG]       no_spaces: "//Skipunchangedfiles"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 214: "        if file.status == \"unchanged\" {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if file.status == \"unchanged\" {"
[SYNCDOC DEBUG]       no_spaces: "iffile.status==\"unchanged\"{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 215: "            continue;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "continue;"
[SYNCDOC DEBUG]       no_spaces: "continue;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 216: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 217: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 218: "        let file_path = &file.path;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let file_path = &file.path;"
[SYNCDOC DEBUG]       no_spaces: "letfile_path=&file.path;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 219: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 220: "        // Create hunk sections directly (no file section)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Create hunk sections directly (no file section)"
[SYNCDOC DEBUG]       no_spaces: "//Createhunksectionsdirectly(nofilesection)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 221: "        if let Some(chunks) = &file.chunks {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(chunks) = &file.chunks {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(chunks)=&file.chunks{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 222: "            let mut hunk_counter = 0;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut hunk_counter = 0;"
[SYNCDOC DEBUG]       no_spaces: "letmuthunk_counter=0;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 223: "            for chunk in chunks {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for chunk in chunks {"
[SYNCDOC DEBUG]       no_spaces: "forchunkinchunks{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 224: "                // Each element in the chunk array is a separate hunk"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Each element in the chunk array is a separate hunk"
[SYNCDOC DEBUG]       no_spaces: "//Eachelementinthechunkarrayisaseparatehunk"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 225: "                for change in chunk {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for change in chunk {"
[SYNCDOC DEBUG]       no_spaces: "forchangeinchunk{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 226: "                    hunk_counter += 1;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "hunk_counter += 1;"
[SYNCDOC DEBUG]       no_spaces: "hunk_counter+=1;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 227: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 228: "                    // Format this individual change as a proper git diff hunk"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Format this individual change as a proper git diff hunk"
[SYNCDOC DEBUG]       no_spaces: "//Formatthisindividualchangeasapropergitdiffhunk"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 229: "                    let hunk_title = format_hunk_header(change, hunk_counter);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let hunk_title = format_hunk_header(change, hunk_counter);"
[SYNCDOC DEBUG]       no_spaces: "lethunk_title=format_hunk_header(change,hunk_counter);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 230: "                    let hunk_content = format_change_content(change);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let hunk_content = format_change_content(change);"
[SYNCDOC DEBUG]       no_spaces: "lethunk_content=format_change_content(change);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 231: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 232: "                    let hunk_start_line = global_line;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let hunk_start_line = global_line;"
[SYNCDOC DEBUG]       no_spaces: "lethunk_start_line=global_line;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 233: "                    let hunk_end_line ="
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let hunk_end_line ="
[SYNCDOC DEBUG]       no_spaces: "lethunk_end_line="
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 234: "                        global_line + i64::try_from(hunk_content.lines().count()).unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "global_line + i64::try_from(hunk_content.lines().count()).unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: "global_line+i64::try_from(hunk_content.lines().count()).unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 235: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 236: "                    // Create section for this hunk"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Create section for this hunk"
[SYNCDOC DEBUG]       no_spaces: "//Createsectionforthishunk"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 237: "                    sections.push(Section {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "sections.push(Section {"
[SYNCDOC DEBUG]       no_spaces: "sections.push(Section{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 238: "                        title: hunk_title,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "title: hunk_title,"
[SYNCDOC DEBUG]       no_spaces: "title:hunk_title,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 239: "                        level: 1,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "level: 1,"
[SYNCDOC DEBUG]       no_spaces: "level:1,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 240: "                        line_start: hunk_start_line,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_start: hunk_start_line,"
[SYNCDOC DEBUG]       no_spaces: "line_start:hunk_start_line,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 241: "                        line_end: hunk_end_line,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_end: hunk_end_line,"
[SYNCDOC DEBUG]       no_spaces: "line_end:hunk_end_line,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 242: "                        column_start: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_start: 0,"
[SYNCDOC DEBUG]       no_spaces: "column_start:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 243: "                        column_end: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_end: 0,"
[SYNCDOC DEBUG]       no_spaces: "column_end:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 244: "                        byte_start: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_start: 0,"
[SYNCDOC DEBUG]       no_spaces: "byte_start:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 245: "                        byte_end: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_end: 0,"
[SYNCDOC DEBUG]       no_spaces: "byte_end:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 246: "                        file_path: file_path.clone(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file_path: file_path.clone(),"
[SYNCDOC DEBUG]       no_spaces: "file_path:file_path.clone(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 247: "                        parent_index: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "parent_index: None,"
[SYNCDOC DEBUG]       no_spaces: "parent_index:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 248: "                        children_indices: Vec::new(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "children_indices: Vec::new(),"
[SYNCDOC DEBUG]       no_spaces: "children_indices:Vec::new(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 249: "                        section_content: Some(vec![hunk_content]),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "section_content: Some(vec![hunk_content]),"
[SYNCDOC DEBUG]       no_spaces: "section_content:Some(vec![hunk_content]),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 250: "                        chunk_type: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "chunk_type: None,"
[SYNCDOC DEBUG]       no_spaces: "chunk_type:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 251: "                        lhs_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "lhs_content: None,"
[SYNCDOC DEBUG]       no_spaces: "lhs_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 252: "                        rhs_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "rhs_content: None,"
[SYNCDOC DEBUG]       no_spaces: "rhs_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 253: "                    });"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "});"
[SYNCDOC DEBUG]       no_spaces: "});"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 254: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 255: "                    global_line = hunk_end_line + 1;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "global_line = hunk_end_line + 1;"
[SYNCDOC DEBUG]       no_spaces: "global_line=hunk_end_line+1;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 256: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 257: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 258: "        } else if file.status == \"created\" || file.status == \"deleted\" {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else if file.status == \"created\" || file.status == \"deleted\" {"
[SYNCDOC DEBUG]       no_spaces: "}elseiffile.status==\"created\"||file.status==\"deleted\"{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 259: "            // For files with no chunks (created/deleted without detailed hunks),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// For files with no chunks (created/deleted without detailed hunks),"
[SYNCDOC DEBUG]       no_spaces: "//Forfileswithnochunks(created/deletedwithoutdetailedhunks),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 260: "            // create a proper hunk header"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// create a proper hunk header"
[SYNCDOC DEBUG]       no_spaces: "//createaproperhunkheader"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 261: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 262: "            // Try to read the file to get line count"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Try to read the file to get line count"
[SYNCDOC DEBUG]       no_spaces: "//Trytoreadthefiletogetlinecount"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 263: "            let line_count = if file.status == \"created\" {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let line_count = if file.status == \"created\" {"
[SYNCDOC DEBUG]       no_spaces: "letline_count=iffile.status==\"created\"{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 264: "                // For created files, try to read from filesystem"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// For created files, try to read from filesystem"
[SYNCDOC DEBUG]       no_spaces: "//Forcreatedfiles,trytoreadfromfilesystem"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 265: "                std::fs::read_to_string(file_path)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "std::fs::read_to_string(file_path)"
[SYNCDOC DEBUG]       no_spaces: "std::fs::read_to_string(file_path)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 266: "                    .ok()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".ok()"
[SYNCDOC DEBUG]       no_spaces: ".ok()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 267: "                    .map_or(0, |content| content.lines().count())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map_or(0, |content| content.lines().count())"
[SYNCDOC DEBUG]       no_spaces: ".map_or(0,|content|content.lines().count())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 268: "            } else {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else {"
[SYNCDOC DEBUG]       no_spaces: "}else{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 269: "                0 // Deleted files"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "0 // Deleted files"
[SYNCDOC DEBUG]       no_spaces: "0//Deletedfiles"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 270: "            };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 271: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 272: "            let hunk_title = if file.status == \"created\" {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let hunk_title = if file.status == \"created\" {"
[SYNCDOC DEBUG]       no_spaces: "lethunk_title=iffile.status==\"created\"{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 273: "                format!(\"(1) @@ -0,0 +1,{line_count} @@\")"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "format!(\"(1) @@ -0,0 +1,{line_count} @@\")"
[SYNCDOC DEBUG]       no_spaces: "format!(\"(1)@@-0,0+1,{line_count}@@\")"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 274: "            } else {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else {"
[SYNCDOC DEBUG]       no_spaces: "}else{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 275: "                format!(\"(1) @@ -1,{line_count} +0,0 @@\")"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "format!(\"(1) @@ -1,{line_count} +0,0 @@\")"
[SYNCDOC DEBUG]       no_spaces: "format!(\"(1)@@-1,{line_count}+0,0@@\")"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 276: "            };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 277: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 278: "            let hunk_content = if file.status == \"created\" {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let hunk_content = if file.status == \"created\" {"
[SYNCDOC DEBUG]       no_spaces: "lethunk_content=iffile.status==\"created\"{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 279: "                std::fs::read_to_string(file_path)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "std::fs::read_to_string(file_path)"
[SYNCDOC DEBUG]       no_spaces: "std::fs::read_to_string(file_path)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 280: "                    .ok()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".ok()"
[SYNCDOC DEBUG]       no_spaces: ".ok()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 281: "                    .unwrap_or_else(|| format!(\"File was {}\", file.status))"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or_else(|| format!(\"File was {}\", file.status))"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or_else(||format!(\"Filewas{}\",file.status))"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 282: "            } else {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "} else {"
[SYNCDOC DEBUG]       no_spaces: "}else{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 283: "                format!(\"File was {}\", file.status)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "format!(\"File was {}\", file.status)"
[SYNCDOC DEBUG]       no_spaces: "format!(\"Filewas{}\",file.status)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 284: "            };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 285: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 286: "            sections.push(Section {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "sections.push(Section {"
[SYNCDOC DEBUG]       no_spaces: "sections.push(Section{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 287: "                title: hunk_title,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "title: hunk_title,"
[SYNCDOC DEBUG]       no_spaces: "title:hunk_title,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 288: "                level: 1,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "level: 1,"
[SYNCDOC DEBUG]       no_spaces: "level:1,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 289: "                line_start: global_line,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_start: global_line,"
[SYNCDOC DEBUG]       no_spaces: "line_start:global_line,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 290: "                line_end: global_line + i64::try_from(line_count).unwrap_or(0),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_end: global_line + i64::try_from(line_count).unwrap_or(0),"
[SYNCDOC DEBUG]       no_spaces: "line_end:global_line+i64::try_from(line_count).unwrap_or(0),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 291: "                column_start: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_start: 0,"
[SYNCDOC DEBUG]       no_spaces: "column_start:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 292: "                column_end: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_end: 0,"
[SYNCDOC DEBUG]       no_spaces: "column_end:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 293: "                byte_start: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_start: 0,"
[SYNCDOC DEBUG]       no_spaces: "byte_start:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 294: "                byte_end: 0,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "byte_end: 0,"
[SYNCDOC DEBUG]       no_spaces: "byte_end:0,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 295: "                file_path: file_path.clone(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file_path: file_path.clone(),"
[SYNCDOC DEBUG]       no_spaces: "file_path:file_path.clone(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 296: "                parent_index: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "parent_index: None,"
[SYNCDOC DEBUG]       no_spaces: "parent_index:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 297: "                children_indices: Vec::new(),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "children_indices: Vec::new(),"
[SYNCDOC DEBUG]       no_spaces: "children_indices:Vec::new(),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 298: "                section_content: Some(hunk_content.lines().map(String::from).collect()),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "section_content: Some(hunk_content.lines().map(String::from).collect()),"
[SYNCDOC DEBUG]       no_spaces: "section_content:Some(hunk_content.lines().map(String::from).collect()),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 299: "                chunk_type: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "chunk_type: None,"
[SYNCDOC DEBUG]       no_spaces: "chunk_type:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 300: "                lhs_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "lhs_content: None,"
[SYNCDOC DEBUG]       no_spaces: "lhs_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 301: "                rhs_content: None,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "rhs_content: None,"
[SYNCDOC DEBUG]       no_spaces: "rhs_content:None,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 302: "            });"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "});"
[SYNCDOC DEBUG]       no_spaces: "});"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 303: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 304: "            global_line += i64::try_from(line_count).unwrap_or(0) + 1;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "global_line += i64::try_from(line_count).unwrap_or(0) + 1;"
[SYNCDOC DEBUG]       no_spaces: "global_line+=i64::try_from(line_count).unwrap_or(0)+1;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 305: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 306: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 307: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 308: "    Ok(sections)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Ok(sections)"
[SYNCDOC DEBUG]       no_spaces: "Ok(sections)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 309: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 310: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 311: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 312: "fn format_hunk_header(change: &DifftLine, hunk_num: usize) -> String {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn format_hunk_header(change: &DifftLine, hunk_num: usize) -> String {"
[SYNCDOC DEBUG]       no_spaces: "fnformat_hunk_header(change:&DifftLine,hunk_num:usize)->String{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 313: "    let (lhs_line, rhs_line) = match (&change.lhs, &change.rhs) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let (lhs_line, rhs_line) = match (&change.lhs, &change.rhs) {"
[SYNCDOC DEBUG]       no_spaces: "let(lhs_line,rhs_line)=match(&change.lhs,&change.rhs){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 314: "        (Some(lhs), Some(rhs)) => (lhs.line_number, rhs.line_number),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(Some(lhs), Some(rhs)) => (lhs.line_number, rhs.line_number),"
[SYNCDOC DEBUG]       no_spaces: "(Some(lhs),Some(rhs))=>(lhs.line_number,rhs.line_number),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 315: "        (Some(lhs), None) => (lhs.line_number, 0),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(Some(lhs), None) => (lhs.line_number, 0),"
[SYNCDOC DEBUG]       no_spaces: "(Some(lhs),None)=>(lhs.line_number,0),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 316: "        (None, Some(rhs)) => (0, rhs.line_number),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(None, Some(rhs)) => (0, rhs.line_number),"
[SYNCDOC DEBUG]       no_spaces: "(None,Some(rhs))=>(0,rhs.line_number),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 317: "        _ => (0, 0),"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "_ => (0, 0),"
[SYNCDOC DEBUG]       no_spaces: "_=>(0,0),"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 318: "    };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 319: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 320: "    // Determine chunk size (for now, single line changes)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Determine chunk size (for now, single line changes)"
[SYNCDOC DEBUG]       no_spaces: "//Determinechunksize(fornow,singlelinechanges)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 321: "    let lhs_count = i32::from(change.lhs.is_some());"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let lhs_count = i32::from(change.lhs.is_some());"
[SYNCDOC DEBUG]       no_spaces: "letlhs_count=i32::from(change.lhs.is_some());"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 322: "    let rhs_count = i32::from(change.rhs.is_some());"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let rhs_count = i32::from(change.rhs.is_some());"
[SYNCDOC DEBUG]       no_spaces: "letrhs_count=i32::from(change.rhs.is_some());"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 323: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 324: "    format!(\"({hunk_num}) @@ -{lhs_line},{lhs_count} +{rhs_line},{rhs_count} @@\")"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "format!(\"({hunk_num}) @@ -{lhs_line},{lhs_count} +{rhs_line},{rhs_count} @@\")"
[SYNCDOC DEBUG]       no_spaces: "format!(\"({hunk_num})@@-{lhs_line},{lhs_count}+{rhs_line},{rhs_count}@@\")"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 325: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 326: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 327: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 328: "fn format_change_content(change: &DifftLine) -> String {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn format_change_content(change: &DifftLine) -> String {"
[SYNCDOC DEBUG]       no_spaces: "fnformat_change_content(change:&DifftLine)->String{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 329: "    let mut output = String::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut output = String::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutoutput=String::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 330: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 331: "    match (&change.lhs, &change.rhs) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "match (&change.lhs, &change.rhs) {"
[SYNCDOC DEBUG]       no_spaces: "match(&change.lhs,&change.rhs){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 332: "        (Some(lhs), Some(rhs)) => {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(Some(lhs), Some(rhs)) => {"
[SYNCDOC DEBUG]       no_spaces: "(Some(lhs),Some(rhs))=>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 333: "            // Modified line - show both sides"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Modified line - show both sides"
[SYNCDOC DEBUG]       no_spaces: "//Modifiedline-showbothsides"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 334: "            write!(output, \"-{}: \", lhs.line_number).unwrap();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "write!(output, \"-{}: \", lhs.line_number).unwrap();"
[SYNCDOC DEBUG]       no_spaces: "write!(output,\"-{}:\",lhs.line_number).unwrap();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 335: "            for ch in &lhs.changes {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for ch in &lhs.changes {"
[SYNCDOC DEBUG]       no_spaces: "forchin&lhs.changes{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 336: "                output.push_str(&ch.content);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       no_spaces: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 337: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 338: "            output.push('\\n');"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push('\\n');"
[SYNCDOC DEBUG]       no_spaces: "output.push('\\n');"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 339: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 340: "            write!(output, \"+{}: \", rhs.line_number).unwrap();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "write!(output, \"+{}: \", rhs.line_number).unwrap();"
[SYNCDOC DEBUG]       no_spaces: "write!(output,\"+{}:\",rhs.line_number).unwrap();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 341: "            for ch in &rhs.changes {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for ch in &rhs.changes {"
[SYNCDOC DEBUG]       no_spaces: "forchin&rhs.changes{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 342: "                output.push_str(&ch.content);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       no_spaces: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 343: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 344: "            output.push('\\n');"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push('\\n');"
[SYNCDOC DEBUG]       no_spaces: "output.push('\\n');"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 345: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 346: "        (Some(lhs), None) => {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(Some(lhs), None) => {"
[SYNCDOC DEBUG]       no_spaces: "(Some(lhs),None)=>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 347: "            // Deleted line"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Deleted line"
[SYNCDOC DEBUG]       no_spaces: "//Deletedline"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 348: "            write!(output, \"-{}: \", lhs.line_number).unwrap();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "write!(output, \"-{}: \", lhs.line_number).unwrap();"
[SYNCDOC DEBUG]       no_spaces: "write!(output,\"-{}:\",lhs.line_number).unwrap();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 349: "            for ch in &lhs.changes {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for ch in &lhs.changes {"
[SYNCDOC DEBUG]       no_spaces: "forchin&lhs.changes{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 350: "                output.push_str(&ch.content);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       no_spaces: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 351: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 352: "            output.push('\\n');"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push('\\n');"
[SYNCDOC DEBUG]       no_spaces: "output.push('\\n');"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 353: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 354: "        (None, Some(rhs)) => {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(None, Some(rhs)) => {"
[SYNCDOC DEBUG]       no_spaces: "(None,Some(rhs))=>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 355: "            // Added line"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "// Added line"
[SYNCDOC DEBUG]       no_spaces: "//Addedline"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 356: "            write!(output, \"+{}: \", rhs.line_number).unwrap();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "write!(output, \"+{}: \", rhs.line_number).unwrap();"
[SYNCDOC DEBUG]       no_spaces: "write!(output,\"+{}:\",rhs.line_number).unwrap();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 357: "            for ch in &rhs.changes {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for ch in &rhs.changes {"
[SYNCDOC DEBUG]       no_spaces: "forchin&rhs.changes{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 358: "                output.push_str(&ch.content);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       no_spaces: "output.push_str(&ch.content);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 359: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 360: "            output.push('\\n');"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push('\\n');"
[SYNCDOC DEBUG]       no_spaces: "output.push('\\n');"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 361: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 362: "        (None, None) => {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(None, None) => {"
[SYNCDOC DEBUG]       no_spaces: "(None,None)=>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 363: "            output.push_str(\" \\n\");"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output.push_str(\" \\n\");"
[SYNCDOC DEBUG]       no_spaces: "output.push_str(\"\\n\");"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 364: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 365: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 366: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 367: "    output"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "output"
[SYNCDOC DEBUG]       no_spaces: "output"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 368: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 369: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 370: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 371: "fn extract_chunk_text(side: &Value) -> Option<String> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn extract_chunk_text(side: &Value) -> Option<String> {"
[SYNCDOC DEBUG]       no_spaces: "fnextract_chunk_text(side:&Value)->Option<String>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 372: "    side.get(\"changes\")"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "side.get(\"changes\")"
[SYNCDOC DEBUG]       no_spaces: "side.get(\"changes\")"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 373: "        .and_then(|c| c.as_array())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|c| c.as_array())"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|c|c.as_array())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 374: "        .map(|changes| {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".map(|changes| {"
[SYNCDOC DEBUG]       no_spaces: ".map(|changes|{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 375: "            changes"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "changes"
[SYNCDOC DEBUG]       no_spaces: "changes"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 376: "                .iter()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".iter()"
[SYNCDOC DEBUG]       no_spaces: ".iter()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 377: "                .filter_map(|change| change.get(\"content\").and_then(|c| c.as_str()))"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".filter_map(|change| change.get(\"content\").and_then(|c| c.as_str()))"
[SYNCDOC DEBUG]       no_spaces: ".filter_map(|change|change.get(\"content\").and_then(|c|c.as_str()))"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 378: "                .collect::<String>()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".collect::<String>()"
[SYNCDOC DEBUG]       no_spaces: ".collect::<String>()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 379: "        })"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "})"
[SYNCDOC DEBUG]       no_spaces: "})"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 380: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 381: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 382: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 383: "fn extract_column_range(side: &Value) -> (i64, i64) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn extract_column_range(side: &Value) -> (i64, i64) {"
[SYNCDOC DEBUG]       no_spaces: "fnextract_column_range(side:&Value)->(i64,i64){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 384: "    let changes = side.get(\"changes\").and_then(|c| c.as_array());"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let changes = side.get(\"changes\").and_then(|c| c.as_array());"
[SYNCDOC DEBUG]       no_spaces: "letchanges=side.get(\"changes\").and_then(|c|c.as_array());"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 385: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 386: "    let start = changes"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let start = changes"
[SYNCDOC DEBUG]       no_spaces: "letstart=changes"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 387: "        .and_then(|arr| arr.first())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|arr| arr.first())"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|arr|arr.first())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 388: "        .and_then(|first| first.get(\"start\"))"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|first| first.get(\"start\"))"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|first|first.get(\"start\"))"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 389: "        .and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]       no_spaces: ".and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 390: "        .unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 391: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 392: "    let end = changes"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let end = changes"
[SYNCDOC DEBUG]       no_spaces: "letend=changes"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 393: "        .and_then(|arr| arr.last())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|arr| arr.last())"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|arr|arr.last())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 394: "        .and_then(|last| last.get(\"end\"))"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|last| last.get(\"end\"))"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|last|last.get(\"end\"))"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 395: "        .and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]       no_spaces: ".and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 396: "        .unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 397: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 398: "    (start, end)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(start, end)"
[SYNCDOC DEBUG]       no_spaces: "(start,end)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 399: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 400: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 401: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 402: "pub fn extract_difftastic_sections(json_path: &Path) -> io::Result<Vec<Section>> {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub fn extract_difftastic_sections(json_path: &Path) -> io::Result<Vec<Section>> {"
[SYNCDOC DEBUG]       no_spaces: "pubfnextract_difftastic_sections(json_path:&Path)->io::Result<Vec<Section>>{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 403: "    let content = fs::read_to_string(json_path)?;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let content = fs::read_to_string(json_path)?;"
[SYNCDOC DEBUG]       no_spaces: "letcontent=fs::read_to_string(json_path)?;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 404: "    let lines: Vec<Value> = content"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let lines: Vec<Value> = content"
[SYNCDOC DEBUG]       no_spaces: "letlines:Vec<Value>=content"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 405: "        .lines()"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".lines()"
[SYNCDOC DEBUG]       no_spaces: ".lines()"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 406: "        .filter_map(|line| serde_json::from_str(line).ok())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".filter_map(|line| serde_json::from_str(line).ok())"
[SYNCDOC DEBUG]       no_spaces: ".filter_map(|line|serde_json::from_str(line).ok())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 407: "        .collect();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".collect();"
[SYNCDOC DEBUG]       no_spaces: ".collect();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 408: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 409: "    let mut sections = Vec::new();"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let mut sections = Vec::new();"
[SYNCDOC DEBUG]       no_spaces: "letmutsections=Vec::new();"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 410: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 411: "    for value in lines {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for value in lines {"
[SYNCDOC DEBUG]       no_spaces: "forvalueinlines{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 412: "        let file_path = value"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let file_path = value"
[SYNCDOC DEBUG]       no_spaces: "letfile_path=value"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 413: "            .get(\"path\")"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".get(\"path\")"
[SYNCDOC DEBUG]       no_spaces: ".get(\"path\")"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 414: "            .and_then(|p| p.as_str())"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|p| p.as_str())"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|p|p.as_str())"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 415: "            .unwrap_or(\"unknown\");"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or(\"unknown\");"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or(\"unknown\");"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 416: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 417: "        if let Some(chunks) = value.get(\"chunks\").and_then(|c| c.as_array()) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(chunks) = value.get(\"chunks\").and_then(|c| c.as_array()) {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(chunks)=value.get(\"chunks\").and_then(|c|c.as_array()){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 418: "            for chunk_array in chunks {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for chunk_array in chunks {"
[SYNCDOC DEBUG]       no_spaces: "forchunk_arrayinchunks{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 419: "                if let Some(chunk_list) = chunk_array.as_array() {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "if let Some(chunk_list) = chunk_array.as_array() {"
[SYNCDOC DEBUG]       no_spaces: "ifletSome(chunk_list)=chunk_array.as_array(){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 420: "                    for chunk in chunk_list {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "for chunk in chunk_list {"
[SYNCDOC DEBUG]       no_spaces: "forchunkinchunk_list{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 421: "                        let lhs = chunk.get(\"lhs\");"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let lhs = chunk.get(\"lhs\");"
[SYNCDOC DEBUG]       no_spaces: "letlhs=chunk.get(\"lhs\");"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 422: "                        let rhs = chunk.get(\"rhs\");"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let rhs = chunk.get(\"rhs\");"
[SYNCDOC DEBUG]       no_spaces: "letrhs=chunk.get(\"rhs\");"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 423: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 424: "                        let chunk_type = match (lhs, rhs) {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let chunk_type = match (lhs, rhs) {"
[SYNCDOC DEBUG]       no_spaces: "letchunk_type=match(lhs,rhs){"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 425: "                            (Some(_), None) => ChunkType::Deleted,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(Some(_), None) => ChunkType::Deleted,"
[SYNCDOC DEBUG]       no_spaces: "(Some(_),None)=>ChunkType::Deleted,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 426: "                            (None, Some(_)) => ChunkType::Added,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(None, Some(_)) => ChunkType::Added,"
[SYNCDOC DEBUG]       no_spaces: "(None,Some(_))=>ChunkType::Added,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 427: "                            (Some(l), Some(r)) if l != r => ChunkType::Modified,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(Some(l), Some(r)) if l != r => ChunkType::Modified,"
[SYNCDOC DEBUG]       no_spaces: "(Some(l),Some(r))ifl!=r=>ChunkType::Modified,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 428: "                            (Some(_), Some(_)) => ChunkType::Unchanged,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "(Some(_), Some(_)) => ChunkType::Unchanged,"
[SYNCDOC DEBUG]       no_spaces: "(Some(_),Some(_))=>ChunkType::Unchanged,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 429: "                            _ => continue,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "_ => continue,"
[SYNCDOC DEBUG]       no_spaces: "_=>continue,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 430: "                        };"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "};"
[SYNCDOC DEBUG]       no_spaces: "};"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 431: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 432: "                        let line_num = lhs"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let line_num = lhs"
[SYNCDOC DEBUG]       no_spaces: "letline_num=lhs"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 433: "                            .or(rhs)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".or(rhs)"
[SYNCDOC DEBUG]       no_spaces: ".or(rhs)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 434: "                            .and_then(|v| v.get(\"line_number\"))"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(|v| v.get(\"line_number\"))"
[SYNCDOC DEBUG]       no_spaces: ".and_then(|v|v.get(\"line_number\"))"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 435: "                            .and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]       no_spaces: ".and_then(serde_json::Value::as_i64)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 436: "                            .unwrap_or(0);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ".unwrap_or(0);"
[SYNCDOC DEBUG]       no_spaces: ".unwrap_or(0);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 437: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 438: "                        let (column_start, column_end) ="
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let (column_start, column_end) ="
[SYNCDOC DEBUG]       no_spaces: "let(column_start,column_end)="
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 439: "                            lhs.or(rhs).map_or((0, 0), extract_column_range);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "lhs.or(rhs).map_or((0, 0), extract_column_range);"
[SYNCDOC DEBUG]       no_spaces: "lhs.or(rhs).map_or((0,0),extract_column_range);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 440: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 441: "                        let title = format!(\"Chunk @@ {file_path}:{line_num} @@\");"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let title = format!(\"Chunk @@ {file_path}:{line_num} @@\");"
[SYNCDOC DEBUG]       no_spaces: "lettitle=format!(\"Chunk@@{file_path}:{line_num}@@\");"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 442: "                        let lhs_text = lhs.and_then(extract_chunk_text);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let lhs_text = lhs.and_then(extract_chunk_text);"
[SYNCDOC DEBUG]       no_spaces: "letlhs_text=lhs.and_then(extract_chunk_text);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 443: "                        let rhs_text = rhs.and_then(extract_chunk_text);"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "let rhs_text = rhs.and_then(extract_chunk_text);"
[SYNCDOC DEBUG]       no_spaces: "letrhs_text=rhs.and_then(extract_chunk_text);"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 444: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 445: "                        sections.push(create_chunk_section("
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "sections.push(create_chunk_section("
[SYNCDOC DEBUG]       no_spaces: "sections.push(create_chunk_section("
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 446: "                            file_path,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "file_path,"
[SYNCDOC DEBUG]       no_spaces: "file_path,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 447: "                            title,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "title,"
[SYNCDOC DEBUG]       no_spaces: "title,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 448: "                            line_num,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "line_num,"
[SYNCDOC DEBUG]       no_spaces: "line_num,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 449: "                            column_start,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_start,"
[SYNCDOC DEBUG]       no_spaces: "column_start,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 450: "                            column_end,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "column_end,"
[SYNCDOC DEBUG]       no_spaces: "column_end,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 451: "                            chunk_type,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "chunk_type,"
[SYNCDOC DEBUG]       no_spaces: "chunk_type,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 452: "                            lhs_text,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "lhs_text,"
[SYNCDOC DEBUG]       no_spaces: "lhs_text,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 453: "                            rhs_text,"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "rhs_text,"
[SYNCDOC DEBUG]       no_spaces: "rhs_text,"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 454: "                        ));"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "));"
[SYNCDOC DEBUG]       no_spaces: "));"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 455: "                    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 456: "                }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 457: "            }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 458: "        }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 459: "    }"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 460: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 461: "    Ok(sections)"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "Ok(sections)"
[SYNCDOC DEBUG]       no_spaces: "Ok(sections)"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 462: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 463: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 464: "#[cfg(test)]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[cfg(test)]"
[SYNCDOC DEBUG]       no_spaces: "#[cfg(test)]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 465: "#[path = \"../tests/difftastic.rs\"]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[path = \"../tests/difftastic.rs\"]"
[SYNCDOC DEBUG]       no_spaces: "#[path=\"../tests/difftastic.rs\"]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 466: "mod tests;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "mod tests;"
[SYNCDOC DEBUG]       no_spaces: "modtests;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Final result length: 15047
[SYNCDOC DEBUG] === BOOKEND DEBUG END ===

[SYNCDOC DEBUG] After bookending: 10675
[SYNCDOC DEBUG] 
--- Final Result ---
[SYNCDOC DEBUG] #![doc = syncdoc::module_doc!()]

use crate::formats::Format;
use crate::section::{ChunkType, Section};
use ratatui::{
    style::{Color, Style},
    text::{Line, Span},
};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::fmt::Write;
use std::path::Path;
use std::{fs, io};

#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftFile {
    pub language: String,
    pub path: String,
    #[serde(default)]
    pub chunks: Option<Vec<Vec<DifftLine>>>,
    pub status: String,
}

#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftLine {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub lhs: Option<DifftSide>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub rhs: Option<DifftSide>,
}

#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftSide {
    pub line_number: u32,
    pub changes: Vec<DifftChange>,
}

#[syncdoc::omnidoc]
#[derive(Debug, Serialize, Deserialize)]
pub struct DifftChange {
    pub start: u32,
    pub end: u32,
    pub content: String,
    pub highlight: String,
}

#[syncdoc::omnidoc]
pub struct DifftasticFormat;

#[syncdoc::omnidoc]
impl Format for DifftasticFormat {
    fn file_extension(&self) -> &'static str {
        "diff"
    }

    fn language(&self) -> tree_sitter::Language {
        // Difftastic doesn't use tree-sitter parsing
        tree_sitter_md::LANGUAGE.into()
    }

    fn section_query(&self) -> &'static str {
        ""
    }

    fn title_query(&self) -> &'static str {
        ""
    }

    fn format_section_display(&self, level: usize, title: &str) -> Line<'static> {
        // Check if this is a hunk header with format: (N) @@ -X,Y +A,B @@
        if title.contains("@@") && title.starts_with('(') {
            if let Some(close_paren) = title.find(')') {
                let hunk_num = &title[..=close_paren];
                let rest = &title[close_paren + 1..].trim();

                // Determine color based on the diff header
                let color = Self::determine_hunk_color_from_header(rest);

                let spans = vec![
                    Span::styled(hunk_num.to_string(), Style::default().fg(color)),
                    Span::raw(" "),
                    Span::raw((*rest).to_string()),
                ];

                return Line::from(spans);
            }
        }

        // For file nodes or other sections
        let color = if level == 0 {
            Color::Cyan // Files
        } else {
            Color::LightYellow // Hunks
        };

        let spans = vec![
            Span::styled(" ", Style::default().fg(color)),
            Span::raw(title.to_string()),
        ];

        Line::from(spans)
    }
}

#[syncdoc::omnidoc]
impl DifftasticFormat {
    fn determine_hunk_color_from_header(header: &str) -> Color {
        // Parse @@ -X,Y +A,B @@
        if let Some(hunk_part) = header.strip_prefix("@@").and_then(|s| s.split("@@").next()) {
            let parts: Vec<&str> = hunk_part.split_whitespace().collect();
            if parts.len() >= 2 {
                let lhs = parts[0].trim_start_matches('-');
                let rhs = parts[1].trim_start_matches('+');

                let lhs_count = lhs
                    .split(',')
                    .nth(1)
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(1);
                let rhs_count = rhs
                    .split(',')
                    .nth(1)
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(1);

                // Parse the line numbers too to detect -0,0 +1,N
                let lhs_start = lhs
                    .split(',')
                    .next()
                    .and_then(|s| s.parse::<u32>().ok())
                    .unwrap_or(0);

                if lhs_start == 0 && lhs_count == 0 && rhs_count > 0 {
                    return Color::Green; // Addition
                } else if lhs_count > 0 && rhs_count == 0 && rhs.starts_with("0,") {
                    return Color::Red; // Deletion
                } else if lhs_count == 0 && rhs_count > 0 {
                    return Color::Green; // Pure addition
                } else if lhs_count > 0 && rhs_count == 0 {
                    return Color::Red; // Pure deletion
                }
            }
        }
        Color::LightYellow // Modification
    }
}

#[syncdoc::omnidoc]
#[allow(clippy::too_many_arguments)]
fn create_chunk_section(
    file_path: &str,
    title: String,
    line_num: i64,
    column_start: i64,
    column_end: i64,
    chunk_type: ChunkType,
    lhs_text: Option<String>,
    rhs_text: Option<String>,
) -> Section {
    Section {
        title,
        level: 2,
        line_start: line_num,
        line_end: line_num + 1,
        column_start,
        column_end,
        byte_start: 0,
        byte_end: 0,
        file_path: file_path.to_string(),
        parent_index: None,
        children_indices: Vec::new(),
        section_content: None,
        chunk_type: Some(chunk_type),
        lhs_content: lhs_text,
        rhs_content: rhs_text,
    }
}

#[syncdoc::omnidoc]
pub fn parse_difftastic_json(json_str: &str) -> io::Result<Vec<Section>> {
    let files: Vec<DifftFile> = if let Ok(files) = serde_json::from_str::<Vec<DifftFile>>(json_str)
    {
        // Array format: [{file1}, {file2}]
        files
    } else if json_str.trim().starts_with('[') {
        // Failed to parse as array, invalid format
        return Err(io::Error::new(
            io::ErrorKind::InvalidData,
            "Invalid JSON array format",
        ));
    } else {
        // Try parsing as newline-delimited JSON (NDJSON/JSON Lines)
        json_str
            .lines()
            .filter(|line| !line.trim().is_empty())
            .map(|line| {
                serde_json::from_str::<DifftFile>(line).map_err(|e| {
                    io::Error::new(
                        io::ErrorKind::InvalidData,
                        format!("Failed to parse JSON line: {e}"),
                    )
                })
            })
            .collect::<Result<Vec<DifftFile>, io::Error>>()?
    };

    let mut sections = Vec::new();
    let mut global_line = 0i64;

    for file in &files {
        // Skip unchanged files
        if file.status == "unchanged" {
            continue;
        }

        let file_path = &file.path;

        // Create hunk sections directly (no file section)
        if let Some(chunks) = &file.chunks {
            let mut hunk_counter = 0;
            for chunk in chunks {
                // Each element in the chunk array is a separate hunk
                for change in chunk {
                    hunk_counter += 1;

                    // Format this individual change as a proper git diff hunk
                    let hunk_title = format_hunk_header(change, hunk_counter);
                    let hunk_content = format_change_content(change);

                    let hunk_start_line = global_line;
                    let hunk_end_line =
                        global_line + i64::try_from(hunk_content.lines().count()).unwrap_or(0);

                    // Create section for this hunk
                    sections.push(Section {
                        title: hunk_title,
                        level: 1,
                        line_start: hunk_start_line,
                        line_end: hunk_end_line,
                        column_start: 0,
                        column_end: 0,
                        byte_start: 0,
                        byte_end: 0,
                        file_path: file_path.clone(),
                        parent_index: None,
                        children_indices: Vec::new(),
                        section_content: Some(vec![hunk_content]),
                        chunk_type: None,
                        lhs_content: None,
                        rhs_content: None,
                    });

                    global_line = hunk_end_line + 1;
                }
            }
        } else if file.status == "created" || file.status == "deleted" {
            // For files with no chunks (created/deleted without detailed hunks),
            // create a proper hunk header

            // Try to read the file to get line count
            let line_count = if file.status == "created" {
                // For created files, try to read from filesystem
                std::fs::read_to_string(file_path)
                    .ok()
                    .map_or(0, |content| content.lines().count())
            } else {
                0 // Deleted files
            };

            let hunk_title = if file.status == "created" {
                format!("(1) @@ -0,0 +1,{line_count} @@")
            } else {
                format!("(1) @@ -1,{line_count} +0,0 @@")
            };

            let hunk_content = if file.status == "created" {
                std::fs::read_to_string(file_path)
                    .ok()
                    .unwrap_or_else(|| format!("File was {}", file.status))
            } else {
                format!("File was {}", file.status)
            };

            sections.push(Section {
                title: hunk_title,
                level: 1,
                line_start: global_line,
                line_end: global_line + i64::try_from(line_count).unwrap_or(0),
                column_start: 0,
                column_end: 0,
                byte_start: 0,
                byte_end: 0,
                file_path: file_path.clone(),
                parent_index: None,
                children_indices: Vec::new(),
                section_content: Some(hunk_content.lines().map(String::from).collect()),
                chunk_type: None,
                lhs_content: None,
                rhs_content: None,
            });

            global_line += i64::try_from(line_count).unwrap_or(0) + 1;
        }
    }

    Ok(sections)
}

#[syncdoc::omnidoc]
fn format_hunk_header(change: &DifftLine, hunk_num: usize) -> String {
    let (lhs_line, rhs_line) = match (&change.lhs, &change.rhs) {
        (Some(lhs), Some(rhs)) => (lhs.line_number, rhs.line_number),
        (Some(lhs), None) => (lhs.line_number, 0),
        (None, Some(rhs)) => (0, rhs.line_number),
        _ => (0, 0),
    };

    // Determine chunk size (for now, single line changes)
    let lhs_count = i32::from(change.lhs.is_some());
    let rhs_count = i32::from(change.rhs.is_some());

    format!("({hunk_num}) @@ -{lhs_line},{lhs_count} +{rhs_line},{rhs_count} @@")
}

#[syncdoc::omnidoc]
fn format_change_content(change: &DifftLine) -> String {
    let mut output = String::new();

    match (&change.lhs, &change.rhs) {
        (Some(lhs), Some(rhs)) => {
            // Modified line - show both sides
            write!(output, "-{}: ", lhs.line_number).unwrap();
            for ch in &lhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');

            write!(output, "+{}: ", rhs.line_number).unwrap();
            for ch in &rhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (Some(lhs), None) => {
            // Deleted line
            write!(output, "-{}: ", lhs.line_number).unwrap();
            for ch in &lhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (None, Some(rhs)) => {
            // Added line
            write!(output, "+{}: ", rhs.line_number).unwrap();
            for ch in &rhs.changes {
                output.push_str(&ch.content);
            }
            output.push('\n');
        }
        (None, None) => {
            output.push_str(" \n");
        }
    }

    output
}

#[syncdoc::omnidoc]
fn extract_chunk_text(side: &Value) -> Option<String> {
    side.get("changes")
        .and_then(|c| c.as_array())
        .map(|changes| {
            changes
                .iter()
                .filter_map(|change| change.get("content").and_then(|c| c.as_str()))
                .collect::<String>()
        })
}

#[syncdoc::omnidoc]
fn extract_column_range(side: &Value) -> (i64, i64) {
    let changes = side.get("changes").and_then(|c| c.as_array());

    let start = changes
        .and_then(|arr| arr.first())
        .and_then(|first| first.get("start"))
        .and_then(serde_json::Value::as_i64)
        .unwrap_or(0);

    let end = changes
        .and_then(|arr| arr.last())
        .and_then(|last| last.get("end"))
        .and_then(serde_json::Value::as_i64)
        .unwrap_or(0);

    (start, end)
}

#[syncdoc::omnidoc]
pub fn extract_difftastic_sections(json_path: &Path) -> io::Result<Vec<Section>> {
    let content = fs::read_to_string(json_path)?;
    let lines: Vec<Value> = content
        .lines()
        .filter_map(|line| serde_json::from_str(line).ok())
        .collect();

    let mut sections = Vec::new();

    for value in lines {
        let file_path = value
            .get("path")
            .and_then(|p| p.as_str())
            .unwrap_or("unknown");

        if let Some(chunks) = value.get("chunks").and_then(|c| c.as_array()) {
            for chunk_array in chunks {
                if let Some(chunk_list) = chunk_array.as_array() {
                    for chunk in chunk_list {
                        let lhs = chunk.get("lhs");
                        let rhs = chunk.get("rhs");

                        let chunk_type = match (lhs, rhs) {
                            (Some(_), None) => ChunkType::Deleted,
                            (None, Some(_)) => ChunkType::Added,
                            (Some(l), Some(r)) if l != r => ChunkType::Modified,
                            (Some(_), Some(_)) => ChunkType::Unchanged,
                            _ => continue,
                        };

                        let line_num = lhs
                            .or(rhs)
                            .and_then(|v| v.get("line_number"))
                            .and_then(serde_json::Value::as_i64)
                            .unwrap_or(0);

                        let (column_start, column_end) =
                            lhs.or(rhs).map_or((0, 0), extract_column_range);

                        let title = format!("Chunk @@ {file_path}:{line_num} @@");
                        let lhs_text = lhs.and_then(extract_chunk_text);
                        let rhs_text = rhs.and_then(extract_chunk_text);

                        sections.push(create_chunk_section(
                            file_path,
                            title,
                            line_num,
                            column_start,
                            column_end,
                            chunk_type,
                            lhs_text,
                            rhs_text,
                        ));
                    }
                }
            }
        }
    }

    Ok(sections)
}

#[cfg(test)]
#[path = "../tests/difftastic.rs"]
mod tests;

[SYNCDOC DEBUG] === REFORMAT END ===

[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: pub, span: bytes(16938..16941) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(16942..16945) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: difftastic, span: bytes(16946..16956) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(16956..16957) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: pub, span: bytes(16958..16961) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(16962..16965) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: markdown, span: bytes(16966..16974) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(16974..16975) })
[SYNCDOC DEBUG] Processing item type: Trait
[SYNCDOC DEBUG] Processing item: Trait(TraitSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(16977..17045) }, Punct { char: '=', spacing: Alone, span: bytes(16977..17045) }, Literal { lit: " Abstracts document type differences through tree-sitter queries.", span: bytes(16977..17045) }], span: bytes(16977..17045) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17046..17049) }, Punct { char: '=', spacing: Alone, span: bytes(17046..17049) }, Literal { lit: "", span: bytes(17046..17049) }], span: bytes(17046..17049) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17050..17148) }, Punct { char: '=', spacing: Alone, span: bytes(17050..17148) }, Literal { lit: " Enables support for markdown and other structured formats by providing format-specific parsing", span: bytes(17050..17148) }], span: bytes(17050..17148) }) }, delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17149..17197) }, Punct { char: '=', spacing: Alone, span: bytes(17149..17197) }, Literal { lit: " queries (tree-sitter uses SCM lisp queries).", span: bytes(17149..17197) }], span: bytes(17149..17197) }) }, delimiter: Some(Nothing) }])), visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(17198..17201) }, string: "pub" }))), unsafe_kw: None, _trait: KTrait(Cached<proc_macro2::Ident> { value: Ident { sym: trait, span: bytes(17202..17207) }, string: "trait" }), name: Ident { sym: Format, span: bytes(17208..17214) }, generics: None, bounds: None, where_clause: None, items: BraceGroupContaining < syncdoc_core::parse::ModuleContent>(ModuleContent { inner_attrs: None, items: Repeats<1, 18446744073709551615, syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17221..17282) }, Punct { char: '=', spacing: Alone, span: bytes(17221..17282) }, Literal { lit: " File extension for syntax highlighting (e.g., \"md\", \"rs\")", span: bytes(17221..17282) }], span: bytes(17221..17282) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17287..17289) }, string: "fn" }), name: Ident { sym: file_extension, span: bytes(17290..17304) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17306..17310) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(17315..17316) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(17316..17317) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(17317..17323) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17324..17327) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17333..17393) }, Punct { char: '=', spacing: Alone, span: bytes(17333..17393) }, Literal { lit: " Returns the tree-sitter language parser for this format.", span: bytes(17333..17393) }], span: bytes(17333..17393) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17398..17400) }, string: "fn" }), name: Ident { sym: language, span: bytes(17401..17409) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17411..17415) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: tree_sitter, span: bytes(17420..17431) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(17431..17432) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(17432..17433) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Language, span: bytes(17433..17441) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17447..17512) }, Punct { char: '=', spacing: Alone, span: bytes(17447..17512) }, Literal { lit: " Tree-sitter query matching section boundaries in this format.", span: bytes(17447..17512) }], span: bytes(17447..17512) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17517..17519) }, string: "fn" }), name: Ident { sym: section_query, span: bytes(17520..17533) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17535..17539) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(17544..17545) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17545..17548) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17554..17617) }, Punct { char: '=', spacing: Alone, span: bytes(17554..17617) }, Literal { lit: " Tree-sitter query extracting section titles in this format.", span: bytes(17554..17617) }], span: bytes(17554..17617) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17622..17624) }, string: "fn" }), name: Ident { sym: title_query, span: bytes(17625..17636) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17638..17642) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(17647..17648) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17648..17651) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17657..17722) }, Punct { char: '=', spacing: Alone, span: bytes(17657..17722) }, Literal { lit: " Format a section heading for display with syntax highlighting", span: bytes(17657..17722) }], span: bytes(17657..17722) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17727..17729) }, string: "fn" }), name: Ident { sym: format_section_display, span: bytes(17730..17752) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17754..17758) }, string: "self" }) })), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: level, span: bytes(17760..17765) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: usize, span: bytes(17767..17772) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: title, span: bytes(17774..17779) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(17781..17782) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17782..17785) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: ratatui, span: bytes(17790..17797) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(17797..17798) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(17798..17799) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: text, span: bytes(17799..17803) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(17803..17804) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(17804..17805) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Line, span: bytes(17805..17809) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(17810..17811) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(17811..17817) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> }), delimiter: Some(Nothing) }]) }) })
[SYNCDOC DEBUG] Processing item type: TraitMethod
[SYNCDOC DEBUG] Processing item: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17221..17282) }, Punct { char: '=', spacing: Alone, span: bytes(17221..17282) }, Literal { lit: " File extension for syntax highlighting (e.g., \"md\", \"rs\")", span: bytes(17221..17282) }], span: bytes(17221..17282) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17287..17289) }, string: "fn" }), name: Ident { sym: file_extension, span: bytes(17290..17304) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17306..17310) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Joint, span: bytes(17315..17316) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(17316..17317) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(17317..17323) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17324..17327) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> })
[SYNCDOC DEBUG] Processing item type: TraitMethod
[SYNCDOC DEBUG] Processing item: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17333..17393) }, Punct { char: '=', spacing: Alone, span: bytes(17333..17393) }, Literal { lit: " Returns the tree-sitter language parser for this format.", span: bytes(17333..17393) }], span: bytes(17333..17393) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17398..17400) }, string: "fn" }), name: Ident { sym: language, span: bytes(17401..17409) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17411..17415) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: tree_sitter, span: bytes(17420..17431) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(17431..17432) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(17432..17433) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Language, span: bytes(17433..17441) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> })
[SYNCDOC DEBUG] Processing item type: TraitMethod
[SYNCDOC DEBUG] Processing item: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17447..17512) }, Punct { char: '=', spacing: Alone, span: bytes(17447..17512) }, Literal { lit: " Tree-sitter query matching section boundaries in this format.", span: bytes(17447..17512) }], span: bytes(17447..17512) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17517..17519) }, string: "fn" }), name: Ident { sym: section_query, span: bytes(17520..17533) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17535..17539) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(17544..17545) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17545..17548) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> })
[SYNCDOC DEBUG] Processing item type: TraitMethod
[SYNCDOC DEBUG] Processing item: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17554..17617) }, Punct { char: '=', spacing: Alone, span: bytes(17554..17617) }, Literal { lit: " Tree-sitter query extracting section titles in this format.", span: bytes(17554..17617) }], span: bytes(17554..17617) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17622..17624) }, string: "fn" }), name: Ident { sym: title_query, span: bytes(17625..17636) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17638..17642) }, string: "self" }) })), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(17647..17648) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17648..17651) })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> })
[SYNCDOC DEBUG] Processing item type: TraitMethod
[SYNCDOC DEBUG] Processing item: TraitMethod(TraitMethodSig { attributes: Some(Repeats<1, 18446744073709551615, syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::Attribute, unsynn::fundamental::Nothing> { value: Attribute { _hash: Operator<'#'>, content: BracketGroup(Group { delimiter: Bracket, stream: TokenStream [Ident { sym: doc, span: bytes(17657..17722) }, Punct { char: '=', spacing: Alone, span: bytes(17657..17722) }, Literal { lit: " Format a section heading for display with syntax highlighting", span: bytes(17657..17722) }], span: bytes(17657..17722) }) }, delimiter: Some(Nothing) }])), const_kw: None, async_kw: None, unsafe_kw: None, extern_kw: None, _fn: KFn(Cached<proc_macro2::Ident> { value: Ident { sym: fn, span: bytes(17727..17729) }, string: "fn" }), name: Ident { sym: format_section_display, span: bytes(17730..17752) }, generics: None, params: ParenthesisGroupContaining < core::option::Option<unsynn::container::DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>>>(Some(DelimitedVec<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>>([Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: SelfParam(Ref(Cons<unsynn::operator::Operator<'&'>, syncdoc_core::parse::KSelf> { first: Operator<'&'>, second: KSelf(Cached<proc_macro2::Ident> { value: Ident { sym: self, span: bytes(17754..17758) }, string: "self" }) })), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: level, span: bytes(17760..17765) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: usize, span: bytes(17767..17772) })) }, delimiter: Some(Nothing) }]) }), delimiter: Some(Operator<','>) }, Delimited<syncdoc_core::parse::FnParam, unsynn::operator::Operator<','>> { value: Named(NamedParam { mut_kw: None, name: Ident { sym: title, span: bytes(17774..17779) }, _colon: Operator<':'>, param_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '&', spacing: Alone, span: bytes(17781..17782) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::operator::Operator<','>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<','>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: str, span: bytes(17782..17785) })) }, delimiter: Some(Nothing) }]) }), delimiter: None }]))), return_type: Some(ReturnTypeTrait { _arrow: Operator<'->'>, return_type: Repeats<1, 18446744073709551615, unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing>([Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: ratatui, span: bytes(17790..17797) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(17797..17798) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(17798..17799) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: text, span: bytes(17799..17803) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Joint, span: bytes(17803..17804) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: ':', spacing: Alone, span: bytes(17804..17805) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: Line, span: bytes(17805..17809) })) }, delimiter: Some(Nothing) }, Delimited<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree>, unsynn::fundamental::Nothing> { value: Cons<unsynn::fundamental::Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::combinator::Either<unsynn::group::BraceGroup, unsynn::operator::Operator<';'>>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>> { first: Operator<'<'>, second: [Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Punct { char: '\'', spacing: Joint, span: bytes(17810..17811) })) }, Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree> { first: Except<unsynn::operator::Operator<'>'>>, second: AngleTokenTree(Either<unsynn::combinator::Cons<unsynn::operator::Operator<'<'>, alloc::vec::Vec<unsynn::combinator::Cons<unsynn::fundamental::Except<unsynn::operator::Operator<'>'>>, syncdoc_core::parse::AngleTokenTree>>, unsynn::operator::Operator<'>'>>, proc_macro2::TokenTree>(Ident { sym: static, span: bytes(17811..17817) })) }], third: Operator<'>'> })) }, delimiter: Some(Nothing) }]) }), where_clause: None, _semi: Operator<';'> })
[SYNCDOC DEBUG] 
=== REFORMAT START ===
[SYNCDOC DEBUG] Original length: 1158
[SYNCDOC DEBUG] Transformed length: 397
[SYNCDOC DEBUG] Formatted original length: 1158
[SYNCDOC DEBUG] Formatted transformed length: 382
[SYNCDOC DEBUG] 
--- Formatted Original ---
[SYNCDOC DEBUG] //! Format trait and implementations for different document types.
//!
//! This module defines the `Format` trait which abstracts over different
//! document formats (markdown, org-mode, restructuredtext, etc.) by providing
//! tree-sitter queries specific to each format.

pub mod difftastic;
pub mod markdown;

/// Abstracts document type differences through tree-sitter queries.
///
/// Enables support for markdown and other structured formats by providing format-specific parsing
/// queries (tree-sitter uses SCM lisp queries).
pub trait Format {
    /// File extension for syntax highlighting (e.g., "md", "rs")
    fn file_extension(&self) -> &'static str;
    /// Returns the tree-sitter language parser for this format.
    fn language(&self) -> tree_sitter::Language;
    /// Tree-sitter query matching section boundaries in this format.
    fn section_query(&self) -> &str;
    /// Tree-sitter query extracting section titles in this format.
    fn title_query(&self) -> &str;
    /// Format a section heading for display with syntax highlighting
    fn format_section_display(&self, level: usize, title: &str) -> ratatui::text::Line<'static>;
}

[SYNCDOC DEBUG] 
--- Formatted Transformed ---
[SYNCDOC DEBUG] # ! [doc = syncdoc :: module_doc ! ()]
pub mod difftastic;
pub mod markdown;
#[syncdoc::omnidoc]
pub trait Format {
    fn file_extension(&self) -> &'static str;
    fn language(&self) -> tree_sitter::Language;
    fn section_query(&self) -> &str;
    fn title_query(&self) -> &str;
    fn format_section_display(&self, level: usize, title: &str) -> ratatui::text::Line<'static>;
}

[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 25
[SYNCDOC DEBUG] After lines: 11
[SYNCDOC DEBUG] Hunks: 7
[SYNCDOC DEBUG] Hunk 0: before[0..6] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! Format trait and implementations for different document types."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module defines the `Format` trait which abstracts over different"
[SYNCDOC DEBUG]     [3]: "//! document formats (markdown, org-mode, restructuredtext, etc.) by providing"
[SYNCDOC DEBUG]     [4]: "//! tree-sitter queries specific to each format."
[SYNCDOC DEBUG]     [5]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[8..13] -> after[3..4]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [8]: ""
[SYNCDOC DEBUG]     [9]: "/// Abstracts document type differences through tree-sitter queries."
[SYNCDOC DEBUG]     [10]: "///"
[SYNCDOC DEBUG]     [11]: "/// Enables support for markdown and other structured formats by providing format-specific parsing"
[SYNCDOC DEBUG]     [12]: "/// queries (tree-sitter uses SCM lisp queries)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [3]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[14..15] -> after[5..5]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [14]: "    /// File extension for syntax highlighting (e.g., \"md\", \"rs\")"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 3: before[16..17] -> after[6..6]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [16]: "    /// Returns the tree-sitter language parser for this format."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 4: before[18..19] -> after[7..7]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [18]: "    /// Tree-sitter query matching section boundaries in this format."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[20..21] -> after[8..8]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [20]: "    /// Tree-sitter query extracting section titles in this format."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[22..23] -> after[9..9]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [22]: "    /// Format a section heading for display with syntax highlighting"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] DEBUG restore: Found 7 hunks
[SYNCDOC DEBUG]   Hunk 0: before[0..6] after[0..1]
[SYNCDOC DEBUG]   Hunk 1: before[8..13] after[3..4]
[SYNCDOC DEBUG]   Hunk 2: before[14..15] after[5..5]
[SYNCDOC DEBUG]   Hunk 3: before[16..17] after[6..6]
[SYNCDOC DEBUG]   Hunk 4: before[18..19] after[7..7]
[SYNCDOC DEBUG]   Hunk 5: before[20..21] after[8..8]
[SYNCDOC DEBUG]   Hunk 6: before[22..23] after[9..9]
[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 25
[SYNCDOC DEBUG] After lines: 11
[SYNCDOC DEBUG] Hunks: 7
[SYNCDOC DEBUG] Hunk 0: before[0..6] -> after[0..1]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [0]: "//! Format trait and implementations for different document types."
[SYNCDOC DEBUG]     [1]: "//!"
[SYNCDOC DEBUG]     [2]: "//! This module defines the `Format` trait which abstracts over different"
[SYNCDOC DEBUG]     [3]: "//! document formats (markdown, org-mode, restructuredtext, etc.) by providing"
[SYNCDOC DEBUG]     [4]: "//! tree-sitter queries specific to each format."
[SYNCDOC DEBUG]     [5]: ""
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [0]: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG] Hunk 1: before[8..13] -> after[3..4]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [8]: ""
[SYNCDOC DEBUG]     [9]: "/// Abstracts document type differences through tree-sitter queries."
[SYNCDOC DEBUG]     [10]: "///"
[SYNCDOC DEBUG]     [11]: "/// Enables support for markdown and other structured formats by providing format-specific parsing"
[SYNCDOC DEBUG]     [12]: "/// queries (tree-sitter uses SCM lisp queries)."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [3]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] Hunk 2: before[14..15] -> after[5..5]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [14]: "    /// File extension for syntax highlighting (e.g., \"md\", \"rs\")"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 3: before[16..17] -> after[6..6]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [16]: "    /// Returns the tree-sitter language parser for this format."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 4: before[18..19] -> after[7..7]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [18]: "    /// Tree-sitter query matching section boundaries in this format."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 5: before[20..21] -> after[8..8]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [20]: "    /// Tree-sitter query extracting section titles in this format."
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] Hunk 6: before[22..23] -> after[9..9]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]     [22]: "    /// Format a section heading for display with syntax highlighting"
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 0..6 (adds 1 lines, removes 6 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 8..13 (adds 1 lines, removes 5 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 14..15 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 16..17 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 18..19 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 20..21 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 22..23 (adds 0 lines, removes 1 lines)
[SYNCDOC DEBUG] Original != Result: true
[SYNCDOC DEBUG] 
=== BOOKEND DEBUG START ===
[SYNCDOC DEBUG] Input code length: 383
[SYNCDOC DEBUG] 
Line 0: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       -> Starts with #!
[SYNCDOC DEBUG]       -> Checking trigger "syncdoc::module_doc!": true
[SYNCDOC DEBUG]       -> Has trigger: true
[SYNCDOC DEBUG]   -> NEEDS BOOKENDING
[SYNCDOC DEBUG]     reformat_line for: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]     extract_bookend_content:
[SYNCDOC DEBUG]       trimmed: "# ! [doc = syncdoc :: module_doc ! ()]"
[SYNCDOC DEBUG]       no_spaces: "#![doc=syncdoc::module_doc!()]"
[SYNCDOC DEBUG]       Found #![ at position: 0
[SYNCDOC DEBUG]       Found ] at position: 29
[SYNCDOC DEBUG]       Extracted content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Got content: "doc=syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Created bookended expr: "const _: i32 = { doc=syncdoc::module_doc!() };"
[SYNCDOC DEBUG]     Rustfmt output: "const _: i32 = { doc = syncdoc::module_doc!() };\n"
[SYNCDOC DEBUG]     Stripped bookends: "doc = syncdoc::module_doc!()"
[SYNCDOC DEBUG]     Final result: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG]   -> Reformatted to: "#![doc = syncdoc::module_doc!()]"
[SYNCDOC DEBUG] 
Line 1: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 2: "pub mod difftastic;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub mod difftastic;"
[SYNCDOC DEBUG]       no_spaces: "pubmoddifftastic;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 3: "pub mod markdown;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub mod markdown;"
[SYNCDOC DEBUG]       no_spaces: "pubmodmarkdown;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 4: ""
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: ""
[SYNCDOC DEBUG]       no_spaces: ""
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 5: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 6: "pub trait Format {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub trait Format {"
[SYNCDOC DEBUG]       no_spaces: "pubtraitFormat{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 7: "    fn file_extension(&self) -> &'static str;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn file_extension(&self) -> &'static str;"
[SYNCDOC DEBUG]       no_spaces: "fnfile_extension(&self)->&'staticstr;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 8: "    fn language(&self) -> tree_sitter::Language;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn language(&self) -> tree_sitter::Language;"
[SYNCDOC DEBUG]       no_spaces: "fnlanguage(&self)->tree_sitter::Language;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 9: "    fn section_query(&self) -> &str;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn section_query(&self) -> &str;"
[SYNCDOC DEBUG]       no_spaces: "fnsection_query(&self)->&str;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 10: "    fn title_query(&self) -> &str;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn title_query(&self) -> &str;"
[SYNCDOC DEBUG]       no_spaces: "fntitle_query(&self)->&str;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 11: "    fn format_section_display(&self, level: usize, title: &str) -> ratatui::text::Line<'static>;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "fn format_section_display(&self, level: usize, title: &str) -> ratatui::text::Line<'static>;"
[SYNCDOC DEBUG]       no_spaces: "fnformat_section_display(&self,level:usize,title:&str)->ratatui::text::Line<'static>;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 12: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Final result length: 377
[SYNCDOC DEBUG] === BOOKEND DEBUG END ===

[SYNCDOC DEBUG] After bookending: 397
[SYNCDOC DEBUG] 
--- Final Result ---
[SYNCDOC DEBUG] #![doc = syncdoc::module_doc!()]

pub mod difftastic;
pub mod markdown;

#[syncdoc::omnidoc]
pub trait Format {
    fn file_extension(&self) -> &'static str;
    fn language(&self) -> tree_sitter::Language;
    fn section_query(&self) -> &str;
    fn title_query(&self) -> &str;
    fn format_section_display(&self, level: usize, title: &str) -> ratatui::text::Line<'static>;
}

[SYNCDOC DEBUG] === REFORMAT END ===

[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: pub, span: bytes(17823..17826) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(17827..17830) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: formats, span: bytes(17831..17838) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(17838..17839) })
[SYNCDOC DEBUG] Processing item type: Module
[SYNCDOC DEBUG] Processing item: Module(ModuleSig { attributes: None, visibility: Some(Public(KPub(Cached<proc_macro2::Ident> { value: Ident { sym: pub, span: bytes(17840..17843) }, string: "pub" }))), _mod: KMod(Cached<proc_macro2::Ident> { value: Ident { sym: mod, span: bytes(17844..17847) }, string: "mod" }), name: Ident { sym: formats, span: bytes(17848..17855) }, items: BraceGroupContaining < syncdoc_core::parse::ModuleContent>(ModuleContent { inner_attrs: None, items: Repeats<1, 18446744073709551615, syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing>([Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Other(Ident { sym: pub, span: bytes(17862..17865) }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Other(Ident { sym: mod, span: bytes(17866..17869) }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Other(Ident { sym: difftastic, span: bytes(17870..17880) }), delimiter: Some(Nothing) }, Delimited<syncdoc_core::parse::ModuleItem, unsynn::fundamental::Nothing> { value: Other(Punct { char: ';', spacing: Alone, span: bytes(17880..17881) }), delimiter: Some(Nothing) }]) }) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: pub, span: bytes(17862..17865) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: mod, span: bytes(17866..17869) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Ident { sym: difftastic, span: bytes(17870..17880) })
[SYNCDOC DEBUG] Processing item type: Other
[SYNCDOC DEBUG] Processing item: Other(Punct { char: ';', spacing: Alone, span: bytes(17880..17881) })
[SYNCDOC DEBUG] 
=== REFORMAT START ===
[SYNCDOC DEBUG] Original length: 61
[SYNCDOC DEBUG] Transformed length: 81
[SYNCDOC DEBUG] Formatted original length: 61
[SYNCDOC DEBUG] Formatted transformed length: 81
[SYNCDOC DEBUG] 
--- Formatted Original ---
[SYNCDOC DEBUG] pub mod formats;
pub mod formats {
    pub mod difftastic;
}

[SYNCDOC DEBUG] 
--- Formatted Transformed ---
[SYNCDOC DEBUG] pub mod formats;
#[syncdoc::omnidoc]
pub mod formats {
    pub mod difftastic;
}

[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 4
[SYNCDOC DEBUG] After lines: 5
[SYNCDOC DEBUG] Hunks: 1
[SYNCDOC DEBUG] Hunk 0: before[1..1] -> after[1..2]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [1]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] DEBUG restore: Found 1 hunks
[SYNCDOC DEBUG]   Hunk 0: before[1..1] after[1..2]
[SYNCDOC DEBUG] === HUNK DEBUG ===
[SYNCDOC DEBUG] Before lines: 4
[SYNCDOC DEBUG] After lines: 5
[SYNCDOC DEBUG] Hunks: 1
[SYNCDOC DEBUG] Hunk 0: before[1..1] -> after[1..2]
[SYNCDOC DEBUG]   Before snippet:
[SYNCDOC DEBUG]   After snippet:
[SYNCDOC DEBUG]     [1]: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG] ==================
[SYNCDOC DEBUG] APPLYING relevant hunk at lines 1..1 (adds 1 lines, removes 0 lines)
[SYNCDOC DEBUG] Original != Result: true
[SYNCDOC DEBUG] 
=== BOOKEND DEBUG START ===
[SYNCDOC DEBUG] Input code length: 80
[SYNCDOC DEBUG] 
Line 0: "pub mod formats;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub mod formats;"
[SYNCDOC DEBUG]       no_spaces: "pubmodformats;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 1: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       no_spaces: "#[syncdoc::omnidoc]"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 2: "pub mod formats {"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub mod formats {"
[SYNCDOC DEBUG]       no_spaces: "pubmodformats{"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 3: "    pub mod difftastic;"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "pub mod difftastic;"
[SYNCDOC DEBUG]       no_spaces: "pubmoddifftastic;"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Line 4: "}"
[SYNCDOC DEBUG]     Checking needs_bookending:
[SYNCDOC DEBUG]       trimmed: "}"
[SYNCDOC DEBUG]       no_spaces: "}"
[SYNCDOC DEBUG]       -> Does NOT start with #!
[SYNCDOC DEBUG]   -> No bookending needed
[SYNCDOC DEBUG] 
Final result length: 80
[SYNCDOC DEBUG] === BOOKEND DEBUG END ===

[SYNCDOC DEBUG] After bookending: 81
[SYNCDOC DEBUG] 
--- Final Result ---
[SYNCDOC DEBUG] pub mod formats;
#[syncdoc::omnidoc]
pub mod formats {
    pub mod difftastic;
}

[SYNCDOC DEBUG] === REFORMAT END ===


=== Migration Summary ===
Processed 3 file(s)
Extracted 30 documentation(s)
Touched 10 missing file(s)
Rewrote 3 file(s)
